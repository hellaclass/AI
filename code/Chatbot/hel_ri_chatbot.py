# -*- coding: utf-8 -*-
"""hel_ri_chatbot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lgo6xDzGk1OETWdEvBKX-G0j22rEcksY
"""

#spell_checker
!pip install git+https://github.com/ssut/py-hanspell.git

!pip install konlpy

#lib

import re

import pickle

from hanspell import spell_checker
from konlpy.tag import Kkma

import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.models import load_model

# word_to_index path
word_to_index_path = '/content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/data/word_to_index.pkl'

# model_path
model_path = '/content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5'
model = load_model(model_path)

# 정규표현식 함수 정의

def re_sub(self):
    
    self = re.sub("\d\d\d\d"," @",self)
    self = re.sub("\d\d분"," #분",self)

    return self

## 띄어쓰기, 맞춤법
def check_spell(self):
    
    spelled_sent = spell_checker.check(self)
    self = spelled_sent.checked

    return self

# kkma 형태소 토큰화 함수정의
def kkma_tokenizer(self):
    kkma = Kkma()
    valid_pos = ['NNG','VV','SW','MAG']

    # tokenize
    token_text = kkma.pos(self)
    
    # 불용어 제거
    ls = []
    for token in token_text:
        
        if token[1] in valid_pos:
            ls.append(token[0])
        
    self = ls

    return self

## df의 정수인코딩 column 생성 및 반영 함수화
# tokenizer.fit_on_texts 에서 특수문자 @,# 을 자체적으로 없앰, 이 부분 보완 필요

def int_encode(self):
    
    # word_to_index 불러오기
    wti = open(word_to_index_path, 'rb')
    word_to_index = pickle.load(wti)
    
    # 토크나이저 최적화
    tokenizer = Tokenizer()
    tokenizer.word_index = word_to_index

    seq = tokenizer.texts_to_sequences(self)

    ls = sum(seq,[])

    self = ls

    
    return self

def padding(self):
    max_len = 8

    pad = [0]*(max_len-len(self))
    self = pad + self

    return self

def pred(self):

    self = np.array(self).reshape(-1,8)

    
    pred = model.predict(self)
    print(pred)

    
    if np.max(pred[0]) < 0.3:
        self = 99
    else:
        self = np.argmax(pred)

    return self

def start_predict(self):

    self = re_sub(self)

    self = check_spell(self)
    
    self = kkma_tokenizer(self)
    
    self = int_encode(self)
    
    intent = {0:'운행시작', 1:'가게전화',2:'가게도착',3:'픽업완료',4:'영수증번호',5:'소요시간선택', 6:'배달완료', 99:'fallback_intent'}

    if self == []:
        self = 99
    else:
        self = padding(self)
        self = pred(self)

    return self,intent[self]

# Commented out IPython magic to ensure Python compatibility.
# %%time
# text = "맛동산 맛있음"
# print(start_predict(text))
#

