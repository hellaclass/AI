# -*- coding: utf-8 -*-
"""hel_ri_chatbot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJuLnmkSvHvWFtc29J3unrr8cPl30BT6
"""

# spell_checker
# !pip install git+https://github.com/ssut/py-hanspell.git

# !pip install konlpy

#lib

# import re

from hanspell import spell_checker
from konlpy.tag import Kkma

import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.models import load_model

# token_ls path
token_ls_path = './data/Chatbot'

# model_path
model_path = './model/best_model.h5'

# # 정규표현식 함수 정의

# def re_sub(self):
    
#     self = re.sub("\d\d\d\d"," @",self)
#     self = re.sub("\d\d분"," #분",self)

#     return self

## 띄어쓰기, 맞춤법
def check_spell(self):
    
    spelled_sent = spell_checker.check(self)
    self = spelled_sent.checked

    return self

# kkma 형태소 토큰화 함수정의
def kkma_tokenizer(self):
    kkma = Kkma()
    valid_pos = ['NNG','VV','SW','MAG']

    # tokenize
    token_text = kkma.pos(self)
    
    # 불용어 제거
    ls = []
    for token in token_text:
        
        if token[1] in valid_pos:
            ls.append(token[0])
        
    self = ls

    return self

## df의 정수인코딩 column 생성 및 반영 함수화
# tokenizer.fit_on_texts 에서 특수문자 @,# 을 자체적으로 없앰, 이 부분 보완 필요

def int_encode(self):
    
    # 토큰 리스트 경로
    token_ls = pd.read_csv(token_ls_path)['token']
    
    # 토크나이저 최적화
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(token_ls)

    seq = tokenizer.texts_to_sequences(self)

    ls = sum(seq,[])

    self = ls

    return self

def padding(self):
    max_len = 8

    pad = [0]*(max_len-len(self))
    self = pad + self

    return self

def pred(self):

    self = np.array(self).reshape(-1,8)
    
    model = load_model(model_path)
    
    pred = model.predict(self)
    
    self = np.argmax(pred)

    
    return self

def start_predict(self):

    # re_self = re_sub(self)
    check_self = check_spell(self)
    kkma_self = kkma_tokenizer(check_self)
    int_self = int_encode(kkma_self)
    pad_self = padding(int_self)
    pred_self = pred(pad_self)

    return pred_self




text = "주문번호 3400"
start_predict(text)

