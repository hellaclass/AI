{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hel_ri_chatbot.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMFamy3WbsNo"
      },
      "source": [
        "# spell_checker\n",
        "# !pip install git+https://github.com/ssut/py-hanspell.git\n",
        "\n",
        "# !pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D7JfRIuXkhX"
      },
      "source": [
        "#lib\n",
        "\n",
        "# import re\n",
        "\n",
        "from hanspell import spell_checker\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v10jv7DhRvFZ"
      },
      "source": [
        "# token_ls path\n",
        "token_ls_path = '/content/drive/MyDrive/Programming/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/token_ls.csv'\n",
        "\n",
        "# model_path\n",
        "model_path = '/content/drive/MyDrive/Programming/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/model/best_model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZADalzTCLJ2I"
      },
      "source": [
        "# # 정규표현식 함수 정의\n",
        "\n",
        "# def re_sub(self):\n",
        "    \n",
        "#     self = re.sub(\"\\d\\d\\d\\d\",\" @\",self)\n",
        "#     self = re.sub(\"\\d\\d분\",\" #분\",self)\n",
        "\n",
        "#     return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLNKB6MiXMKU"
      },
      "source": [
        "## 띄어쓰기, 맞춤법\n",
        "def check_spell(self):\n",
        "    \n",
        "    spelled_sent = spell_checker.check(self)\n",
        "    self = spelled_sent.checked\n",
        "\n",
        "    return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmsZcSzsZoLM"
      },
      "source": [
        "# kkma 형태소 토큰화 함수정의\n",
        "def kkma_tokenizer(self):\n",
        "    kkma = Kkma()\n",
        "    valid_pos = ['NNG','VV','SW','MAG']\n",
        "\n",
        "    # tokenize\n",
        "    token_text = kkma.pos(self)\n",
        "    \n",
        "    # 불용어 제거\n",
        "    ls = []\n",
        "    for token in token_text:\n",
        "        \n",
        "        if token[1] in valid_pos:\n",
        "            ls.append(token[0])\n",
        "        \n",
        "    self = ls\n",
        "\n",
        "    return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47JDSSKmN-8u"
      },
      "source": [
        "## df의 정수인코딩 column 생성 및 반영 함수화\n",
        "# tokenizer.fit_on_texts 에서 특수문자 @,# 을 자체적으로 없앰, 이 부분 보완 필요\n",
        "\n",
        "def int_encode(self):\n",
        "    \n",
        "    # 토큰 리스트 경로\n",
        "    token_ls = pd.read_csv(token_ls_path)['token']\n",
        "    \n",
        "    # 토크나이저 최적화\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(token_ls)\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences(self)\n",
        "\n",
        "    ls = sum(seq,[])\n",
        "\n",
        "    self = ls\n",
        "\n",
        "    return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bcQO0EQMpkJ"
      },
      "source": [
        "def padding(self):\n",
        "    max_len = 8\n",
        "\n",
        "    pad = [0]*(max_len-len(self))\n",
        "    self = pad + self\n",
        "\n",
        "    return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEkyqyKMPkjx"
      },
      "source": [
        "def pred(self):\n",
        "\n",
        "    self = np.array(self).reshape(-1,8)\n",
        "    \n",
        "    model = load_model(model_path)\n",
        "    \n",
        "    pred = model.predict(self)\n",
        "    \n",
        "    self = np.argmax(pred)\n",
        "\n",
        "    \n",
        "    return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj6Erx6jXZUd"
      },
      "source": [
        "def start_predict(self):\n",
        "\n",
        "    # re_self = re_sub(self)\n",
        "    check_self = check_spell(re_self)\n",
        "    kkma_self = kkma_tokenizer(check_self)\n",
        "    int_self = int_encode(kkma_self)\n",
        "    pad_self = padding(int_self)\n",
        "    pred_self = pred(pad_self)\n",
        "\n",
        "    return pred_self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r20HZS89NgB-"
      },
      "source": [
        "text = \"주문번호 3400\"\n",
        "start_predict(text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hGvZe0kOzfZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}