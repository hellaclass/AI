{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hel_ri_celus_model_training_model and activation compare","provenance":[{"file_id":"1sQujHqvwSp4vswingcOQdm6pCh1pKFvh","timestamp":1608182204055}],"collapsed_sections":["4zgaRpQDdvXb","kguP0dF4shL8"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WGO07lIw1kG9"},"source":["# Code for model training & test"]},{"cell_type":"markdown","metadata":{"id":"qlbKkYipU4Yl"},"source":["# lib & load_data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLUeFcl6FWua","executionInfo":{"status":"ok","timestamp":1608697944252,"user_tz":-540,"elapsed":20540,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"31e88b2f-473d-4623-add4-b3c8ae82bfe5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WxNNJLVzm2Jn"},"source":["#### installation ###\n","\n","!pip install git+https://github.com/ssut/py-hanspell.git\n","!pip install konlpy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cv54gM_7-3ui"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.datasets import reuters\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from konlpy.tag import Okt, Kkma\n","okt = Okt()\n","kkma = Kkma()\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import re\n","from hanspell import spell_checker\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n","\n","from tensorflow.keras.optimizers import Adadelta, Adam, Nadam\n","\n","from tensorflow.keras import backend as K\n","import timeit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OnaYS6u2ynBy"},"source":["!pip install scikit-optimize"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7VgckmKyk5s"},"source":["import skopt\r\n","from skopt import gp_minimize\r\n","from skopt.space import Real, Categorical, Integer\r\n","from skopt.plots import plot_convergence\r\n","from skopt.plots import plot_objective, plot_evaluations\r\n","from skopt.plots import plot_histogram, plot_objective_2D\r\n","from skopt.utils import use_named_args"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M_g2attpzpQr"},"source":["## path setting"]},{"cell_type":"code","metadata":{"id":"eD0cMKN20N9Y"},"source":["train_data_path = \"/content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/data/train_data.csv\"\n","test_data_path = \"/content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/data/test_data.csv\"\n","\n","word_to_index_save_path = \"/content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/data/\"\n","\n","model_save_path = '/content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fkHBqJjpU7yD"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"RzHmt72Qg_W0"},"source":["df_train = pd.read_csv(train_data_path)\n","df_test = pd.read_csv(test_data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9GKIlxYKU_Yn"},"source":["## 정규 표현식으로 치환\n","분, 주문번호 변환"]},{"cell_type":"code","metadata":{"id":"Q4iY6nV8hrx2"},"source":["# 정규표현식 함수 정의\n","\n","def re_sub(df):\n","    convert_ls =[]\n","    for idx in (df['text']):\n","        sample = idx = re.sub(r',', '', idx)\n","        idx = re.sub(r'(.)(\\d)\\s(\\d)\\s(\\d)\\s(\\d)', r'\\1\\2\\3\\4\\5', sample)\n","        idx = re.sub(\"\\d\\d\\d\\d\",\" @\",idx)\n","        idx = re.sub(\"\\d\\d분\",\" #분\",idx)\n","        \n","        ## 띄어쓰기, 맞춤법\n","        spelled_sent = spell_checker.check(idx)\n","        hanspell_sent = spelled_sent.checked\n","        \n","        convert_ls.append(hanspell_sent)\n","\n","    convert_txt = pd.Series(convert_ls, name = 'convert_ls')\n","    df = pd.concat([df,convert_txt],axis = 1)\n","\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9WY-8mVhidQq"},"source":["df_train = re_sub(df_train)\n","df_test = re_sub(df_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"iGGTCnkAd47L","executionInfo":{"status":"ok","timestamp":1608698139490,"user_tz":-540,"elapsed":215725,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"1d0e736e-30cd-4365-8e54-878cee77eb7c"},"source":["display(df_train)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>intent</th>\n","      <th>label</th>\n","      <th>convert_ls</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>352</td>\n","      <td>뒷자리 746</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>뒷자리 746</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>370</td>\n","      <td>30분 뒤 도착</td>\n","      <td>소요시간선택</td>\n","      <td>5</td>\n","      <td>#분 뒤 도착</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>305</td>\n","      <td>가게 도착</td>\n","      <td>가게도착</td>\n","      <td>2</td>\n","      <td>가게 도착</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>90</td>\n","      <td>음식점에 왔어</td>\n","      <td>가게도착</td>\n","      <td>2</td>\n","      <td>음식점에 왔어</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>350</td>\n","      <td>주문 번호 7614</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>주문 번호  @</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>512</th>\n","      <td>129</td>\n","      <td>주문번호 9972</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>주문번호  @</td>\n","    </tr>\n","    <tr>\n","      <th>513</th>\n","      <td>144</td>\n","      <td>뒷자리 4334</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>뒷자리  @</td>\n","    </tr>\n","    <tr>\n","      <th>514</th>\n","      <td>72</td>\n","      <td>식당도착했어</td>\n","      <td>가게도착</td>\n","      <td>2</td>\n","      <td>식당 도착했어</td>\n","    </tr>\n","    <tr>\n","      <th>515</th>\n","      <td>235</td>\n","      <td>배달 완료 했어</td>\n","      <td>배달완료</td>\n","      <td>6</td>\n","      <td>배달 완료했어</td>\n","    </tr>\n","    <tr>\n","      <th>516</th>\n","      <td>37</td>\n","      <td>배달을 시작해주세요</td>\n","      <td>운행시작</td>\n","      <td>0</td>\n","      <td>배달을 시작해주세요</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>517 rows × 5 columns</p>\n","</div>"],"text/plain":["     Unnamed: 0        text  intent  label  convert_ls\n","0           352     뒷자리 746   영수증번호      4     뒷자리 746\n","1           370    30분 뒤 도착  소요시간선택      5     #분 뒤 도착\n","2           305       가게 도착    가게도착      2       가게 도착\n","3            90     음식점에 왔어    가게도착      2     음식점에 왔어\n","4           350  주문 번호 7614   영수증번호      4    주문 번호  @\n","..          ...         ...     ...    ...         ...\n","512         129   주문번호 9972   영수증번호      4     주문번호  @\n","513         144    뒷자리 4334   영수증번호      4      뒷자리  @\n","514          72      식당도착했어    가게도착      2     식당 도착했어\n","515         235    배달 완료 했어    배달완료      6     배달 완료했어\n","516          37  배달을 시작해주세요    운행시작      0  배달을 시작해주세요\n","\n","[517 rows x 5 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"paXKMAtHdoqM"},"source":["### train_data label 확인"]},{"cell_type":"code","metadata":{"id":"TsPwdwU0ZA9m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608623188105,"user_tz":-540,"elapsed":141109,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"2acef7d6-ee59-49b5-b1d0-319925c89f7e"},"source":["# label\n","pd.Series.unique(df_train['intent'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['영수증번호', '소요시간선택', '가게도착', '운행시작', '배달완료', '픽업완료', '가게전화', '소요시간'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtF5UFDo4xVl","executionInfo":{"status":"ok","timestamp":1608623191555,"user_tz":-540,"elapsed":144498,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"45480308-70b6-4fcd-a9e8-5b9e4598f24d"},"source":["intent = pd.unique(df_train['label'])\r\n","print(intent)\r\n","intent_count = intent.shape[0]\r\n","intent_count"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[4 5 2 0 6 3 1]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"markdown","metadata":{"id":"Ao3cGm9EyXty"},"source":["## 형태소로 분리 , df에 열로 추가"]},{"cell_type":"markdown","metadata":{"id":"4zgaRpQDdvXb"},"source":["### tokenizer 테스트"]},{"cell_type":"code","metadata":{"id":"S7SuQ-EFkqvL"},"source":["# okt_ls = []\n","# for i in range(len(text_data)):\n","#     okt_text = okt.pos(text_data['convert_ls'][i])\n","#     okt_ls = okt_ls + okt_text\n","\n","# pd.unique(okt_ls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIaU_-3zmT9X"},"source":["# kkma_ls = []\n","# for i in range(len(text_data)):\n","#     kkma_text = kkma.pos(text_data['convert_ls'][i])\n","#     kkma_ls = kkma_ls + kkma_text\n","\n","# pd.unique(kkma_ls)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kguP0dF4shL8"},"source":["### kkma가 더 적합해보임\n","\n","토큰화 / 불용어 제거 / token_len_max"]},{"cell_type":"code","metadata":{"id":"XL1lW7wrgI0S"},"source":["# kkma 토큰화 함수정의\n","\n","def kkma_tokenizer(input_df):\n","    \n","    # 명사, 동사, 기호, 일반부사()\n","    valid_pos = ['NNG','VV','SW','MAG']\n","    \n","    input_df['token_text'] = np.nan\n","\n","    for i in range(len(input_df)):\n","        \n","        # tokenize\n","        token_text = kkma.pos(input_df['convert_ls'][i])\n","        \n","        # 불용어 제거\n","        ls = []\n","        for token in token_text:\n","            if token[1] in valid_pos:\n","                ls.append(token[0])\n","            \n","            input_df['token_text'][i] = ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFPLS6YJhOjm"},"source":["kkma_tokenizer(df_train)\n","kkma_tokenizer(df_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJgn95TyX4JL"},"source":["## Interer encode"]},{"cell_type":"code","metadata":{"id":"l8hPLUpMGlj_"},"source":["# save & load word_to_index\n","\n","import pickle\n","\n","def save_obj(obj, name ):\n","    with open(word_to_index_save_path + name + '.pkl', 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ay8M8AIrrYeM"},"source":["# 토크나이저 최적화\n","from collections import Counter\n","\n","token_ls = []\n","vocab = Counter()\n","\n","for i in range(len(df_train)):\n","    \n","    token_ls = token_ls + df_train['token_text'][i]\n","\n","token_ls = pd.Series(token_ls, name = 'token')\n","\n","result = []\n","\n","# 형태소 개수 count: vocab\n","for word in token_ls:\n","    result.append(word) \n","    vocab[word] = vocab[word]+1 # 각 단어의 빈도를 Count한다\n","\n","# vocab안에서 정렬\n","vocab_sorted = sorted(vocab.items(), key=lambda x:x[1], reverse=True)\n","vocab_sorted\n","\n","# word to_index 만들기\n","word_to_index = {}\n","i = 0\n","for (word, frequency) in vocab_sorted:\n","    if frequency > 1: # 빈도수가 적은 단어는 제외\n","        i += 1\n","        word_to_index[word] = i\n","\n","\n","# 글자 묶음 크기\n","vocab_size = len(word_to_index)+1\n","\n","# word to index 저장\n","save_obj(word_to_index, 'word_to_index')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AW-dArz7sCs0"},"source":["## df의 정수인코딩 column 생성 및 반영 함수화\n","\n","def int_encode(df):\n","    tokenizer = Tokenizer()\n","    tokenizer.word_index = word_to_index\n","\n","    df['integer_encode'] = np.nan\n","    \n","    for i in range(len(df)):\n","        \n","        # integer encode\n","        seq = tokenizer.texts_to_sequences(df['token_text'])\n","\n","        df['integer_encode'] = seq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxuA9_Uwsyjl"},"source":["int_encode(df_train)\n","int_encode(df_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qb-q9UF4ef9C","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1608623191547,"user_tz":-540,"elapsed":144519,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"089b5a7f-4818-4bdf-b0d9-0cfb03203bd4"},"source":["df_train.to_excel('./df_train_sample.xlsx')\r\n","\r\n","df_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>intent</th>\n","      <th>label</th>\n","      <th>convert_ls</th>\n","      <th>token_text</th>\n","      <th>integer_encode</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>352</td>\n","      <td>뒷자리 746</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>뒷자리 746</td>\n","      <td>[뒷자리]</td>\n","      <td>[16]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>370</td>\n","      <td>30분 뒤 도착</td>\n","      <td>소요시간선택</td>\n","      <td>5</td>\n","      <td>#분 뒤 도착</td>\n","      <td>[#, 분, 뒤, 도착]</td>\n","      <td>[12, 13, 35, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>305</td>\n","      <td>가게 도착</td>\n","      <td>가게도착</td>\n","      <td>2</td>\n","      <td>가게 도착</td>\n","      <td>[가게, 도착]</td>\n","      <td>[8, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>90</td>\n","      <td>음식점에 왔어</td>\n","      <td>가게도착</td>\n","      <td>2</td>\n","      <td>음식점에 왔어</td>\n","      <td>[음식점, 오]</td>\n","      <td>[6, 20]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>350</td>\n","      <td>주문 번호 7614</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>주문 번호  @</td>\n","      <td>[주문, 번호, @]</td>\n","      <td>[18, 5, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>512</th>\n","      <td>129</td>\n","      <td>주문번호 9972</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>주문번호  @</td>\n","      <td>[주문, 번호, @]</td>\n","      <td>[18, 5, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>513</th>\n","      <td>144</td>\n","      <td>뒷자리 4334</td>\n","      <td>영수증번호</td>\n","      <td>4</td>\n","      <td>뒷자리  @</td>\n","      <td>[뒷자리, @]</td>\n","      <td>[16, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>514</th>\n","      <td>72</td>\n","      <td>식당도착했어</td>\n","      <td>가게도착</td>\n","      <td>2</td>\n","      <td>식당 도착했어</td>\n","      <td>[식당, 도착]</td>\n","      <td>[4, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>515</th>\n","      <td>235</td>\n","      <td>배달 완료 했어</td>\n","      <td>배달완료</td>\n","      <td>6</td>\n","      <td>배달 완료했어</td>\n","      <td>[배달, 완료]</td>\n","      <td>[3, 9]</td>\n","    </tr>\n","    <tr>\n","      <th>516</th>\n","      <td>37</td>\n","      <td>배달을 시작해주세요</td>\n","      <td>운행시작</td>\n","      <td>0</td>\n","      <td>배달을 시작해주세요</td>\n","      <td>[배달, 시작하]</td>\n","      <td>[3, 11]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>517 rows × 7 columns</p>\n","</div>"],"text/plain":["     Unnamed: 0        text  intent  ...  convert_ls     token_text   integer_encode\n","0           352     뒷자리 746   영수증번호  ...     뒷자리 746          [뒷자리]             [16]\n","1           370    30분 뒤 도착  소요시간선택  ...     #분 뒤 도착  [#, 분, 뒤, 도착]  [12, 13, 35, 1]\n","2           305       가게 도착    가게도착  ...       가게 도착       [가게, 도착]           [8, 1]\n","3            90     음식점에 왔어    가게도착  ...     음식점에 왔어       [음식점, 오]          [6, 20]\n","4           350  주문 번호 7614   영수증번호  ...    주문 번호  @    [주문, 번호, @]       [18, 5, 2]\n","..          ...         ...     ...  ...         ...            ...              ...\n","512         129   주문번호 9972   영수증번호  ...     주문번호  @    [주문, 번호, @]       [18, 5, 2]\n","513         144    뒷자리 4334   영수증번호  ...      뒷자리  @       [뒷자리, @]          [16, 2]\n","514          72      식당도착했어    가게도착  ...     식당 도착했어       [식당, 도착]           [4, 1]\n","515         235    배달 완료 했어    배달완료  ...     배달 완료했어       [배달, 완료]           [3, 9]\n","516          37  배달을 시작해주세요    운행시작  ...  배달을 시작해주세요      [배달, 시작하]          [3, 11]\n","\n","[517 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"2E3C6je4wsoo"},"source":["## Zero padding"]},{"cell_type":"code","metadata":{"id":"RBC9y3WjwwPu"},"source":["df_train_for_padded = df_train[['integer_encode','label']]\n","df_test_for_padded = df_test[['integer_encode','label']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zX_xFf0A7kRN"},"source":["max_len = 8\n","\n","train_padded = pad_sequences(df_train_for_padded['integer_encode'], maxlen=max_len)\n","test_padded = pad_sequences(df_test_for_padded['integer_encode'], maxlen=max_len)\n","train_padded.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jVj-tCR4w53H"},"source":["# train_test_split"]},{"cell_type":"code","metadata":{"id":"bqCLFUBOt3ZS"},"source":["x_data_train,x_data_valid, y_data_train, y_data_valid = \\\n","train_test_split(train_padded,\n","                 df_train['label'],\n","                 test_size=0.3,\n","                 random_state=0,\n","                 shuffle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zj_YeBJMw0mS"},"source":["# Modeling"]},{"cell_type":"code","metadata":{"id":"eUaP_oyKxIvD"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Embedding, SimpleRNN,Bidirectional\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpHHsdO49Ry_"},"source":["## label one_hot_encoding"]},{"cell_type":"code","metadata":{"id":"0vmPsON77eJa"},"source":["from tensorflow.keras.utils import to_categorical\n","\n","y_data_train_one_hot = to_categorical(y_data_train) # 훈련용 레이블의 원-핫 인코딩\n","y_data_valid_one_hot = to_categorical(y_data_valid) # valid용 레이블의 원-핫 인코딩"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WUOd7Z9UA_KO"},"source":["##call_back"]},{"cell_type":"code","metadata":{"id":"gIn2xC0cyTKE"},"source":["es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n","mc = ModelCheckpoint(model_save_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xW3tyDdlDMAV"},"source":["# predict"]},{"cell_type":"code","metadata":{"id":"yX0HXyNXaA08"},"source":["def pred(self,model):\r\n","    \r\n","    pred = model.predict(self)\r\n","    \r\n","    pred_result =[]\r\n","    for i in pred:\r\n","       \r\n","        if np.max(i) < 0.3:\r\n","            label = 99\r\n","        else:\r\n","            label = np.argmax(i)\r\n","        \r\n","        pred_result.append(label)\r\n","\r\n","    return pred_result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFPik0Q_BOxG"},"source":["## modeling"]},{"cell_type":"markdown","metadata":{"id":"Q5pbcZeDIg6n"},"source":["### Simple RNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wdePJfCIdoe","executionInfo":{"status":"ok","timestamp":1608623191557,"user_tz":-540,"elapsed":144493,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"3171c010-cdec-4033-88f2-446f85cae455"},"source":["RNN_model = Sequential()\r\n","RNN_model.add(Embedding(vocab_size, 120))\r\n","\r\n","RNN_model.add(SimpleRNN(128, input_shape=(8, vocab_size)))\r\n","RNN_model.add(Dense(intent_count, activation='softmax'))\r\n","RNN_model.summary()\r\n","\r\n","# hidden_size = 은닉 상태의 크기를 정의. 메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기(output_dim)와도 동일. RNN의 용량(capacity)을 늘린다고 보면 되며, 중소형 모델의 경우 보통 128, 256, 512, 1024 등의 값을 가진다.\r\n","# timesteps = 입력 시퀀스의 길이(input_length)라고 표현하기도 함. 시점의 수.\r\n","# input_dim = 입력의 크기\r\n","RNN_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 120)         6000      \n","_________________________________________________________________\n","simple_rnn (SimpleRNN)       (None, 128)               31872     \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 903       \n","=================================================================\n","Total params: 38,775\n","Trainable params: 38,775\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XYFIYvKv43jt","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1608623198861,"user_tz":-540,"elapsed":151791,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"39a22608-e433-4492-eef1-6f1beafef691"},"source":["history = RNN_model.fit(x_data_train,\n","                    y_data_train_one_hot,\n","                    batch_size = 20,\n","                    epochs=20,\n","                    callbacks=[es,mc],\n","                    \n","                    validation_data=(x_data_valid,\n","                                     y_data_valid_one_hot))\n","\n","\n","# 학습 정확성 값과 검증 정확성 값을 플롯팅 합니다. \n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Valid'], loc='upper left')\n","plt.show()\n","\n","# 학습 손실 값과 검증 손실 값을 플롯팅 합니다.\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Valid'], loc='upper left')\n","plt.show()\n","\n","import sklearn\n","y_val_series = pd.Series(y_data_valid)\n","print(sklearn.metrics.classification_report(y_val_series,pred(x_data_valid,RNN_model),digits=4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","19/19 [==============================] - 1s 28ms/step - loss: 1.8001 - acc: 0.2853 - val_loss: 1.3270 - val_acc: 0.6090\n","\n","Epoch 00001: val_acc improved from -inf to 0.60897, saving model to /content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5\n","Epoch 2/20\n","19/19 [==============================] - 0s 16ms/step - loss: 1.2274 - acc: 0.6295 - val_loss: 0.7498 - val_acc: 0.8654\n","\n","Epoch 00002: val_acc improved from 0.60897 to 0.86538, saving model to /content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5\n","Epoch 3/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.6896 - acc: 0.8994 - val_loss: 0.3368 - val_acc: 0.9615\n","\n","Epoch 00003: val_acc improved from 0.86538 to 0.96154, saving model to /content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5\n","Epoch 4/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.3401 - acc: 0.9605 - val_loss: 0.1810 - val_acc: 0.9744\n","\n","Epoch 00004: val_acc improved from 0.96154 to 0.97436, saving model to /content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5\n","Epoch 5/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.1611 - acc: 0.9870 - val_loss: 0.1239 - val_acc: 0.9744\n","\n","Epoch 00005: val_acc did not improve from 0.97436\n","Epoch 6/20\n","19/19 [==============================] - 0s 16ms/step - loss: 0.1051 - acc: 0.9822 - val_loss: 0.1021 - val_acc: 0.9744\n","\n","Epoch 00006: val_acc did not improve from 0.97436\n","Epoch 7/20\n","19/19 [==============================] - 0s 16ms/step - loss: 0.0874 - acc: 0.9814 - val_loss: 0.0885 - val_acc: 0.9872\n","\n","Epoch 00007: val_acc improved from 0.97436 to 0.98718, saving model to /content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5\n","Epoch 8/20\n","19/19 [==============================] - 0s 16ms/step - loss: 0.0930 - acc: 0.9792 - val_loss: 0.0838 - val_acc: 0.9872\n","\n","Epoch 00008: val_acc did not improve from 0.98718\n","Epoch 9/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.0618 - acc: 0.9925 - val_loss: 0.0762 - val_acc: 0.9744\n","\n","Epoch 00009: val_acc did not improve from 0.98718\n","Epoch 10/20\n","19/19 [==============================] - 0s 16ms/step - loss: 0.0791 - acc: 0.9772 - val_loss: 0.0767 - val_acc: 0.9808\n","\n","Epoch 00010: val_acc did not improve from 0.98718\n","Epoch 11/20\n","19/19 [==============================] - 0s 16ms/step - loss: 0.0452 - acc: 0.9917 - val_loss: 0.0715 - val_acc: 0.9872\n","\n","Epoch 00011: val_acc did not improve from 0.98718\n","Epoch 12/20\n","19/19 [==============================] - 0s 16ms/step - loss: 0.0343 - acc: 0.9944 - val_loss: 0.0712 - val_acc: 0.9744\n","\n","Epoch 00012: val_acc did not improve from 0.98718\n","Epoch 13/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.0463 - acc: 0.9900 - val_loss: 0.0657 - val_acc: 0.9872\n","\n","Epoch 00013: val_acc did not improve from 0.98718\n","Epoch 14/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.0343 - acc: 0.9914 - val_loss: 0.0658 - val_acc: 0.9744\n","\n","Epoch 00014: val_acc did not improve from 0.98718\n","Epoch 15/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.0350 - acc: 0.9926 - val_loss: 0.0694 - val_acc: 0.9744\n","\n","Epoch 00015: val_acc did not improve from 0.98718\n","Epoch 16/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.0254 - acc: 0.9952 - val_loss: 0.0669 - val_acc: 0.9744\n","\n","Epoch 00016: val_acc did not improve from 0.98718\n","Epoch 17/20\n","19/19 [==============================] - 0s 15ms/step - loss: 0.0206 - acc: 0.9980 - val_loss: 0.0685 - val_acc: 0.9744\n","\n","Epoch 00017: val_acc did not improve from 0.98718\n","Epoch 00017: early stopping\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70e39fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     0.9737    1.0000    0.9867        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    0.9091    0.9524        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9633    0.9649    0.9610       156\n","weighted avg     0.9790    0.9744    0.9750       156\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vCSYTeRrIehT"},"source":["### LSTM"]},{"cell_type":"code","metadata":{"id":"bv6cg4lm_lI3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608623199180,"user_tz":-540,"elapsed":152101,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"3b0055c2-e7fd-402a-c1ce-501f276ad757"},"source":["LSTM_model = Sequential()\n","LSTM_model.add(Embedding(vocab_size, 120))\n","LSTM_model.add(LSTM(120))\n","LSTM_model.add(Dense(intent_count, activation='softmax'))\n","LSTM_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 120)         6000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 120)               115680    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 847       \n","=================================================================\n","Total params: 122,527\n","Trainable params: 122,527\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9H5SJ24Ap5an"},"source":["Adam_optimizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"e1iVZMA4MdGl","executionInfo":{"status":"ok","timestamp":1608623205994,"user_tz":-540,"elapsed":158907,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"45a4a408-97e3-4e62-f03a-286011a7e7e8"},"source":["LSTM_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\r\n","\r\n","history = LSTM_model.fit(x_data_train,\r\n","                    y_data_train_one_hot,\r\n","                    batch_size = 20,\r\n","                    epochs=20,\r\n","                    callbacks=[es, mc],\r\n","                    \r\n","                    validation_data=(x_data_valid,\r\n","                                     y_data_valid_one_hot))\r\n","\r\n","\r\n","# 학습 정확성 값과 검증 정확성 값을 플롯팅 합니다. \r\n","plt.plot(history.history['acc'])\r\n","plt.plot(history.history['val_acc'])\r\n","plt.title('Model accuracy')\r\n","plt.ylabel('Accuracy')\r\n","plt.xlabel('Epoch')\r\n","plt.legend(['Train', 'Valid'], loc='upper left')\r\n","plt.show()\r\n","\r\n","# 학습 손실 값과 검증 손실 값을 플롯팅 합니다.\r\n","plt.plot(history.history['loss'])\r\n","plt.plot(history.history['val_loss'])\r\n","plt.title('Model loss')\r\n","plt.ylabel('Loss')\r\n","plt.xlabel('Epoch')\r\n","plt.legend(['Train', 'Valid'], loc='upper left')\r\n","plt.show()\r\n","\r\n","import sklearn\r\n","y_val_series = pd.Series(y_data_valid)\r\n","print(sklearn.metrics.classification_report(y_val_series,pred(x_data_valid,LSTM_model),digits=4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","19/19 [==============================] - 3s 34ms/step - loss: 1.9049 - acc: 0.2842 - val_loss: 1.7230 - val_acc: 0.2949\n","\n","Epoch 00001: val_acc did not improve from 0.98718\n","Epoch 2/20\n","19/19 [==============================] - 0s 9ms/step - loss: 1.7091 - acc: 0.2793 - val_loss: 1.4187 - val_acc: 0.6282\n","\n","Epoch 00002: val_acc did not improve from 0.98718\n","Epoch 3/20\n","19/19 [==============================] - 0s 8ms/step - loss: 1.3432 - acc: 0.6011 - val_loss: 0.7537 - val_acc: 0.7308\n","\n","Epoch 00003: val_acc did not improve from 0.98718\n","Epoch 4/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.7470 - acc: 0.8035 - val_loss: 0.2991 - val_acc: 0.9295\n","\n","Epoch 00004: val_acc did not improve from 0.98718\n","Epoch 5/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.2534 - acc: 0.9439 - val_loss: 0.1757 - val_acc: 0.9744\n","\n","Epoch 00005: val_acc did not improve from 0.98718\n","Epoch 6/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.1880 - acc: 0.9672 - val_loss: 0.0950 - val_acc: 0.9808\n","\n","Epoch 00006: val_acc did not improve from 0.98718\n","Epoch 7/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.1360 - acc: 0.9738 - val_loss: 0.0826 - val_acc: 0.9872\n","\n","Epoch 00007: val_acc did not improve from 0.98718\n","Epoch 8/20\n","19/19 [==============================] - 0s 9ms/step - loss: 0.0747 - acc: 0.9803 - val_loss: 0.0539 - val_acc: 0.9936\n","\n","Epoch 00008: val_acc improved from 0.98718 to 0.99359, saving model to /content/drive/MyDrive/Project/Hel_ri_celus (AI voice_bot for delivery_riders)/Chatbot/model/best_model.h5\n","Epoch 9/20\n","19/19 [==============================] - 0s 9ms/step - loss: 0.0568 - acc: 0.9877 - val_loss: 0.0571 - val_acc: 0.9808\n","\n","Epoch 00009: val_acc did not improve from 0.99359\n","Epoch 10/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0472 - acc: 0.9913 - val_loss: 0.0441 - val_acc: 0.9808\n","\n","Epoch 00010: val_acc did not improve from 0.99359\n","Epoch 11/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0386 - acc: 0.9904 - val_loss: 0.0545 - val_acc: 0.9808\n","\n","Epoch 00011: val_acc did not improve from 0.99359\n","Epoch 12/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0916 - acc: 0.9787 - val_loss: 0.0645 - val_acc: 0.9872\n","\n","Epoch 00012: val_acc did not improve from 0.99359\n","Epoch 13/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0538 - acc: 0.9875 - val_loss: 0.0492 - val_acc: 0.9808\n","\n","Epoch 00013: val_acc did not improve from 0.99359\n","Epoch 14/20\n","19/19 [==============================] - 0s 9ms/step - loss: 0.0264 - acc: 0.9975 - val_loss: 0.0434 - val_acc: 0.9808\n","\n","Epoch 00014: val_acc did not improve from 0.99359\n","Epoch 15/20\n","19/19 [==============================] - 0s 9ms/step - loss: 0.0280 - acc: 0.9917 - val_loss: 0.0409 - val_acc: 0.9808\n","\n","Epoch 00015: val_acc did not improve from 0.99359\n","Epoch 16/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0241 - acc: 0.9954 - val_loss: 0.0588 - val_acc: 0.9679\n","\n","Epoch 00016: val_acc did not improve from 0.99359\n","Epoch 17/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0372 - acc: 0.9837 - val_loss: 0.0348 - val_acc: 0.9936\n","\n","Epoch 00017: val_acc did not improve from 0.99359\n","Epoch 18/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9937 - val_loss: 0.0587 - val_acc: 0.9744\n","\n","Epoch 00018: val_acc did not improve from 0.99359\n","Epoch 19/20\n","19/19 [==============================] - 0s 9ms/step - loss: 0.0920 - acc: 0.9502 - val_loss: 0.0496 - val_acc: 0.9936\n","\n","Epoch 00019: val_acc did not improve from 0.99359\n","Epoch 20/20\n","19/19 [==============================] - 0s 8ms/step - loss: 0.0339 - acc: 0.9964 - val_loss: 0.0441 - val_acc: 0.9808\n","\n","Epoch 00020: val_acc did not improve from 0.99359\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcZb348c83k31t1m5Jmxa6UAotbdhkp8Ati1QWpb2Xn+CGekVBRS+gIqLcq1fcUK5XXEC8StmxQhHKUgFpoSm0dElL05C0SZfsS5Nm//7+OCftJJkkkzSzJPN9v17zmjnnPGfmO5PJ+c55nuc8j6gqxhhjIldUqAMwxhgTWpYIjDEmwlkiMMaYCGeJwBhjIpwlAmOMiXCWCIwxJsJZIjARQUTyRURFJNqPsjeKyJvBiMuYcGCJwIQdESkVkXYRyeqz/j33YJ4fmsiMGZ8sEZhw9SGwomdBRE4CEkMXTnjw54zGmOGyRGDC1Z+AT3ot3wA84l1ARNJE5BERqRKRMhH5tohEuds8InKfiFSLSAlwuY99fy8i+0WkQkR+ICIefwITkSdE5ICINIjI6yJyote2BBH5iRtPg4i8KSIJ7razReQtEakXkb0icqO7fq2IfNbrOXpVTblnQV8SkV3ALnfdL9znaBSRjSJyjld5j4jcKSK7RaTJ3Z4nIg+IyE/6vJdVIvJVf963Gb8sEZhwtR5IFZET3AP0cuD/+pT5JZAGzATOw0kcn3K3fQ64AjgFKACu7bPvw0AncLxb5hLgs/jnBWAWkAO8C/zZa9t9wGLgI0AG8E2gW0Smu/v9EsgGFgKb/Hw9gI8BpwPz3OUN7nNkAH8BnhCReHfb13DOpi4DUoFPAy3AH4EVXskyC7jI3d9EMlW1m93C6gaU4hygvg38F7AUWANEAwrkAx6gHZjntd/ngbXu41eBL3htu8TdNxqYCLQBCV7bVwCvuY9vBN70M9YJ7vOm4fywOgws8FHuDuCZAZ5jLfBZr+Ver+8+/4VDxFHX87rATmDZAOWKgIvdxzcDq0P997Zb6G9W32jC2Z+A14EZ9KkWArKAGKDMa10ZMNV9PAXY22dbj+nuvvtFpGddVJ/yPrlnJ/cCH8f5Zd/tFU8cEA/s9rFr3gDr/dUrNhG5DfgMzvtUnF/+PY3rg73WH4HrcRLr9cAvjiEmM05Y1ZAJW6pahtNofBnwdJ/N1UAHzkG9xzSgwn28H+eA6L2tx16cM4IsVZ3g3lJV9USG9q/AMpwzljScsxMAcWNqBY7zsd/eAdYDNNO7IXySjzJHhgl22wO+CXwCSFfVCUCDG8NQr/V/wDIRWQCcADw7QDkTQSwRmHD3GZxqkWbvlaraBTwO3CsiKW4d/Nc42o7wOPAVEckVkXTgdq999wMvAT8RkVQRiRKR40TkPD/iScFJIjU4B+//9HrebuAPwE9FZIrbaHumiMThtCNcJCKfEJFoEckUkYXurpuAq0UkUUSOd9/zUDF0AlVAtIjchXNG0ON3wPdFZJY4ThaRTDfGcpz2hT8BT6nqYT/esxnnLBGYsKaqu1W1cIDNX8b5NV0CvInT6PkHd9tvgReBzTgNun3PKD4JxALbcerXnwQm+xHSIzjVTBXuvuv7bL8N2IJzsK0FfgREqeoenDObr7vrNwEL3H1+htPecRCn6ubPDO5F4O/AB24srfSuOvopTiJ8CWgEfg8keG3/I3ASTjIwBlG1iWmMiSQici7OmdN0tQOAwc4IjIkoIhID3AL8zpKA6WGJwJgIISInAPU4VWA/D3E4JoxY1ZAxxkQ4OyMwxpgIN+YuKMvKytL8/PxQh2GMMWPKxo0bq1U129e2MZcI8vPzKSwcqDehMcYYX0SkbKBtVjVkjDERzhKBMcZEOEsExhgT4QLWRiAif8AZD75SVef72C44Ix9ehjNW+o2q+u5IXqujo4Py8nJaW1uPJeQxIT4+ntzcXGJiYkIdijFmnAhkY/HDwK/oP3xwj0txJveYhTPhxq/d+2ErLy8nJSWF/Px8vIYVHndUlZqaGsrLy5kxY0aowzHGjBMBqxpS1ddxBtcayDLgEXWsByaIiD+DfvXT2tpKZmbmuE4CACJCZmZmRJz5GGOCJ5RtBFPpPWJiOUcnFelFRG4SkUIRKayqqvL5ZOM9CfSIlPdpjAmeMXEdgao+CDwIUFBQYGNiRAJVOFwHjRXQUAGN5dDaAJNOhtwCSEgPdYRmLGmogKK/waT5MO0jEBXk38CVO6D4ZUibCnmnQ+qUYT9FfUs7aQkxAfkxGMpEUEHvGaRyOTq71JhSU1PDkiVLADhw4AAej4fsbOcCvnfeeYfY2NgB9y0sLOSRRx7h/vvvD0qsYaOt6egBvqGi9wG/Z7mjZeD9s+dC3mnOP1Xe6ZB5PITZ2ZKqcriji+a2LprbOuno6mbKhASS4oL/b9fc1sneuhYaD3fS3N5Jc1snLW1dHGrrpKW9k0NtXe69s77Z63FPmcMdXcTHeEiKjSYpzkNibDTJcc5jZ100iXEekmOjSYyLJjnOQ1Jc9NFtsR6ijuFvJAIZSbFkJsUS7fHzQH5gC7z1K9j6JHR3OuuSJ8GJH4MTr4bcU3slBVWltrmdD6ubj9xKa5opqWqmsqmNq0+ZytcumU1irB9/w+pi2PYMbHsaKrf33paW5/X9PQ0mzgeP7w4gqsoTG8u59/ki7rpiHtcszvXvvQ9DKBPBKuBmEVmJ00jc4M4cNeZkZmayadMmAO6++26Sk5O57bbbjmzv7OwkOtr3R11QUEBBQUFQ4gyajsPQuA8ayn0f4BsqoK2hz06CpkyiK3kKHRlzaJ16Ps3xE2mKm0RDTDa1nmwOSwLT23cxtel90mvfI277KuRdty9CQob7j+X+c01ZBLGJ/UIbjvbObqoOtVHZ2EplUxvVh9pobnMOms3eB9A296DZ7qx3DrTOwdTXmI45KXHkZyUxMyuJ/KwkZri3aRmJxMd4oLPN+fz6fnbNVZCUBalTIS3XvZ/q3EfH0drRxd7aFkqqmyl1D2I9jyub2gZ9r7GeKBLjjh7kk+Kcg3xOStyRg3lCrIdWr8TWk1CqmtqOPG5u76K9s3vQ1zpWUQIZSXHkpMSRk+rep8QfeZydHEde3Xoy3/8Nng/XQkwSnPpZWHwjHNwG255BCx9C3v5fWhImUZSxhLXR5/D6oVxKalpoau088lrRUcK0jETys5LIz0zid29+yN+3HeDeq07ivNk+RmuoK4WtTzsH/wNbnHXTzoRLfwxzL4NDB2HvO7D3bShbB1ufcsrEJMLUxUe/v7mnQmIGpdXN3PnMFt7aXUPB9HQW5KUF5DMN2OijIvIocD7OhNoHge/iTBiOqv6v2330V8BSnO6jnxpkJqojCgoKtO8QE0VFRZxwwgmjGv9I9SSCrVu3Eh8fz3vvvcdZZ53F8uXLueWWW2htbSUhIYGHHnqIOXPmsHbtWu677z6ee+457r77bvbs2UNJSQl79uzh1ltv5Stf+Uq/1wjp++1sh6Z9Xgf1cq+Dlnvgb6npt1tzdDq10dnURGVTGZXFAc2gojuTvV3plHakU9qRSkvn8E7Xo6SbRYnVnBVXwiL5gLkd25nYvgeAbonmcOY8uqeeStzMM4nNP9M5eAIt7Z1UNrZR2dRGZVNrr8dVTW3ucit1LR0DvnZSrMf91ev80nUOlkcPoM6vZadMz7ZoTxQVNY3U7t/D4ZoyuuvLSW47yGSpZYrUMFlqyI2qJYO+SRI0IR1Jykabq5DDdf2215JGeXcG+zWTfZrJfs3gUNxEJC2XxKzppE+exrSsVCYkxDq/2t24e2KNjR69qpKOrm7nTKInObQNnhj91a1KTXM7VW5i9v77VR9qw6OdfDTqLT4X/TwnRO3loE5gpVzG2pQrSEzLJD0xloONrXxY3UzroXoujtrIFZ71nBP1PrHSxUHPZHZmLqF2xhWk5S9iRnYyU9MTiPE6+3jnw1ruePp9dlc187GFU/jOFfPI7KpyfvlvfRr2uT3gpxbA/Kth3secZD2QhnInKfQkh/3vg3YBUJeYzyuH8tkicyg4ZymXX3AeUR7PiD8/Edmoqj5/dQbsjEBVVwyxXYEvjfbrfu9v29i+r3FUn3PelFS++1F/5jXvrby8nLfeeguPx0NjYyNvvPEG0dHRvPzyy9x555089dRT/fbZsWMHr732Gk1NTcyZM4cvfvGLwbtmoLsLmg70Pqh7/SLtbihHmqsQev83t0QlUxWVxX7NpKzzFPZ0ZrBfM9iPc1A6oBmoJ56s5FiSY6K9qgucX6CL46I5p0+VQmJs7yqHpLhooqOE2ub2Pgfw6WxtnM+rTW1UdrTS2V7DyexicdQHLD64iwVV/0fs5t8DUEcahzWGbpwv/hT3Bs6s7x6BqCjBEyVEeQRPmuARObLOI4KIU0UheFVxdOH8lBmkJssp1wHNlaBev5hjoCsmmeb4idR6JrJD51HaMYGillRK2iew3z2od7QnkNMdR2VTGzHdh5kstUyWGmbG1DM3qZEZMfVMkRryu6pIat2Bp+MQdONMwlkHFEdBUs6A1Q+jKQZIc2+9SJRTBXLkrG0hxCT0f4LhOlxPd+HD6Nu/xnPoAIfSZvH29O9TmLKE6mYlp8lJHOV1DUxMiWfJ3InkZ81kRtY55GUn0Z3QDrtfYOLWp5lY8ihU/h8UHw8nXuVUH02cd+SlTpuRwepbzuHhv6+n8u2H2LtjPZnsdDZOXgAXfc/ZL326f7Gn5Tq3+dc4y+3NFG96gzdefZ68pi0sjXmXa7vXwpu/gcI0WPojWDjooXVExkRj8Vj18Y9/HI+bwRsaGrjhhhvYtWsXIkJHh+9fm5dffjlxcXHExcWRk5PDwYMHyc0dpTrB5mqo3zNwdU3T/iO/Ro6ISaIrZQrFbWlsapjHfjLcX5zOQb4hJofkpDRyUuLJdk/NJ6bGc1yf0/XRauTKyxi8uqerW91k4fzzP1/fTPeBrSRVbSSj6QMSPEp8rIeEGA/xMR7iY6JIiPEQ64kKfI8siYKUSf2qdjzxaaTizD6fD3yE3nXVPdU7+xtamZwW36taKTMp1nfcrQ19ztoqnCSvga22GVRnK+zbBDufd5ajYpyDZ089ed7pkDqMHuT1e2D9r+HdR4hqPwQzzoNlD5B8/BJOFxneRUmnXO/cmmugaJVTtfPGT+D1HzvtUSdeDbMuhoqNxG17hs+XvQUepTR6Bj8+/AkO5F3KV679F6ZnJg3nVXtpbuvkvpdK+eNbXWSnLOOe5d8ied5EqCl2zxrehvT8ET//YMZdIhjJL/dASUo6+qX4zne+wwUXXMAzzzxDaWkp559/vs994uLijjz2eDx0dnb6LDcsne3w99uh8Pe913vinN4LabmQf/bR+mb3IKWpU/nrjmbueb6IxsMd3PCRfBbkTeCMlJ762XiSQ9DwORhPlJCdEkd2ShxHvwkzgI+GLqgREBEyk+PITI6jID9j+E8Qn+bcvH7Nho3m6qNVIXvfcb6X6x9wtqVN89GI2uc7tu89eOuXsO1Z5/Rs/jVw5s0w+eRjjy0pEwo+5dyaDjpJYevTsPa/YO1/OmWy5sD5t8OJVzEtczaT3tnDH1/YwfM/f51bL5rNZ8+e4X9jtuu1HZV8+9mt7Gs4zPWnT+cbS+eQGu+evWXNcm6nXH/s728A4fVfPI41NDQwdapTV/jwww8H74Ub98Pjn4Tyd+DUz8HM890Dfq7T8DjAr+C9tS18a+VWXv+gioV5E/jhNScxd1Jq8OI241dSltNwOvcyZ7mz3WlY7fnVW/ZPp5cPeDWing4ZM2Hzo1D6BsSmwJn/Dqd/4Ujbz6hLmQinfc65Ne6Dkn84ySZn3pH/myjg/50xnYtPmMhdf93KD1/YwapN+/jRNSdzUu7QDbtVTW3c89x2/rZ5H7NyknnyC2eyePoIEv8xskQQJN/85je54YYb+MEPfsDll18enBctWwdP3ABth+Dah5zGqyF0dnXz0D9L+emaD4gSuPuj8/h/Z+bjiQqvrplmHImOhdzFzu3Mf3euIenbiPrmz5xqy9SpcMkPYNEnnTOeYEmdMmjd/KS0eB78ZAF/37qfu/66jWUPvMmnz5oxYFdT7y6hh9u7+OpFs/nC+TOJix55Y/CxGHNzFod7r6FgGPL9qsKG3znVQROmwXV/9quKYGtFA3c8vYUtFQ0smZvD9z82nykTRqExz5hj1d7s1JXnzAtKg/exaGzt4Ecv7ODPb+9h6oQE7r1qPufPyTmy/cPqZu58egvrSmo4LT+D/7z6JI7PSQ54XCHpNWRCpOMwPPc12PwXmL0UrvoNJEwYdJfD7V387OUP+P2bH5KeGMsD/7qIy06aZMNZmPARm+Q0LI8BqfEx3HvVSXzslKnc/tT73PjQBpYtnMKdl53AkxvLuf+VXcRGR/GfV53E8lPziAqDs21LBONJ/R547HrYvxnOux3O+48hL6V/Y1cVdz6zhb21h1l+ah53XHoCaYnh/YvLmLHg1Hynq+n/vLab/1lbzKrN+1CFS+dP4ntXnkhOanyoQzzCEsF4UbIWnviUcxn9isdgztJBi9c2t/OD57bz9HsVzMxKYuVNZ3DGzMzgxGpMhIiL9vDVi2dzxcmT+fXa3SydP4lLTpwU6rD6sUQw1qnCW/fDy3dD1mxY/hfIPG6Q4sqzmyr4/nNOl9AvX3g8X7rgeGdoA2NMQMyamMJPr1sY6jAGZIlgLGs7BKtudi5vn7cMlv0PxA3c6LS3toU7n9nCG7uqOWXaBH549cnMmZQSxICNMeHIEsFYVbPbaQ+o2uFc1n7WLYOOvvnmrmo++8gGPCJ878oTuf6M6dYl1BgD2OT1o+KCCy7gxRdf7LXu5z//OV/84hd9lj///PPp6QJ72WWXUV9f36/M3XffzX333ef7BTsOw4MXOENCXP8UnH3roEmg5lAbX318E3npiaz52nnc8BG7LsAYc5QlglGwYsUKVq5c2WvdypUrWbFi6MGhVq9ezYQJg3fvPELVOfg3VzmDWt30DzjuwiF2Ue54egsNLR3cv+IUuy7AGNOPJYJRcO211/L888/T3t4OQGlpKfv27ePRRx+loKCAE088ke9+97s+983Pz6e6uhqAe++9l9mzZ3P22Wezc+fO3gW7u6C2xBk4LDYJPvOSXyMcPrZhLy9tP8g3l87hhMk2RIQxpr/x10bwwu1HJ4QYLZNOgkt/OODmjIwMTjvtNF544QWWLVvGypUr+cQnPsGdd95JRkYGXV1dLFmyhPfff5+TT/Y9MNbGjRtZuXIlmzZtorOzk0WLFrF48eKjBZqroa3RGSOoodqv4Xs/rG7me3/bzlnHZ/Lps2YM+20bYyKDnRGMEu/qoZ5qoccff5xFixZxyimnsG3bNrZv3z7g/m+88QZXXXUViYmJpKamcuWVV/Yu0NYI0QmQ7GNWJB86urq59bFNxEZHcd/HF4TF1YvGmPA0/s4IBvnlHkjLli3jq1/9Ku+++y4tLS1kZGRw3333sWHDBtLT07nxxhtpbW0d2ZN3d0L7IUie6Pcuv3y1mM1763ngXxcxOc3aBYwxA7MzglGSnJzMBRdcwKc//WlWrFhBY2MjSUlJpKWlcfDgQV544YVB9z/33HN59tlnOXz4ME1NTfztb387urHtkHMf518d/8ayWn716i6uWZTL5ScPY6IPY0xEGn9nBCG0YsUKrrrqKlauXMncuXM55ZRTmDt3Lnl5eZx11lmD7rto0SKuu+46FixYQE5ODqeeeurRjW2NIB6nkXgIh9o6ufWxTUxNT+DuK8NwUhJjTNixYajDnSoc3OYkgQynwXew93vbE5t5+t1yHv/8mSOb2coYMy4NNgx1QKuGRGSpiOwUkWIRud3H9uki8oqIvC8ia0UkQFMNjWGdrdDd4Ve10Oot+3lyYzlfuuB4SwLGGL8FLBGIiAd4ALgUmAesEJG+dRX3AY+o6snAPcB/BSqeMau10bmPH3xMoAMNrdz5zBYW5KbxlSWzghCYMWa8COQZwWlAsaqWqGo7sBJY1qfMPOBV9/FrPrb7baxVcfmtp9uoJxbw/T67u5XbnthMW0c3P7tuITHDnDjbGBPZAnnEmArs9Voud9d52wz0TKR7FZAiIv0GxReRm0SkUEQKq6qq+r1QfHw8NTU14y8ZdHc5U/S5ZwOqSk1NDfHxvSe0eOitUt4sruauj85jZnbgp7wzxowvoe41dBvwKxG5EXgdqAC6+hZS1QeBB8FpLO67PTc3l/LycnwliTGto8W5ojhZIdqpIoqPjyc392hTyo4Djfzo7zu4eN5Elp+aF6pIjTFjWCATQQXgfWTKddcdoar7cM8IRCQZuEZV+w/FOYSYmBhmzBiHQyis+ooz18A3S3xO2N3a0cWtKzeRGh/DD68+yeYYNsaMSCCrhjYAs0RkhojEAsuBVd4FRCRLRHpiuAP4QwDjGVtUofhlmHmezyQA8OMXd7LjQBM//vjJZCbHBTlAY8x4EbBEoKqdwM3Ai0AR8LiqbhORe0SkZyCd84GdIvIBMBG4N1DxjDmVRdBYAcdf7HPzm7uq+f2bH3LDmdO5YE5OkIMzxownAW0jUNXVwOo+6+7yevwk8GQgYxizitc498df1G9TXXM7X39iE8fnJHP7peP0QjpjTNBYP8NwtWsN5JwIab07Wqkqdz6zhdrmdn5+3UISYm3SeWPMsbFEEI7ammDPepjV/2zgqXcreGHrAb5+yRzmT00LQXDGmPHGEkE4KvmHM6xEn/aBPTUtfPevWzl9RgafO2dmiIIzxow3lgjCUfEaiE2BaWccWdXZ1c1XH99EVJTw0+sW2uTzxphRE+oLykxfqrCrf7fRv27ax8ayOn6xfCFTbQJ6Y8wosjOCcFO1AxrL+/UWemt3DZlJsVy5YEqIAjPGjFeWCMLNLrfb6Kze7QOFZbUU5Kfb1cPGmFFniSDcFK+B7BMg7eh4QpVNrZTVtFAw3eYYMMaMPksE4aStCcrW9es2urG0DoCC/PRQRGWMGecsEYSTD1/32W20sKyOuOgoTpxi1w0YY0afJYJwsmsNxCbDtDN7rS4srWVh3gRio+3PZYwZfXZkCRc9o43OOA+iY4+sbmnvZNu+RqsWMsYEjCWCcFH9ATTs7dc+sGlvPZ3dapPRG2MCxhJBuOjpNtqnfWBjaR0isGianREYYwLDEkG4KF4D2XNhQu/pJjeU1TFnYgppCb4npzHGmGNliSActB2Csrf6XU3c1a28V1bH4ul2NmCMCRxLBOGg9A3oau93NfHOA000tXVyqrUPGGMCyBJBONi1BmKS+nUb3VhWC2BnBMaYgLJEEGqqTvvAzPMguvcE9BtK65iYGkduuo02aowJnIAmAhFZKiI7RaRYRG73sX2aiLwmIu+JyPsiclkg4wlL1bugfg8cv6Tfpo1ldRTkZ9hAc8aYgApYIhARD/AAcCkwD1ghIvP6FPs28LiqngIsB/4nUPGErWLf3Ub31R+mov4wBVYtZIwJsECeEZwGFKtqiaq2AyuBZX3KKJDqPk4D9gUwnvC0aw1kzYb06b1WF5Y5A81ZQ7ExJtACmQimAnu9lsvddd7uBq4XkXJgNfBlX08kIjeJSKGIFFZVVQUi1tBob4ayf/Y7GwBnfKHEWA9zJ6WEIDBjTCQJdWPxCuBhVc0FLgP+JCL9YlLVB1W1QFULsrOzgx5kwHzY0230on6bCkvrWDQtnWhPqP9ExpjxLpBHmQrA+zLZXHedt88AjwOo6jogHsgKYEzhpXgNxCTC9LN6rW5q7WDHgUbrNmqMCYpAJoINwCwRmSEisTiNwav6lNkDLAEQkRNwEsE4qvsZhKrTPjDj3H7dRt/bU0+3WvuAMSY4ApYIVLUTuBl4ESjC6R20TUTuEZEr3WJfBz4nIpuBR4EbVVUDFVNYqSmG+rJ+w0qA01AcJbBw2oQQBGaMiTTRgXxyVV2N0wjsve4ur8fbgbP67hcRBpikHpyG4nlTUkmOC+ifxxhjgNA3Fkeu4jWQOQvS83ut7ujqZtPeepuo3hgTNJYIQqG9BUr/6fNsoGh/Iy3tXTYjmTEmaCwRhELpG9DV5rt9oNS5kMzOCIwxwWKJIBSKX4bohH7dRgEKy2rJTU9gUlp8CAIzxkQiSwShsGsNzDgHYnof7FWVwtI6G1/IGBNUlgiCrWY31H3oc1iJvbWHqWxqY7FdP2CMCSJLBMF2pNuor+sHnIloTrWGYmNMEFkiCLbiNZBxHGTM7LdpQ2kdKfHRzM6xgeaMMcFjiSCYOg5D6Zs+u42CMzXl4unpREXZRDTGmOCxRBBMpW9CZ6vP9oH6lnY+OHjIGoqNMUFniSCYdq2B6HjI799t9N097vUD1lBsjAkySwTBVLwG8s+BmP6T0W8orSM6SliQawPNGWOCyxJBsNTshtqSgdsHSuuYPzWNhFhPkAMzxkQ6SwTBsvUp597HsBJtnV1sLq+39gFjTEhYIgiGQ1Xwz/thzmWQeVy/zVsrGmnr7Lb2AWNMSFgiCIZ//BA6WuCi7/ncvNG9kMympjTGhIIlgkCr3gWFD8HiGyF7ts8iG0rrmJGVRHZKnM/txhgTSJYIAu3lu51eQuff7nOzqrKxrM7OBowxITNkIhCRj4qIJYyRKHsLdjwHZ98KyTk+i5RUN1Pb3G7jCxljQsafA/x1wC4R+W8RmTucJxeRpSKyU0SKRaTfT2IR+ZmIbHJvH4hI/XCeP6ypwkvfhpQpcMaXBiy20Z2IZrFNRGOMCZEhZ0dX1etFJBVYATwsIgo8BDyqqk0D7SciHuAB4GKgHNggIqvcCet7nvurXuW/DJwy4ncSbrY9DRUbYdkDEJs4YLENpbWkJ8ZwXHZSEIMzxpij/KryUdVG4ElgJTAZuAp41z14D+Q0oFhVS1S13d132SDlVwCP+hV1uOtsg5e/BxPnw4IVgxZ12gcyELGB5owxoeFPG8GVIvIMsBaIAU5T1UuBBcDXB9l1KrDXa7ncXefrNaYDM4BXB9h+k4gUikhhVVXVUCGH3ju/hfoyuPgeiBr4SuHqQ22UVDfbRPXGmJAasmoIuAb4maq+7r1SVVtE5DOjFMdy4ElV7fK1UVUfBB4EKCgo0FF6zcA4XEoXaHkAABfVSURBVAev/xiOuxCOXzJo0Y1lTvuANRQbY0LJn6qhu4F3ehZEJEFE8gFU9ZVB9qsA8ryWc911vixnvFQLvX4ftDbAxd8fsmhhaS2x0VHMn5oWhMCMMcY3fxLBE0C313KXu24oG4BZIjJDRGJxDvar+hZyeyKlA+v8eM7wVlcK7zwIC/8NJs0fsnhhWR0LctOIi7aB5owxoeNPIoh2G3sBcB/HDrWTqnYCNwMvAkXA46q6TUTuEZErvYouB1aqanhX+fjjlXtAPHDht4Ys2trRxdaKBus2aowJOX/aCKpE5EpVXQUgIsuAan+eXFVXA6v7rLurz/Ld/oUa5so3OiOMnvsNSJ0yZPHNe+vp6FJrHzDGhJw/ieALwJ9F5FeA4PQE+mRAoxprei4eS8qGs27xa5fCsp4LySwRGGNCy58LynYDZ4hIsrt8KOBRjTU7V8Oet+Dyn0Bcil+7FJbWMisnmQmJQ9ayGWNMQPlzRoCIXA6cCMT3XPikqvcEMK6xo6sD1nwXsmbDohv82qW72xlo7vKTJwc4OGOMGdqQiUBE/hdIBC4Afgdci1d30oi38WGo2QXLHwVPjF+77Ko8RGNrJwXWUGyMCQP+9Br6iKp+EqhT1e8BZwK+B9aPNK2NsPaHMP0smHOp37sVuhPR2BXFxphw4E/VUKt73yIiU4AanPGGzD9/AS3VcMnjMIyxggpL68hOiWNaxsCD0RljTLD4kwj+JiITgB8D7wIK/DagUY0FDRWw7lcw/1qYunhYuxaW1VIwPd0GmjPGhIVBE4E7Ic0rqloPPCUizwHxqtoQlOjC2Wv3gnbDkruGLuvlYGMre2sPc8OZ+YGJyxhjhmnQNgJV7caZU6Bnuc2SAHBgC2z6C5z+eUifPqxdC0t7BpqzhmJjTHjwp7H4FRG5Rqwe46iXvgPxaXDOYKNw+7ahtJaEGA/zpqQGIDBjjBk+fxLB53EGmWsTkUYRaRKRxgDHFb6KX4aS1+C8b0LC8Hv9bCyrY2HeBGI8Ng20MSY8DHk0UtUUVY1S1VhVTXWXI/PnbHcXvHQXpOfDqZ8d9u7NbZ1s399o3UaNMWHFnwvKzvW1vu9ENRFh01+gchtc+xBExw1/9731dHUrBdY+YIwJI/50H/2G1+N4nLmINwIXBiSicNXe7PQUmloAJ141oqfYUFqLCJwybcIoB2eMMSPnz6BzH/VeFpE84OcBiyhcvf8YNO2Ha/8wrIvHvG0sq2PupFRS4/0bisIYY4JhJC2W5cAJox1I2Nu3CRIyYNqZI9q9s6ubd8vqKLBhp40xYcafNoJf4lxNDE7iWIhzhXFkqdoBOSeM+Gxgx4Emmtu7rKHYGBN2/GkjKPR63Ak8qqr/DFA84UkVKovg5E+M+Ck2lPYMNGcNxcaY8OJPIngSaFXVLgAR8YhIoqq2BDa0MNK4D9oaIXvuiJ9ifUkNuekJTJ2QMIqBGWPMsfPrymLA++iVALzsz5OLyFIR2SkixSJy+wBlPiEi20Vkm4j8xZ/nDbrKIuc+Z96Idu/uVt7+sJYzZ2aOYlDGGDM6/DkjiPeenlJVD4nIkOMni4gHZ5yii3EamDeIyCpV3e5VZhZwB3CWqtaJSM6w30EwVPUkgpG1ke840ER9SwdnHmeJwBgTfvw5I2gWkUU9CyKyGDjsx36nAcWqWqKq7cBKYFmfMp8DHlDVOgBVrfQv7CCrLILkiZA4svr99SU1AJxhZwTGmDDkzxnBrcATIrIPEGAScJ0f+00F9notlwOn9ykzG0BE/gl4gLtV9e9+PHdwVRYdU/vAupIapmcmMsXaB4wxYcifC8o2iMhcYI67aqeqdozi688CzgdygddF5CR3/oMjROQm4CaAadOmjdJL+6m72+k66ufE9H11dStvl9Rw6Xyb1M0YE56GrBoSkS8BSaq6VVW3Aski8u9+PHcFkOe1nOuu81YOrFLVDlX9EPgAJzH0oqoPqmqBqhZkZ2f78dKjqGEPdLRAzsjOCIr2N9LY2mntA8aYsOVPG8HnvH+hu/X5n/Njvw3ALBGZISKxwHJgVZ8yz+KcDSAiWThVRSV+PHfwHGOPIWsfMMaEO38Sgcd7Uhq3N1DsUDupaidwM/AiUAQ8rqrbROQeEbnSLfYiUCMi24HXgG+oas1w30RA9SSC7DmDlxvA+pIaZmQlMSktfhSDMsaY0eNPY/HfgcdE5Dfu8ueBF/x5clVdDazus+4ur8cKfM29hafKIkjNdWYkG6Yu9/qBK06eEoDAjDFmdPiTCP4Dp6H2C+7y+zg9hyJDVdGI2we27WugqbWTM2basBLGmPDlzwxl3cDbQCnOtQEX4lT1jH/dXVD1wYgvJOtpH7Ario0x4WzAMwIRmQ2scG/VwGMAqnpBcEILA7UfQlcbZI8sEazbXcNx2UnkpFr7gDEmfA12RrAD59f/Fap6tqr+EugKTlhhotIdDWMEZwSdXd1sKK2z3kLGmLA3WCK4GtgPvCYivxWRJThXFkeOqh3O/Qh6DG3d18ihNrt+wBgT/gZMBKr6rKouB+bidO28FcgRkV+LyCXBCjCkKosgPR9ik4a967rdTvvA6TMsERhjwps/jcXNqvoXd+7iXOA9nJ5E419l0YjbB9aX1DArJ5nslLhRDsoYY0bXsOYsVtU6d7iHJYEKKGx0tkPNrhG1D3R0dbOhtNaqhYwxY8JIJq+PDLW7obtzRIlgS0UDLe1d1lBsjBkTLBEMpHLkk9EcbR+wC8mMMeHPEsFAKotAoiCz32CoQ1pfUsOciSlkJlv7gDEm/FkiGEhVEWQcBzHDuxisvbObwtI6ax8wxowZlggGUjmyMYbeL6/ncIe1Dxhjxg5LBL50tEJtyYjmIFhfUoOItQ8YY8YOSwS+VH8A2j2ieYrXldQwd1Iq6UlDTtlgjDFhwRKBLz1DSwzzjKCts4vC0jobdtoYM6ZYIvClcjtExUDmccPabfPeBto6u23YaWPMmGKJwJfKHZA1Czwxw9pt3e6e9gFLBMaYscMSgS+V20fUPrC+pIZ5k1NJSxxeAjHGmFCyRNBXezPUlw27faC1o4uNe+qsWsgYM+YENBGIyFIR2SkixSJyu4/tN4pIlYhscm+fDWQ8fjnSUDy8M4L39tTT3tlt1w8YY8YcfyavHxER8QAPABcD5cAGEVmlqtv7FH1MVW8OVBzDVjmyHkPrS2qIEjjNegwZY8aYQJ4RnAYUq2qJqrYDK4FlAXy90VG5HaLjnQlphmFdSQ3zp6aRGm/tA8aYsSWQiWAqsNdrudxd19c1IvK+iDwpInm+nkhEbhKRQhEprKqqCkSsR1XtgKzZEOXxe5fWji427am3aiFjzJgU6sbivwH5qnoysAb4o69C7mQ4BapakJ2dHdiIKouGPfT0u2V1tHfZ9QPGmLEpkImgAvD+hZ/rrjtCVWtUtc1d/B2wOIDxDK21ARorhp0I1pXU4IkSCvLTAxSYMcYETiATwQZglojMEJFYYDmwyruAiEz2WrwSKApgPEPraSge5jzF6932gRRrHzDGjEEBSwSq2gncDLyIc4B/XFW3icg9InKlW+wrIrJNRDYDXwFuDFQ8fqka/qxkh9u72LS33qqFjDFjVsC6jwKo6mpgdZ91d3k9vgO4I5AxDEtlEcQkQZrPNmufNpbV0dGlNtCcMWbMCnVjcXjpmYwmyv+PZV1JNZ4o4dR8SwTGmLHJEoG3yqIRtA/UcnJuGklxAT25MsaYgLFE0KO5Bporh9U+0NzWyWZrHzDGjHGWCHocaSj2f4yhwrI6OrvVJqo3xoxplgh6VLqJYBhVQ+tLaojxCIun2/UDxpixyxJBj8oiiEuD1Cl+77Judw0LcieQGGvtA8aYscsSQY+qHU61kIhfxQ+1dbKlosHGFzLGjHmWCABUnVFHh9FQvKG0li5rHzDGjAOWCAAOVcLhuuG1D+yuIdYTxaJp1j5gjBnbLBGAczYAwzojWF9Sw8K8CSTE+j9ctTHGhCNLBOA1PaV/iaCxtcNpH7BqIWPMOGCJAJweQ4mZkOTfXAeFpbV0Kza+kDFmXLBEAEeHlvCzx9C63TXERlv7gDFmfLBEoOp2HfW/fWBdSQ2Lpk0gPsbaB4wxY58lgsYKaGv0e2iJhsMdbNvXaNcPGGPGDUsEPbOS5czzq/g7H9aiig00Z4wZNywR9HQdzfbvjGB9SQ1x0VEsnDYhgEEZY0zwWCKo2gHJkyDRvx5A63bXsHh6OnHR1j5gjBkfLBFUbve7faC+pZ2iA41WLWSMGVcCmghEZKmI7BSRYhG5fZBy14iIikhBIOPpp7sbqnb63T7wtts+YBeSGWPGk4AlAhHxAA8AlwLzgBUi0u+IKyIpwC3A24GKZUD1ZdDR4nf7wLrdNcTHRLEg19oHjDHjRyDPCE4DilW1RFXbgZXAMh/lvg/8CGgNYCy+VQ2vx9D6khoKpmcQG201asaY8SOQR7SpwF6v5XJ33REisgjIU9XnB3siEblJRApFpLCqqmr0IjzSY2jOkEVrm9vZcaDJhp02xow7IftpKyJRwE+Brw9VVlUfVNUCVS3IzvZvPCC/VO6AtDyITx2wSHe3sqW8gZ+8tBPALiQzxow7gZxjsQLI81rOddf1SAHmA2vFGeNnErBKRK5U1cIAxnVUZZHP9oFDbZ28uaua13ZU8trOSiqb2hCBi07I4eTctKCEZowxwRLIRLABmCUiM3ASwHLgX3s2qmoDkNWzLCJrgduClgS6OqH6AzjuAgBKq5t5ZUclr+2o5O0Pa+joUlLiozl3djYXzsnh/DnZZCbHBSU0Y4wJpoAlAlXtFJGbgRcBD/AHVd0mIvcAhaq6KlCv7Y/26t3EdrXx132p/OK+tZRUNwNwfE4ynz5rBhfMzWHx9HRiPNYwbIwZ3wJ5RoCqrgZW91l31wBlzw9kLACVTa2s3VHFqzsqiS9+np8LPFycSN7MRG74SD4Xzs0hLyMx0GEYY0xYCWgiCCe/+cdu/usFp7vopNR4vj+pHj0o/PmO/0di0sCNxcYYM95FTCI4fWYm3/iXOVwwJ4cTJqcgT/4J2vMtCRhjIl7EJIKFeRNYmOd1RXBl0bAmozHGmPEqMltCO9uhptgSgTHGEKmJoKYYujudeYqNMSbCRWYiqCpy7u2MwBhjIjQRVBaBeCBrVqgjMcaYkIvcRJB5HETblcLGGBO5icDPOQiMMWa8i7xE0HEY6j70ew4CY4wZ7yIvEVR/ANrt9zzFxhgz3kVeIqgc3qxkxhgz3kVgItgOUTGQMTPUkRhjTFiIvERQtQOyZoMnJtSRGGNMWIi8RFC53doHjDHGS2QlgrZDUL/Hrig2xhgvkZUIqpwJ6G2MIWOMOSrCEoGNMWSMMX1FViKoLILoeEjPD3UkxhgTNgKaCERkqYjsFJFiEbndx/YviMgWEdkkIm+KSGA791cWQfYciPIE9GWMMWYsCVgiEBEP8ABwKTAPWOHjQP8XVT1JVRcC/w38NFDxAE7XUWsfMMaYXgJ5RnAaUKyqJaraDqwElnkXUNVGr8UkQAMWzeF6aKyw9gFjjOkjkHMWTwX2ei2XA6f3LSQiXwK+BsQCF/p6IhG5CbgJYNq0aSOLpqfHkCUCY4zpJeSNxar6gKoeB/wH8O0ByjyoqgWqWpCdnT2yF6rc7txbIjDGmF4CmQgqgDyv5Vx33UBWAh8LWDTJOTDnckjLG7qsMcZEkEAmgg3ALBGZISKxwHJglXcBEfGeK/JyYFfAopl7Oaz4C4gE7CWMMWYsClgbgap2isjNwIuAB/iDqm4TkXuAQlVdBdwsIhcBHUAdcEOg4jHGGONbIBuLUdXVwOo+6+7yenxLIF/fGGPM0ELeWGyMMSa0LBEYY0yEs0RgjDERzhKBMcZEOEsExhgT4SwRGGNMhBPVwI3zFggiUgWUjXD3LKB6FMMZbRbfsbH4jl24x2jxjdx0VfU5Rs+YSwTHQkQKVbUg1HEMxOI7NhbfsQv3GC2+wLCqIWOMiXCWCIwxJsJFWiJ4MNQBDMHiOzYW37EL9xgtvgCIqDYCY4wx/UXaGYExxpg+LBEYY0yEG5eJQESWishOESkWkdt9bI8Tkcfc7W+LSH4QY8sTkddEZLuIbBORfkNxi8j5ItIgIpvc212+niuAMZaKyBb3tQt9bBcRud/9/N4XkUVBjG2O1+eySUQaReTWPmWC/vmJyB9EpFJEtnqtyxCRNSKyy71PH2DfG9wyu0Rk1OfkGCC2H4vIDvfv94yITBhg30G/CwGO8W4RqfD6O142wL6D/r8HML7HvGIrFZFNA+wblM/wmKjquLrhTIKzG5gJxAKbgXl9yvw78L/u4+XAY0GMbzKwyH2cAnzgI77zgedC+BmWAlmDbL8MeAEQ4Azg7RD+rQ/gXCgT0s8POBdYBGz1WvffwO3u49uBH/nYLwMoce/T3cfpQYjtEiDaffwjX7H5810IcIx3A7f58R0Y9P89UPH12f4T4K5QfobHchuPZwSnAcWqWqKq7ThzIS/rU2YZ8Ef38ZPAEpHgzGGpqvtV9V33cRNQBEwNxmuPomXAI+pYD0wQkckhiGMJsFtVR3ql+ahR1deB2j6rvb9nf8T3nNz/AqxR1VpVrQPWAEsDHZuqvqSqne7iepw5xUNmgM/PH/78vx+zweJzjx2fAB4d7dcNlvGYCKYCe72Wy+l/oD1Sxv1naAAygxKdF7dK6hTgbR+bzxSRzSLygoicGNTAQIGXRGSjiNzkY7s/n3EwLGfgf75Qfn49JqrqfvfxAWCijzLh8Fl+GucMz5ehvguBdrNbffWHAarWwuHzOwc4qKoDzbke6s9wSOMxEYwJIpIMPAXcqqqNfTa/i1PdsQD4JfBskMM7W1UXAZcCXxKRc4P8+kMSkVjgSuAJH5tD/fn1o04dQdj11RaRbwGdwJ8HKBLK78KvgeOAhcB+nOqXcLSCwc8Gwv7/aTwmggogz2s5113ns4yIRANpQE1QonNeMwYnCfxZVZ/uu11VG1X1kPt4NRAjIlnBik9VK9z7SuAZnNNvb/58xoF2KfCuqh7suyHUn5+Xgz1VZu59pY8yIfssReRG4Arg39xE1Y8f34WAUdWDqtqlqt3Abwd47ZB+F93jx9XAYwOVCeVn6K/xmAg2ALNEZIb7q3E5sKpPmVVAT++Ma4FXB/pHGG1ufeLvgSJV/ekAZSb1tFmIyGk4f6egJCoRSRKRlJ7HOI2KW/sUWwV80u09dAbQ4FUFEiwD/goL5efXh/f37Abgrz7KvAhcIiLpbtXHJe66gBKRpcA3gStVtWWAMv58FwIZo3e701UDvLY//++BdBGwQ1XLfW0M9Wfot1C3VgfihtOr5QOc3gTfctfdg/OlB4jHqVIoBt4BZgYxtrNxqgjeBza5t8uALwBfcMvcDGzD6QGxHvhIEOOb6b7uZjeGns/POz4BHnA/3y1AQZD/vkk4B/Y0r3Uh/fxwktJ+oAOnnvozOO1OrwC7gJeBDLdsAfA7r30/7X4Xi4FPBSm2Ypy69Z7vYE8vuinA6sG+C0H8/P7kfr/exzm4T+4bo7vc7/89GPG56x/u+d55lQ3JZ3gsNxtiwhhjItx4rBoyxhgzDJYIjDEmwlkiMMaYCGeJwBhjIpwlAmOMiXCWCIzpQ0S6+oxwOmojWopIvvcIlsaEg+hQB2BMGDqsqgtDHYQxwWJnBMb4yR1X/r/dseXfEZHj3fX5IvKqOzjaKyIyzV0/0R3rf7N7+4j7VB4R+a0481G8JCIJIXtTxmCJwBhfEvpUDV3nta1BVU8CfgX83F33S+CPqnoyzuBt97vr7wf+oc7gd4twriwFmAU8oKonAvXANQF+P8YMyq4sNqYPETmkqsk+1pcCF6pqiTtw4AFVzRSRapzhDzrc9ftVNUtEqoBcVW3zeo58nPkHZrnL/wHEqOoPAv/OjPHNzgiMGR4d4PFwtHk97sLa6kyIWSIwZniu87pf5z5+C2fUS4B/A95wH78CfBFARDwikhasII0ZDvslYkx/CX0mIv+7qvZ0IU0XkfdxftWvcNd9GXhIRL4BVAGfctffAjwoIp/B+eX/RZwRLI0JK9ZGYIyf3DaCAlWtDnUsxowmqxoyxpgIZ2cExhgT4eyMwBhjIpwlAmOMiXCWCIwxJsJZIjDGmAhnicAYYyLc/wfl48V1R/8PgwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_eajX_QWp9KI"},"source":["#Bayesian optimizer\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEaOBloUraiQ","executionInfo":{"status":"ok","timestamp":1608623206630,"user_tz":-540,"elapsed":159535,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"8c0f2138-8227-45e9-c401-446933e30cda"},"source":["LSTM_model = Sequential()\r\n","LSTM_model.add(Embedding(vocab_size, 120))\r\n","LSTM_model.add(LSTM(120))\r\n","LSTM_model.add(Dense(intent_count, activation='softmax'))\r\n","LSTM_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, None, 120)         6000      \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 120)               115680    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 847       \n","=================================================================\n","Total params: 122,527\n","Trainable params: 122,527\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"txLp_vijocEL"},"source":["LSTM_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['acc'],)\r\n","\r\n","history = LSTM_model.fit(x_data_train,\r\n","                    y_data_train_one_hot,\r\n","                    batch_size = 30,\r\n","                    epochs=50,\r\n","                    callbacks=[es, mc],\r\n","                    \r\n","                    \r\n","                    validation_data=(x_data_valid,\r\n","                                     y_data_valid_one_hot))\r\n","\r\n","\r\n","# 학습 정확성 값과 검증 정확성 값을 플롯팅 합니다. \r\n","plt.plot(history.history['acc'])\r\n","plt.plot(history.history['val_acc'])\r\n","plt.title('Model accuracy')\r\n","plt.ylabel('Accuracy')\r\n","plt.xlabel('Epoch')\r\n","plt.legend(['Train', 'Valid'], loc='upper left')\r\n","plt.show()\r\n","\r\n","# 학습 손실 값과 검증 손실 값을 플롯팅 합니다.\r\n","plt.plot(history.history['loss'])\r\n","plt.plot(history.history['val_loss'])\r\n","plt.title('Model loss')\r\n","plt.ylabel('Loss')\r\n","plt.xlabel('Epoch')\r\n","plt.legend(['Train', 'Valid'], loc='upper left')\r\n","plt.show()\r\n","\r\n","import sklearn\r\n","y_val_series = pd.Series(y_data_valid)\r\n","print(sklearn.metrics.classification_report(y_val_series,pred(x_data_valid,LSTM_model),digits=4))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DEHaU-9BDVn","executionInfo":{"status":"ok","timestamp":1608623216311,"user_tz":-540,"elapsed":169199,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"8017fbaa-bef9-49b4-b622-5d9145c5ae17"},"source":["start_time = timeit.default_timer() # 시작 시간 체크\r\n","test_sample = [0, 0, 0, 0, 0, 0, 8, 1]\r\n","LSTM_model.predict(test_sample)\r\n","\r\n","terminate_time = timeit.default_timer() # 종료 시간 체크\r\n","pred_time = terminate_time - start_time\r\n","pred_time"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.37524851099988155"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"E_Io7SeGwd70"},"source":["### hyper parameter ###"]},{"cell_type":"markdown","metadata":{"id":"Jjk9Gmgw4eH1"},"source":["#### default hyper_parameter"]},{"cell_type":"code","metadata":{"id":"pz_NkU_Kwd71","scrolled":true},"source":["# default hyper_parameter\n","from tensorflow_addons import optimizers\n","LEARNING_RATE = 1e-03\n","NUM_DENSE_LAYERS = 0\n","NUM_DENSE_NODES = 8\n","Embed_dim = 120\n","OPTIMIZER = optimizers.RectifiedAdam\n","\n","default_parameter = [LEARNING_RATE,\n","                     NUM_DENSE_LAYERS,\n","                     NUM_DENSE_NODES,\n","                     OPTIMIZER,\n","                     Embed_dim]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c3rx5GvCxz9H"},"source":["#### hyper parameter range ####"]},{"cell_type":"code","metadata":{"id":"Nj_hKF3_wd77"},"source":["# hyper parameter\n","\n","#learning_rate\n","learning_rate = Real(low=1.0e-04, high=1e-2, prior='log-uniform',\n","                         name='learning_rate')\n","\n","# num_dense_layers\n","dim_num_dense_layers = Integer(low=0, high=2, name='num_dense_layers')\n","\n","# dense nodes\n","dim_num_dense_nodes = Integer(low=8, high=512, name='num_dense_nodes')\n","\n","# optimizer\n","optimizer = Categorical(categories= [Adadelta, Adam, Nadam, optimizers.RectifiedAdam], name = 'optimizer')\n","\n","Embed_dim = Integer(low=60, high=240, name='Embed_dim')\n","\n","paras = [learning_rate,\n","         dim_num_dense_layers,\n","         dim_num_dense_nodes,\n","         optimizer,\n","         Embed_dim]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_I9UYebkwd8F"},"source":["#### hyper function for log-dir-name"]},{"cell_type":"code","metadata":{"id":"n1bVBcoXwd8G"},"source":["def log_dir_name(learning_rate,\n","                 num_dense_layers,\n","                 num_dense_nodes,\n","                 optimizer,\n","                 Embed_dim):\n","\n","    # The dir-name for the TensorBoard log-dir.\n","    s = \"./logs/lr_{0:.0e}_layers_{1}_nodes_{2}_{3}/\"\n","\n","    # Insert all the hyper-parameters in the dir-name.\n","    log_dir = s.format(learning_rate,\n","                       num_dense_layers,\n","                       num_dense_nodes,\n","                       optimizer,\n","                       Embed_dim\n","                      )\n","\n","    return log_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO2v4k0lwd8Y"},"source":["path_best_model = 'helra_model.h5'\n","best_accuracy = 0.0\n","\n","@use_named_args(dimensions=paras)\n","def fitness(learning_rate,\n","            num_dense_layers,\n","            num_dense_nodes,\n","            optimizer,\n","            Embed_dim):\n","\n","    # Print the hyper-parameters.\n","    print('learning rate: {0:.1e}'.format(learning_rate))\n","    print('num_dense_layers:', num_dense_layers)\n","    print('num_dense_nodes:', num_dense_nodes)\n","    print('optimizer:', optimizer)\n","    print('epochs:', 3)\n","    print('batch_size:', 20)\n","    print('Embed_dim:', Embed_dim)\n","    \n","    # Create the neural network with these hyper-parameters.\n","    \n","    LSTM_model = Sequential()\n","    LSTM_model.add(Embedding(vocab_size, Embed_dim))\n","    LSTM_model.add(LSTM(Embed_dim))\n","    \n","    initializer = tf.keras.initializers.Orthogonal()\n","    \n","    for i in range(num_dense_layers):\n","        LSTM_model.add(Dense(num_dense_nodes, activation='relu', kernel_initializer='he_normal'))\n","    \n","    LSTM_model.add(Dense(intent_count, activation='softmax'))\n","    \n","\n","    LSTM_model.compile(loss='categorical_crossentropy', optimizer=optimizer(learning_rate=learning_rate), metrics=['acc'],)\n","\n","\n","    # Dir-name for the TensorBoard log-files.\n","    log_dir = log_dir_name(learning_rate, num_dense_layers,\n","                           num_dense_nodes, optimizer,Embed_dim)\n","    \n","\n","    callback_log = TensorBoard(\n","        log_dir=log_dir,\n","        histogram_freq=0,\n","        write_graph=True,\n","        write_grads=False,\n","        write_images=False)\n","   \n","    # Use Keras to train the model.\n","    history = LSTM_model.fit(x_data_train,\n","                             y_data_train_one_hot,\n","                             batch_size = 25,\n","                             epochs=50,\n","                             validation_data=(x_data_valid,y_data_valid_one_hot),\n","                             callbacks=[callback_log])\n","\n","\n","    # Get the classification accuracy on the validation-set\n","    # after the last training-epoch.\n","    accuracy = history.history['val_acc'][-1]\n","\n","    # Print the classification accuracy.\n","    print()\n","    print(\"Accuracy: {0:.2%}\".format(accuracy))\n","    print()\n","\n","    # Save the model if it improves on the best-found performance.\n","    # We use the global keyword so we update the variable outside\n","    # of this function.\n","    global best_accuracy\n","\n","    # If the classification accuracy of the saved model is improved ...\n","    if accuracy > best_accuracy:\n","        # Save the new model to harddisk.\n","        LSTM_model.save(\"best_model.h5\")\n","        \n","        # Update the classification accuracy.\n","        best_accuracy = accuracy\n","\n","    y_val_series = pd.Series(y_data_valid)\n","    result = sklearn.metrics.classification_report(y_val_series,pred(x_data_valid,LSTM_model),digits=4)\n","\n","\n","    #데이터 예측 시간 측정\n","    start_time = timeit.default_timer() # 시작 시간 체크\n","    test_sample = [0, 0, 0, 0, 0, 0, 8, 1]\n","    LSTM_model.predict(test_sample)\n","\n","    terminate_time = timeit.default_timer() # 종료 시간 체크\n","    pred_time = terminate_time - start_time\n","\n","    LSTM_model.summary()\n","    # Delete the Keras model with these hyper-parameters from memory.\n","    del LSTM_model\n","    del start_time, terminate_time\n","    # Clear the Keras session, otherwise it will keep adding new\n","    # models to the same TensorFlow graph each time we create\n","    # a model with a different set of hyper-parameters.\n","    K.clear_session()\n","    \n","    # NOTE: Scikit-optimize does minimization so it tries to\n","    # find a set of hyper-parameters with the LOWEST fitness-value.\n","    # Because we are interested in the HIGHEST classification\n","    # accuracy, we need to negate this number so it can be minimized.\n","    print(result)\n","    print('샘플예측시간:{} 초'.format(round(pred_time,2)))\n","    \n","    model_ls.append([pred_time, best_accuracy, learning_rate, num_dense_layers, num_dense_nodes, optimizer,Embed_dim])\n","    \n","    return -accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7_i8JyKdyLiO"},"source":["## Bayesian optimization Run!!"]},{"cell_type":"code","metadata":{"id":"hkzZDuoXwd8f","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608623231888,"user_tz":-540,"elapsed":184761,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"391b9575-35c9-42f7-bc87-6084015637e1"},"source":["model_ls =[]\r\n","fitness(x=default_parameter)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["learning rate: 1.0e-03\n","num_dense_layers: 0\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 120\n","Epoch 1/50\n","15/15 [==============================] - 4s 89ms/step - loss: 1.9454 - acc: 0.2246 - val_loss: 1.9409 - val_acc: 0.1795\n","Epoch 2/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9383 - acc: 0.2304 - val_loss: 1.9287 - val_acc: 0.1731\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9251 - acc: 0.2406 - val_loss: 1.9093 - val_acc: 0.3013\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9089 - acc: 0.2901 - val_loss: 1.8826 - val_acc: 0.2821\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8736 - acc: 0.2644 - val_loss: 1.8418 - val_acc: 0.1731\n","Epoch 6/50\n","15/15 [==============================] - 0s 15ms/step - loss: 1.8364 - acc: 0.2174 - val_loss: 1.7873 - val_acc: 0.1731\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7958 - acc: 0.2213 - val_loss: 1.7351 - val_acc: 0.2949\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7446 - acc: 0.3709 - val_loss: 1.6679 - val_acc: 0.6154\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.6860 - acc: 0.5732 - val_loss: 1.5940 - val_acc: 0.5769\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.5643 - acc: 0.6116 - val_loss: 1.4611 - val_acc: 0.6282\n","Epoch 11/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.4485 - acc: 0.6116 - val_loss: 1.2550 - val_acc: 0.6218\n","Epoch 12/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.2343 - acc: 0.6347 - val_loss: 1.0011 - val_acc: 0.7051\n","Epoch 13/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.0268 - acc: 0.6758 - val_loss: 0.7781 - val_acc: 0.8462\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7719 - acc: 0.8220 - val_loss: 0.5917 - val_acc: 0.9103\n","Epoch 15/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6129 - acc: 0.8871 - val_loss: 0.4701 - val_acc: 0.8974\n","Epoch 16/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.5254 - acc: 0.8870 - val_loss: 0.3439 - val_acc: 0.9359\n","Epoch 17/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.3521 - acc: 0.9373 - val_loss: 0.2814 - val_acc: 0.9487\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.3153 - acc: 0.9314 - val_loss: 0.2300 - val_acc: 0.9551\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2392 - acc: 0.9660 - val_loss: 0.1838 - val_acc: 0.9551\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2030 - acc: 0.9795 - val_loss: 0.1649 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1940 - acc: 0.9618 - val_loss: 0.1978 - val_acc: 0.9679\n","Epoch 22/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1832 - acc: 0.9633 - val_loss: 0.1329 - val_acc: 0.9551\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1560 - acc: 0.9672 - val_loss: 0.1236 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1247 - acc: 0.9826 - val_loss: 0.1028 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.1257 - acc: 0.9775 - val_loss: 0.1016 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1287 - acc: 0.9758 - val_loss: 0.0929 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1097 - acc: 0.9728 - val_loss: 0.0898 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1062 - acc: 0.9835 - val_loss: 0.0792 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1094 - acc: 0.9732 - val_loss: 0.0896 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0972 - acc: 0.9758 - val_loss: 0.0821 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0734 - acc: 0.9874 - val_loss: 0.0796 - val_acc: 0.9872\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0960 - acc: 0.9734 - val_loss: 0.0743 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1090 - acc: 0.9769 - val_loss: 0.0690 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0719 - acc: 0.9807 - val_loss: 0.0694 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0665 - acc: 0.9848 - val_loss: 0.0639 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0757 - acc: 0.9808 - val_loss: 0.0619 - val_acc: 0.9872\n","Epoch 37/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0575 - acc: 0.9867 - val_loss: 0.0589 - val_acc: 0.9872\n","Epoch 38/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0486 - acc: 0.9929 - val_loss: 0.0532 - val_acc: 0.9872\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0549 - acc: 0.9867 - val_loss: 0.0551 - val_acc: 0.9744\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0596 - acc: 0.9857 - val_loss: 0.0591 - val_acc: 0.9872\n","Epoch 41/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0491 - acc: 0.9792 - val_loss: 0.0530 - val_acc: 0.9872\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0657 - acc: 0.9766 - val_loss: 0.0565 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0455 - acc: 0.9889 - val_loss: 0.0487 - val_acc: 0.9872\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0568 - acc: 0.9833 - val_loss: 0.0571 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0537 - acc: 0.9837 - val_loss: 0.0448 - val_acc: 0.9872\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0490 - acc: 0.9788 - val_loss: 0.0488 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0573 - acc: 0.9843 - val_loss: 0.0496 - val_acc: 0.9872\n","Epoch 48/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0390 - acc: 0.9917 - val_loss: 0.0468 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0393 - acc: 0.9903 - val_loss: 0.0468 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0441 - acc: 0.9855 - val_loss: 0.0452 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, None, 120)         6000      \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 120)               115680    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 7)                 847       \n","=================================================================\n","Total params: 122,527\n","Trainable params: 122,527\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.38 초\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["-0.9807692170143127"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"o2mIxz3d7Xql","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608623231889,"user_tz":-540,"elapsed":184760,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"d53d3281-dc41-4fc4-f65b-8dcfa439b24c"},"source":["print(model_ls)\r\n","del model_ls\r\n","\r\n","model_ls = []"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.3849937790000695, 0.9807692170143127, 0.001, 0, 8, <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>, 120]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qLL8u4jGwd8i","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608623888790,"user_tz":-540,"elapsed":841654,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"d6cf0a8e-24d4-46ed-bfc7-72db0a23b013"},"source":["search_result = gp_minimize(func=fitness,\n","                            dimensions=paras,\n","                            acq_func='EI', # Expected Improvement.\n","                            n_calls=45,\n","                            x0=default_parameter,\n","                            \n","                            )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["learning rate: 1.0e-03\n","num_dense_layers: 0\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 120\n","Epoch 1/50\n","15/15 [==============================] - 4s 113ms/step - loss: 1.9409 - acc: 0.0995 - val_loss: 1.9385 - val_acc: 0.1603\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9344 - acc: 0.2334 - val_loss: 1.9255 - val_acc: 0.3718\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9194 - acc: 0.4154 - val_loss: 1.9066 - val_acc: 0.3782\n","Epoch 4/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9023 - acc: 0.3718 - val_loss: 1.8800 - val_acc: 0.3846\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8712 - acc: 0.4344 - val_loss: 1.8401 - val_acc: 0.3910\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8267 - acc: 0.4053 - val_loss: 1.7808 - val_acc: 0.3910\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8127 - acc: 0.3637 - val_loss: 1.7314 - val_acc: 0.3718\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7240 - acc: 0.3951 - val_loss: 1.6671 - val_acc: 0.5705\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7093 - acc: 0.5256 - val_loss: 1.5737 - val_acc: 0.6154\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.5867 - acc: 0.5797 - val_loss: 1.4378 - val_acc: 0.6282\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.4524 - acc: 0.5862 - val_loss: 1.2182 - val_acc: 0.6282\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.1832 - acc: 0.6247 - val_loss: 0.9797 - val_acc: 0.6859\n","Epoch 13/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.0108 - acc: 0.6770 - val_loss: 0.7356 - val_acc: 0.7500\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7849 - acc: 0.7434 - val_loss: 0.5710 - val_acc: 0.8333\n","Epoch 15/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.5813 - acc: 0.8362 - val_loss: 0.4434 - val_acc: 0.9423\n","Epoch 16/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.4803 - acc: 0.9370 - val_loss: 0.3317 - val_acc: 0.9487\n","Epoch 17/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.3716 - acc: 0.9433 - val_loss: 0.2600 - val_acc: 0.9551\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.3100 - acc: 0.9628 - val_loss: 0.2100 - val_acc: 0.9487\n","Epoch 19/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2367 - acc: 0.9620 - val_loss: 0.1926 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2093 - acc: 0.9725 - val_loss: 0.1538 - val_acc: 0.9872\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1628 - acc: 0.9792 - val_loss: 0.1589 - val_acc: 0.9744\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1912 - acc: 0.9646 - val_loss: 0.1329 - val_acc: 0.9551\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1357 - acc: 0.9810 - val_loss: 0.1092 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1136 - acc: 0.9859 - val_loss: 0.0944 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1246 - acc: 0.9722 - val_loss: 0.0945 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0798 - acc: 0.9877 - val_loss: 0.0832 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0987 - acc: 0.9868 - val_loss: 0.0798 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0836 - acc: 0.9795 - val_loss: 0.0769 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0759 - acc: 0.9823 - val_loss: 0.0649 - val_acc: 0.9872\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0747 - acc: 0.9842 - val_loss: 0.0700 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0677 - acc: 0.9854 - val_loss: 0.0638 - val_acc: 0.9872\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0736 - acc: 0.9807 - val_loss: 0.0692 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0912 - acc: 0.9788 - val_loss: 0.0574 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0542 - acc: 0.9856 - val_loss: 0.0750 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0752 - acc: 0.9831 - val_loss: 0.0565 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0546 - acc: 0.9902 - val_loss: 0.0651 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0567 - acc: 0.9862 - val_loss: 0.0481 - val_acc: 0.9936\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0627 - acc: 0.9797 - val_loss: 0.0531 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0622 - acc: 0.9913 - val_loss: 0.0472 - val_acc: 0.9936\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0471 - acc: 0.9906 - val_loss: 0.0600 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0506 - acc: 0.9885 - val_loss: 0.0456 - val_acc: 0.9872\n","Epoch 42/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0379 - acc: 0.9910 - val_loss: 0.0502 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0451 - acc: 0.9882 - val_loss: 0.0452 - val_acc: 0.9936\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0316 - acc: 0.9896 - val_loss: 0.0458 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0367 - acc: 0.9898 - val_loss: 0.0432 - val_acc: 0.9936\n","Epoch 46/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0479 - acc: 0.9868 - val_loss: 0.0434 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0353 - acc: 0.9914 - val_loss: 0.0460 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0391 - acc: 0.9909 - val_loss: 0.0409 - val_acc: 0.9936\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0387 - acc: 0.9898 - val_loss: 0.0458 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0373 - acc: 0.9902 - val_loss: 0.0435 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd77017c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 120)         6000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 120)               115680    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 847       \n","=================================================================\n","Total params: 122,527\n","Trainable params: 122,527\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.58 초\n","learning rate: 2.4e-04\n","num_dense_layers: 1\n","num_dense_nodes: 415\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 202\n","Epoch 1/50\n","15/15 [==============================] - 4s 111ms/step - loss: 1.9273 - acc: 0.2948 - val_loss: 1.8637 - val_acc: 0.3782\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8356 - acc: 0.3646 - val_loss: 1.7410 - val_acc: 0.5769\n","Epoch 3/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7328 - acc: 0.4839 - val_loss: 1.5929 - val_acc: 0.6218\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5540 - acc: 0.5985 - val_loss: 1.3453 - val_acc: 0.6154\n","Epoch 5/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.2866 - acc: 0.6299 - val_loss: 0.9436 - val_acc: 0.7308\n","Epoch 6/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.9197 - acc: 0.7015 - val_loss: 0.5535 - val_acc: 0.8974\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5885 - acc: 0.8739 - val_loss: 0.4549 - val_acc: 0.8910\n","Epoch 8/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.3836 - acc: 0.9247 - val_loss: 0.3163 - val_acc: 0.9103\n","Epoch 9/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2724 - acc: 0.9431 - val_loss: 0.2049 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1617 - acc: 0.9852 - val_loss: 0.3201 - val_acc: 0.8974\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1824 - acc: 0.9763 - val_loss: 0.1025 - val_acc: 0.9872\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1099 - acc: 0.9863 - val_loss: 0.1109 - val_acc: 0.9551\n","Epoch 13/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1157 - acc: 0.9816 - val_loss: 0.0775 - val_acc: 0.9872\n","Epoch 14/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1038 - acc: 0.9774 - val_loss: 0.0669 - val_acc: 0.9872\n","Epoch 15/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0821 - acc: 0.9827 - val_loss: 0.0605 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0830 - acc: 0.9815 - val_loss: 0.0603 - val_acc: 0.9872\n","Epoch 17/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0673 - acc: 0.9910 - val_loss: 0.0522 - val_acc: 0.9936\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0699 - acc: 0.9822 - val_loss: 0.0533 - val_acc: 0.9872\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0732 - acc: 0.9798 - val_loss: 0.0458 - val_acc: 0.9936\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0623 - acc: 0.9825 - val_loss: 0.0424 - val_acc: 0.9872\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0701 - acc: 0.9737 - val_loss: 0.0504 - val_acc: 0.9872\n","Epoch 22/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0532 - acc: 0.9898 - val_loss: 0.0394 - val_acc: 0.9936\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0639 - acc: 0.9839 - val_loss: 0.0377 - val_acc: 0.9936\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0670 - acc: 0.9802 - val_loss: 0.0494 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0570 - acc: 0.9728 - val_loss: 0.0536 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0476 - acc: 0.9880 - val_loss: 0.0351 - val_acc: 0.9936\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0875 - acc: 0.9675 - val_loss: 0.0411 - val_acc: 0.9872\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0334 - acc: 0.9928 - val_loss: 0.0472 - val_acc: 0.9936\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0348 - acc: 0.9925 - val_loss: 0.0838 - val_acc: 0.9679\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0534 - acc: 0.9750 - val_loss: 0.0376 - val_acc: 0.9936\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0239 - acc: 0.9938 - val_loss: 0.0525 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0610 - acc: 0.9681 - val_loss: 0.0328 - val_acc: 0.9936\n","Epoch 33/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0436 - acc: 0.9846 - val_loss: 0.0482 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0477 - acc: 0.9784 - val_loss: 0.0355 - val_acc: 0.9936\n","Epoch 35/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0383 - acc: 0.9875 - val_loss: 0.0688 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0411 - acc: 0.9836 - val_loss: 0.0417 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0471 - acc: 0.9779 - val_loss: 0.0490 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0413 - acc: 0.9912 - val_loss: 0.0399 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0440 - acc: 0.9862 - val_loss: 0.0494 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0512 - acc: 0.9755 - val_loss: 0.0335 - val_acc: 0.9872\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0369 - acc: 0.9850 - val_loss: 0.0374 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0390 - acc: 0.9896 - val_loss: 0.0418 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0292 - acc: 0.9875 - val_loss: 0.0340 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0232 - acc: 0.9908 - val_loss: 0.0412 - val_acc: 0.9872\n","Epoch 45/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0445 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0411 - acc: 0.9867 - val_loss: 0.0487 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0453 - acc: 0.9748 - val_loss: 0.0318 - val_acc: 0.9936\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0301 - acc: 0.9864 - val_loss: 0.0602 - val_acc: 0.9679\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0454 - acc: 0.9765 - val_loss: 0.0420 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0381 - acc: 0.9821 - val_loss: 0.0371 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6dff5f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 202)         10100     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 202)               327240    \n","_________________________________________________________________\n","dense (Dense)                (None, 415)               84245     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 2912      \n","=================================================================\n","Total params: 424,497\n","Trainable params: 424,497\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 1.6e-04\n","num_dense_layers: 0\n","num_dense_nodes: 259\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 122\n","Epoch 1/50\n","15/15 [==============================] - 3s 62ms/step - loss: 1.9492 - acc: 0.1039 - val_loss: 1.9485 - val_acc: 0.1410\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9477 - acc: 0.1338 - val_loss: 1.9485 - val_acc: 0.1410\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9486 - acc: 0.1123 - val_loss: 1.9485 - val_acc: 0.1410\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9486 - acc: 0.0998 - val_loss: 1.9484 - val_acc: 0.1410\n","Epoch 5/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.9483 - acc: 0.1127 - val_loss: 1.9484 - val_acc: 0.1410\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9486 - acc: 0.1096 - val_loss: 1.9484 - val_acc: 0.1410\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9485 - acc: 0.1039 - val_loss: 1.9484 - val_acc: 0.1410\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9488 - acc: 0.1174 - val_loss: 1.9484 - val_acc: 0.1410\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9490 - acc: 0.1083 - val_loss: 1.9484 - val_acc: 0.1410\n","Epoch 10/50\n","15/15 [==============================] - 0s 29ms/step - loss: 1.9485 - acc: 0.1064 - val_loss: 1.9483 - val_acc: 0.1410\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9480 - acc: 0.1232 - val_loss: 1.9483 - val_acc: 0.1410\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9492 - acc: 0.0874 - val_loss: 1.9483 - val_acc: 0.1410\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9481 - acc: 0.0925 - val_loss: 1.9483 - val_acc: 0.1410\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9492 - acc: 0.1085 - val_loss: 1.9483 - val_acc: 0.1410\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9494 - acc: 0.0868 - val_loss: 1.9483 - val_acc: 0.1410\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9488 - acc: 0.0968 - val_loss: 1.9482 - val_acc: 0.1410\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9481 - acc: 0.1325 - val_loss: 1.9482 - val_acc: 0.1410\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9486 - acc: 0.1090 - val_loss: 1.9482 - val_acc: 0.1410\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9481 - acc: 0.1334 - val_loss: 1.9482 - val_acc: 0.1410\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9492 - acc: 0.0923 - val_loss: 1.9482 - val_acc: 0.1410\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9489 - acc: 0.1137 - val_loss: 1.9482 - val_acc: 0.1410\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9483 - acc: 0.1232 - val_loss: 1.9481 - val_acc: 0.1410\n","Epoch 23/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9485 - acc: 0.0891 - val_loss: 1.9481 - val_acc: 0.1410\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9482 - acc: 0.1215 - val_loss: 1.9481 - val_acc: 0.1410\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9486 - acc: 0.1150 - val_loss: 1.9481 - val_acc: 0.1410\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9484 - acc: 0.1246 - val_loss: 1.9481 - val_acc: 0.1410\n","Epoch 27/50\n","15/15 [==============================] - 0s 23ms/step - loss: 1.9487 - acc: 0.1029 - val_loss: 1.9480 - val_acc: 0.1410\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9478 - acc: 0.1214 - val_loss: 1.9480 - val_acc: 0.1410\n","Epoch 29/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9486 - acc: 0.0946 - val_loss: 1.9480 - val_acc: 0.1410\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9478 - acc: 0.1191 - val_loss: 1.9480 - val_acc: 0.1410\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9480 - acc: 0.1410 - val_loss: 1.9480 - val_acc: 0.1410\n","Epoch 32/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9478 - acc: 0.1208 - val_loss: 1.9480 - val_acc: 0.1410\n","Epoch 33/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9482 - acc: 0.1141 - val_loss: 1.9479 - val_acc: 0.1410\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9486 - acc: 0.1073 - val_loss: 1.9479 - val_acc: 0.1410\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9483 - acc: 0.1067 - val_loss: 1.9479 - val_acc: 0.1410\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9482 - acc: 0.1113 - val_loss: 1.9479 - val_acc: 0.1410\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9481 - acc: 0.1190 - val_loss: 1.9479 - val_acc: 0.1410\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9483 - acc: 0.1214 - val_loss: 1.9479 - val_acc: 0.1410\n","Epoch 39/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9482 - acc: 0.0916 - val_loss: 1.9478 - val_acc: 0.1410\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9479 - acc: 0.1252 - val_loss: 1.9478 - val_acc: 0.1410\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9480 - acc: 0.1215 - val_loss: 1.9478 - val_acc: 0.1410\n","Epoch 42/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9486 - acc: 0.1059 - val_loss: 1.9478 - val_acc: 0.1410\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9476 - acc: 0.1144 - val_loss: 1.9478 - val_acc: 0.1410\n","Epoch 44/50\n","15/15 [==============================] - 0s 22ms/step - loss: 1.9481 - acc: 0.1170 - val_loss: 1.9477 - val_acc: 0.1410\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9476 - acc: 0.1147 - val_loss: 1.9477 - val_acc: 0.1410\n","Epoch 46/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9481 - acc: 0.0932 - val_loss: 1.9477 - val_acc: 0.1410\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9481 - acc: 0.1121 - val_loss: 1.9477 - val_acc: 0.1410\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9475 - acc: 0.1210 - val_loss: 1.9477 - val_acc: 0.1410\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9475 - acc: 0.1145 - val_loss: 1.9477 - val_acc: 0.1410\n","Epoch 50/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9476 - acc: 0.1269 - val_loss: 1.9476 - val_acc: 0.1410\n","\n","Accuracy: 14.10%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd77017c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 122)         6100      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 122)               119560    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 861       \n","=================================================================\n","Total params: 126,521\n","Trainable params: 126,521\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000      27.0\n","           1     0.0000    0.0000    0.0000      20.0\n","           2     0.0000    0.0000    0.0000      37.0\n","           3     0.0000    0.0000    0.0000      17.0\n","           4     0.0000    0.0000    0.0000      34.0\n","           5     0.0000    0.0000    0.0000      11.0\n","           6     0.0000    0.0000    0.0000      10.0\n","          99     0.0000    0.0000    0.0000       0.0\n","\n","    accuracy                         0.0000     156.0\n","   macro avg     0.0000    0.0000    0.0000     156.0\n","weighted avg     0.0000    0.0000    0.0000     156.0\n","\n","샘플예측시간:0.41 초\n","learning rate: 2.0e-03\n","num_dense_layers: 0\n","num_dense_nodes: 201\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 172\n","Epoch 1/50\n","15/15 [==============================] - 4s 108ms/step - loss: 1.8744 - acc: 0.2621 - val_loss: 1.4891 - val_acc: 0.5962\n","Epoch 2/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.2810 - acc: 0.5993 - val_loss: 0.5328 - val_acc: 0.8846\n","Epoch 3/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.3730 - acc: 0.9237 - val_loss: 0.1189 - val_acc: 0.9551\n","Epoch 4/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1173 - acc: 0.9793 - val_loss: 0.0463 - val_acc: 0.9872\n","Epoch 5/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0675 - acc: 0.9818 - val_loss: 0.0466 - val_acc: 0.9808\n","Epoch 6/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0387 - acc: 0.9911 - val_loss: 0.0379 - val_acc: 0.9936\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0598 - acc: 0.9761 - val_loss: 0.0274 - val_acc: 0.9936\n","Epoch 8/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0338 - acc: 0.9886 - val_loss: 0.0267 - val_acc: 0.9936\n","Epoch 9/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0323 - acc: 0.9893 - val_loss: 0.0413 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0295 - acc: 0.9882 - val_loss: 0.0366 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0353 - acc: 0.9882 - val_loss: 0.0337 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0269 - acc: 0.9863 - val_loss: 0.0699 - val_acc: 0.9679\n","Epoch 13/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0255 - acc: 0.9884 - val_loss: 0.0443 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0236 - acc: 0.9971 - val_loss: 0.0620 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0299 - acc: 0.9898 - val_loss: 0.0794 - val_acc: 0.9679\n","Epoch 16/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0336 - acc: 0.9878 - val_loss: 0.0577 - val_acc: 0.9744\n","Epoch 17/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0246 - acc: 0.9871 - val_loss: 0.0418 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0182 - acc: 0.9955 - val_loss: 0.0459 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0186 - acc: 0.9953 - val_loss: 0.0599 - val_acc: 0.9744\n","Epoch 20/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0554 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0251 - acc: 0.9853 - val_loss: 0.0539 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0221 - acc: 0.9881 - val_loss: 0.0504 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0130 - acc: 0.9940 - val_loss: 0.0436 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0395 - acc: 0.9898 - val_loss: 0.0521 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0102 - acc: 0.9966 - val_loss: 0.0562 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0272 - acc: 0.9926 - val_loss: 0.0609 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.0752 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0149 - acc: 0.9935 - val_loss: 0.0738 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0153 - acc: 0.9938 - val_loss: 0.0625 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0169 - acc: 0.9932 - val_loss: 0.0738 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0180 - acc: 0.9874 - val_loss: 0.0763 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0238 - acc: 0.9909 - val_loss: 0.0706 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0128 - acc: 0.9932 - val_loss: 0.0804 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0080 - acc: 0.9956 - val_loss: 0.0670 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0162 - acc: 0.9905 - val_loss: 0.0740 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0127 - acc: 0.9932 - val_loss: 0.0765 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0157 - acc: 0.9887 - val_loss: 0.0664 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0150 - acc: 0.9942 - val_loss: 0.0718 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0165 - acc: 0.9882 - val_loss: 0.0761 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0159 - acc: 0.9944 - val_loss: 0.0850 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - acc: 0.9916 - val_loss: 0.0843 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0925 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0132 - acc: 0.9973 - val_loss: 0.0567 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0148 - acc: 0.9925 - val_loss: 0.0627 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0184 - acc: 0.9918 - val_loss: 0.0797 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0117 - acc: 0.9921 - val_loss: 0.0822 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.0805 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0111 - acc: 0.9953 - val_loss: 0.0862 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0153 - acc: 0.9863 - val_loss: 0.0852 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0197 - acc: 0.9828 - val_loss: 0.0929 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70f4648c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 172)         8600      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 172)               237360    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1211      \n","=================================================================\n","Total params: 247,171\n","Trainable params: 247,171\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.43 초\n","learning rate: 3.4e-03\n","num_dense_layers: 2\n","num_dense_nodes: 139\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 227\n","Epoch 1/50\n","15/15 [==============================] - 3s 62ms/step - loss: 1.7860 - acc: 0.2899 - val_loss: 0.7264 - val_acc: 0.7949\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4756 - acc: 0.8546 - val_loss: 0.0857 - val_acc: 0.9679\n","Epoch 3/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0772 - acc: 0.9846 - val_loss: 0.0586 - val_acc: 0.9808\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0338 - acc: 0.9868 - val_loss: 0.1262 - val_acc: 0.9808\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0882 - acc: 0.9828 - val_loss: 0.0580 - val_acc: 0.9808\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0246 - acc: 0.9977 - val_loss: 0.0708 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - acc: 0.9971 - val_loss: 0.0999 - val_acc: 0.9808\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0148 - acc: 0.9988 - val_loss: 0.0403 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - acc: 0.9997 - val_loss: 0.0979 - val_acc: 0.9744\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - acc: 0.9967 - val_loss: 0.1028 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 30ms/step - loss: 0.0225 - acc: 0.9900 - val_loss: 0.0764 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0117 - acc: 0.9881 - val_loss: 0.0902 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.1047 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - acc: 0.9942 - val_loss: 0.0970 - val_acc: 0.9744\n","Epoch 15/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0076 - acc: 0.9938 - val_loss: 0.0906 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - acc: 0.9943 - val_loss: 0.0925 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.1023 - val_acc: 0.9744\n","Epoch 18/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0257 - acc: 0.9876 - val_loss: 0.0742 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0145 - acc: 0.9956 - val_loss: 0.0949 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.1102 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0958 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0175 - acc: 0.9884 - val_loss: 0.0988 - val_acc: 0.9744\n","Epoch 23/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.0976 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - acc: 0.9945 - val_loss: 0.1111 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - acc: 0.9925 - val_loss: 0.1106 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - acc: 0.9953 - val_loss: 0.0937 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - acc: 0.9926 - val_loss: 0.0976 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - acc: 0.9973 - val_loss: 0.0963 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0101 - acc: 0.9936 - val_loss: 0.0898 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - acc: 0.9951 - val_loss: 0.0755 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0084 - acc: 0.9922 - val_loss: 0.0793 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0042 - acc: 0.9964 - val_loss: 0.1024 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - acc: 0.9928 - val_loss: 0.1223 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - acc: 0.9956 - val_loss: 0.1091 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0072 - acc: 0.9933 - val_loss: 0.0970 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0147 - acc: 0.9905 - val_loss: 0.1150 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0071 - acc: 0.9967 - val_loss: 0.1212 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0166 - acc: 0.9875 - val_loss: 0.1263 - val_acc: 0.9744\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - acc: 0.9956 - val_loss: 0.1226 - val_acc: 0.9744\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - acc: 0.9930 - val_loss: 0.1129 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0095 - acc: 0.9929 - val_loss: 0.1068 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0091 - acc: 0.9977 - val_loss: 0.1012 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0137 - acc: 0.9897 - val_loss: 0.0679 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0122 - acc: 0.9922 - val_loss: 0.0833 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0079 - acc: 0.9943 - val_loss: 0.0878 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.1045 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - acc: 0.9826 - val_loss: 0.0977 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0089 - acc: 0.9949 - val_loss: 0.1035 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0113 - acc: 0.9925 - val_loss: 0.1161 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0078 - acc: 0.9962 - val_loss: 0.1110 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e1a0b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 227)         11350     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 227)               413140    \n","_________________________________________________________________\n","dense (Dense)                (None, 139)               31692     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 139)               19460     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 980       \n","=================================================================\n","Total params: 476,622\n","Trainable params: 476,622\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.59 초\n","learning rate: 9.7e-04\n","num_dense_layers: 1\n","num_dense_nodes: 212\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 86\n","Epoch 1/50\n","15/15 [==============================] - 4s 116ms/step - loss: 1.9390 - acc: 0.4062 - val_loss: 1.9366 - val_acc: 0.4103\n","Epoch 2/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.9335 - acc: 0.4304 - val_loss: 1.9262 - val_acc: 0.4679\n","Epoch 3/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.9248 - acc: 0.4508 - val_loss: 1.9122 - val_acc: 0.5064\n","Epoch 4/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.9064 - acc: 0.5058 - val_loss: 1.8891 - val_acc: 0.5064\n","Epoch 5/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.8831 - acc: 0.4849 - val_loss: 1.8551 - val_acc: 0.4615\n","Epoch 6/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.8419 - acc: 0.4399 - val_loss: 1.8018 - val_acc: 0.4551\n","Epoch 7/50\n","15/15 [==============================] - 0s 15ms/step - loss: 1.7734 - acc: 0.4256 - val_loss: 1.7304 - val_acc: 0.3782\n","Epoch 8/50\n","15/15 [==============================] - 0s 15ms/step - loss: 1.7535 - acc: 0.3978 - val_loss: 1.6429 - val_acc: 0.5705\n","Epoch 9/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.6156 - acc: 0.5313 - val_loss: 1.5181 - val_acc: 0.5962\n","Epoch 10/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.5528 - acc: 0.5326 - val_loss: 1.3290 - val_acc: 0.6154\n","Epoch 11/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.3109 - acc: 0.5950 - val_loss: 1.0472 - val_acc: 0.6218\n","Epoch 12/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.0656 - acc: 0.6914 - val_loss: 0.7705 - val_acc: 0.7115\n","Epoch 13/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.7753 - acc: 0.7029 - val_loss: 0.5765 - val_acc: 0.8654\n","Epoch 14/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.4992 - acc: 0.9039 - val_loss: 0.4338 - val_acc: 0.9551\n","Epoch 15/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.4253 - acc: 0.9669 - val_loss: 0.3386 - val_acc: 0.9423\n","Epoch 16/50\n","15/15 [==============================] - 0s 28ms/step - loss: 0.3204 - acc: 0.9294 - val_loss: 0.2213 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.2360 - acc: 0.9674 - val_loss: 0.1685 - val_acc: 0.9487\n","Epoch 18/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.2229 - acc: 0.9477 - val_loss: 0.1375 - val_acc: 0.9551\n","Epoch 19/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.1714 - acc: 0.9658 - val_loss: 0.1425 - val_acc: 0.9551\n","Epoch 20/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.1252 - acc: 0.9896 - val_loss: 0.1003 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.1400 - acc: 0.9708 - val_loss: 0.1041 - val_acc: 0.9872\n","Epoch 22/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.1151 - acc: 0.9722 - val_loss: 0.0893 - val_acc: 0.9744\n","Epoch 23/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0971 - acc: 0.9787 - val_loss: 0.0762 - val_acc: 0.9872\n","Epoch 24/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0837 - acc: 0.9833 - val_loss: 0.1073 - val_acc: 0.9551\n","Epoch 25/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.1187 - acc: 0.9637 - val_loss: 0.1020 - val_acc: 0.9487\n","Epoch 26/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0775 - acc: 0.9798 - val_loss: 0.0731 - val_acc: 0.9936\n","Epoch 27/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0733 - acc: 0.9843 - val_loss: 0.0771 - val_acc: 0.9872\n","Epoch 28/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0624 - acc: 0.9841 - val_loss: 0.0730 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0699 - acc: 0.9806 - val_loss: 0.0618 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0887 - acc: 0.9701 - val_loss: 0.0628 - val_acc: 0.9872\n","Epoch 31/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0518 - acc: 0.9882 - val_loss: 0.0685 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0721 - acc: 0.9769 - val_loss: 0.0548 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0725 - acc: 0.9728 - val_loss: 0.0626 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 27ms/step - loss: 0.0629 - acc: 0.9857 - val_loss: 0.0746 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0456 - acc: 0.9896 - val_loss: 0.0609 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0632 - acc: 0.9872 - val_loss: 0.0698 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0400 - acc: 0.9856 - val_loss: 0.0554 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0291 - acc: 0.9930 - val_loss: 0.0583 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0528 - acc: 0.9839 - val_loss: 0.0506 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0468 - acc: 0.9822 - val_loss: 0.0667 - val_acc: 0.9872\n","Epoch 41/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0470 - acc: 0.9812 - val_loss: 0.0532 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0438 - acc: 0.9888 - val_loss: 0.0650 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0470 - acc: 0.9715 - val_loss: 0.0487 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0407 - acc: 0.9802 - val_loss: 0.0549 - val_acc: 0.9872\n","Epoch 45/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0415 - acc: 0.9831 - val_loss: 0.0551 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0390 - acc: 0.9916 - val_loss: 0.0593 - val_acc: 0.9872\n","Epoch 47/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0490 - acc: 0.9793 - val_loss: 0.0410 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0263 - acc: 0.9979 - val_loss: 0.0575 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0296 - acc: 0.9880 - val_loss: 0.0454 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0272 - acc: 0.9909 - val_loss: 0.0508 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70f41d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 86)          4300      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 86)                59512     \n","_________________________________________________________________\n","dense (Dense)                (None, 212)               18444     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 1491      \n","=================================================================\n","Total params: 83,747\n","Trainable params: 83,747\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.56 초\n","learning rate: 1.0e-03\n","num_dense_layers: 1\n","num_dense_nodes: 431\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 215\n","Epoch 1/50\n","15/15 [==============================] - 3s 104ms/step - loss: 1.9414 - acc: 0.2291 - val_loss: 1.9435 - val_acc: 0.1731\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9410 - acc: 0.2295 - val_loss: 1.9433 - val_acc: 0.1731\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9410 - acc: 0.2070 - val_loss: 1.9430 - val_acc: 0.1731\n","Epoch 4/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9410 - acc: 0.2368 - val_loss: 1.9427 - val_acc: 0.1731\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9407 - acc: 0.2377 - val_loss: 1.9425 - val_acc: 0.1731\n","Epoch 6/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9408 - acc: 0.1957 - val_loss: 1.9422 - val_acc: 0.1731\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9401 - acc: 0.2247 - val_loss: 1.9420 - val_acc: 0.1731\n","Epoch 8/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9400 - acc: 0.2358 - val_loss: 1.9417 - val_acc: 0.2436\n","Epoch 9/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9385 - acc: 0.2982 - val_loss: 1.9414 - val_acc: 0.2436\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9399 - acc: 0.2477 - val_loss: 1.9412 - val_acc: 0.2436\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9392 - acc: 0.2688 - val_loss: 1.9409 - val_acc: 0.2436\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9404 - acc: 0.2367 - val_loss: 1.9407 - val_acc: 0.2436\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9395 - acc: 0.2451 - val_loss: 1.9404 - val_acc: 0.2436\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9394 - acc: 0.2462 - val_loss: 1.9401 - val_acc: 0.2436\n","Epoch 15/50\n","15/15 [==============================] - 0s 23ms/step - loss: 1.9378 - acc: 0.2849 - val_loss: 1.9399 - val_acc: 0.2436\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9369 - acc: 0.2795 - val_loss: 1.9396 - val_acc: 0.2436\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9371 - acc: 0.2899 - val_loss: 1.9394 - val_acc: 0.2436\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9383 - acc: 0.2342 - val_loss: 1.9391 - val_acc: 0.2436\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9366 - acc: 0.2809 - val_loss: 1.9388 - val_acc: 0.2436\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9379 - acc: 0.2473 - val_loss: 1.9386 - val_acc: 0.2436\n","Epoch 21/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9372 - acc: 0.2577 - val_loss: 1.9383 - val_acc: 0.2436\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9355 - acc: 0.2847 - val_loss: 1.9381 - val_acc: 0.2436\n","Epoch 23/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9354 - acc: 0.2939 - val_loss: 1.9378 - val_acc: 0.2436\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9346 - acc: 0.2898 - val_loss: 1.9376 - val_acc: 0.2436\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9360 - acc: 0.2582 - val_loss: 1.9373 - val_acc: 0.2436\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9345 - acc: 0.2698 - val_loss: 1.9370 - val_acc: 0.2949\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9351 - acc: 0.3274 - val_loss: 1.9368 - val_acc: 0.2949\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9370 - acc: 0.2541 - val_loss: 1.9365 - val_acc: 0.2949\n","Epoch 29/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9350 - acc: 0.3157 - val_loss: 1.9363 - val_acc: 0.2949\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9347 - acc: 0.3118 - val_loss: 1.9360 - val_acc: 0.2949\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9353 - acc: 0.2962 - val_loss: 1.9358 - val_acc: 0.3013\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9336 - acc: 0.3079 - val_loss: 1.9355 - val_acc: 0.3013\n","Epoch 33/50\n","15/15 [==============================] - 0s 23ms/step - loss: 1.9330 - acc: 0.3391 - val_loss: 1.9353 - val_acc: 0.3013\n","Epoch 34/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9333 - acc: 0.3096 - val_loss: 1.9351 - val_acc: 0.3013\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9331 - acc: 0.3322 - val_loss: 1.9348 - val_acc: 0.3013\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9331 - acc: 0.3130 - val_loss: 1.9345 - val_acc: 0.3013\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9340 - acc: 0.3263 - val_loss: 1.9343 - val_acc: 0.3013\n","Epoch 38/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9332 - acc: 0.3203 - val_loss: 1.9340 - val_acc: 0.3013\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9318 - acc: 0.3111 - val_loss: 1.9338 - val_acc: 0.3013\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9325 - acc: 0.3213 - val_loss: 1.9335 - val_acc: 0.3013\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9324 - acc: 0.3165 - val_loss: 1.9333 - val_acc: 0.3013\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9328 - acc: 0.2848 - val_loss: 1.9331 - val_acc: 0.3013\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9326 - acc: 0.3140 - val_loss: 1.9328 - val_acc: 0.3013\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9321 - acc: 0.3205 - val_loss: 1.9326 - val_acc: 0.3013\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9297 - acc: 0.3423 - val_loss: 1.9323 - val_acc: 0.3013\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9312 - acc: 0.3336 - val_loss: 1.9321 - val_acc: 0.3013\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9307 - acc: 0.3154 - val_loss: 1.9318 - val_acc: 0.3013\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9301 - acc: 0.3155 - val_loss: 1.9316 - val_acc: 0.3013\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9301 - acc: 0.3015 - val_loss: 1.9313 - val_acc: 0.3013\n","Epoch 50/50\n","15/15 [==============================] - 0s 22ms/step - loss: 1.9314 - acc: 0.2744 - val_loss: 1.9311 - val_acc: 0.3013\n","\n","Accuracy: 30.13%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e1a0b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 215)         10750     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 215)               370660    \n","_________________________________________________________________\n","dense (Dense)                (None, 431)               93096     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 3024      \n","=================================================================\n","Total params: 477,530\n","Trainable params: 477,530\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000      27.0\n","           1     0.0000    0.0000    0.0000      20.0\n","           2     0.0000    0.0000    0.0000      37.0\n","           3     0.0000    0.0000    0.0000      17.0\n","           4     0.0000    0.0000    0.0000      34.0\n","           5     0.0000    0.0000    0.0000      11.0\n","           6     0.0000    0.0000    0.0000      10.0\n","          99     0.0000    0.0000    0.0000       0.0\n","\n","    accuracy                         0.0000     156.0\n","   macro avg     0.0000    0.0000    0.0000     156.0\n","weighted avg     0.0000    0.0000    0.0000     156.0\n","\n","샘플예측시간:0.39 초\n","learning rate: 9.0e-03\n","num_dense_layers: 0\n","num_dense_nodes: 495\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 188\n","Epoch 1/50\n","15/15 [==============================] - 4s 107ms/step - loss: 1.6114 - acc: 0.4398 - val_loss: 0.1713 - val_acc: 0.9167\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1322 - acc: 0.9572 - val_loss: 0.0434 - val_acc: 0.9808\n","Epoch 3/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0487 - acc: 0.9854 - val_loss: 0.0483 - val_acc: 0.9808\n","Epoch 4/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0594 - acc: 0.9835 - val_loss: 0.0430 - val_acc: 0.9808\n","Epoch 5/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0479 - acc: 0.9858 - val_loss: 0.0416 - val_acc: 0.9808\n","Epoch 6/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0514 - val_acc: 0.9744\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0311 - acc: 0.9890 - val_loss: 0.0376 - val_acc: 0.9808\n","Epoch 8/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0451 - acc: 0.9894 - val_loss: 0.0448 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0334 - acc: 0.9849 - val_loss: 0.0409 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0245 - acc: 0.9899 - val_loss: 0.0576 - val_acc: 0.9744\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0476 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - acc: 0.9949 - val_loss: 0.0738 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0141 - acc: 0.9924 - val_loss: 0.0449 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0189 - acc: 0.9926 - val_loss: 0.0537 - val_acc: 0.9744\n","Epoch 15/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0084 - acc: 0.9964 - val_loss: 0.0564 - val_acc: 0.9744\n","Epoch 16/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0089 - acc: 0.9959 - val_loss: 0.0705 - val_acc: 0.9744\n","Epoch 17/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0144 - acc: 0.9882 - val_loss: 0.0704 - val_acc: 0.9744\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0141 - acc: 0.9927 - val_loss: 0.0800 - val_acc: 0.9744\n","Epoch 19/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0726 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0177 - acc: 0.9873 - val_loss: 0.0832 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0115 - acc: 0.9912 - val_loss: 0.0986 - val_acc: 0.9744\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0203 - acc: 0.9875 - val_loss: 0.0784 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0631 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0196 - acc: 0.9794 - val_loss: 0.0666 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0102 - acc: 0.9904 - val_loss: 0.0797 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0183 - acc: 0.9808 - val_loss: 0.0752 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0089 - acc: 0.9948 - val_loss: 0.0887 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - acc: 0.9891 - val_loss: 0.0923 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0113 - acc: 0.9915 - val_loss: 0.0931 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0087 - acc: 0.9939 - val_loss: 0.0887 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0128 - acc: 0.9935 - val_loss: 0.0864 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0082 - acc: 0.9914 - val_loss: 0.0935 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0083 - acc: 0.9960 - val_loss: 0.0982 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0925 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - acc: 0.9929 - val_loss: 0.0916 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0160 - acc: 0.9905 - val_loss: 0.0959 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0098 - acc: 0.9918 - val_loss: 0.0977 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0105 - acc: 0.9916 - val_loss: 0.0929 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0185 - acc: 0.9910 - val_loss: 0.1023 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0110 - acc: 0.9949 - val_loss: 0.1103 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0060 - acc: 0.9977 - val_loss: 0.1029 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0176 - acc: 0.9820 - val_loss: 0.0983 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0101 - acc: 0.9894 - val_loss: 0.1009 - val_acc: 0.9744\n","Epoch 44/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0060 - acc: 0.9944 - val_loss: 0.1027 - val_acc: 0.9744\n","Epoch 45/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0151 - acc: 0.9855 - val_loss: 0.1071 - val_acc: 0.9744\n","Epoch 46/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0120 - acc: 0.9931 - val_loss: 0.1039 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0998 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0999 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.1071 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0089 - acc: 0.9935 - val_loss: 0.1084 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70f41d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 188)         9400      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 188)               283504    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1323      \n","=================================================================\n","Total params: 294,227\n","Trainable params: 294,227\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.6 초\n","learning rate: 1.0e-03\n","num_dense_layers: 0\n","num_dense_nodes: 476\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 140\n","Epoch 1/50\n","15/15 [==============================] - 4s 114ms/step - loss: 1.9422 - acc: 0.2913 - val_loss: 1.9373 - val_acc: 0.2500\n","Epoch 2/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9343 - acc: 0.2886 - val_loss: 1.9210 - val_acc: 0.2500\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9206 - acc: 0.2267 - val_loss: 1.8970 - val_acc: 0.1731\n","Epoch 4/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8940 - acc: 0.2179 - val_loss: 1.8614 - val_acc: 0.1731\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8520 - acc: 0.2215 - val_loss: 1.8084 - val_acc: 0.1795\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7915 - acc: 0.2161 - val_loss: 1.7634 - val_acc: 0.1795\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7590 - acc: 0.2573 - val_loss: 1.7045 - val_acc: 0.4295\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7451 - acc: 0.4751 - val_loss: 1.6259 - val_acc: 0.6090\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.6099 - acc: 0.6049 - val_loss: 1.5120 - val_acc: 0.6154\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.5217 - acc: 0.5801 - val_loss: 1.3246 - val_acc: 0.6154\n","Epoch 11/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.3381 - acc: 0.5943 - val_loss: 1.0533 - val_acc: 0.7885\n","Epoch 12/50\n","15/15 [==============================] - 0s 15ms/step - loss: 1.0861 - acc: 0.7001 - val_loss: 0.8050 - val_acc: 0.8333\n","Epoch 13/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.8710 - acc: 0.7598 - val_loss: 0.5739 - val_acc: 0.9231\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.6068 - acc: 0.8990 - val_loss: 0.4223 - val_acc: 0.9038\n","Epoch 15/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.4290 - acc: 0.8994 - val_loss: 0.3100 - val_acc: 0.9487\n","Epoch 16/50\n","15/15 [==============================] - 0s 27ms/step - loss: 0.3343 - acc: 0.9617 - val_loss: 0.2865 - val_acc: 0.9359\n","Epoch 17/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2902 - acc: 0.9449 - val_loss: 0.2136 - val_acc: 0.9487\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2134 - acc: 0.9708 - val_loss: 0.1642 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.2243 - acc: 0.9625 - val_loss: 0.1432 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1838 - acc: 0.9727 - val_loss: 0.1604 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1558 - acc: 0.9786 - val_loss: 0.1138 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.1099 - acc: 0.9849 - val_loss: 0.1082 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1412 - acc: 0.9767 - val_loss: 0.0941 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1272 - acc: 0.9723 - val_loss: 0.1011 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0924 - acc: 0.9838 - val_loss: 0.0842 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0774 - acc: 0.9904 - val_loss: 0.0771 - val_acc: 0.9872\n","Epoch 27/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0808 - acc: 0.9862 - val_loss: 0.0884 - val_acc: 0.9872\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0775 - acc: 0.9880 - val_loss: 0.0720 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0659 - acc: 0.9866 - val_loss: 0.0829 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0827 - acc: 0.9745 - val_loss: 0.0754 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0726 - acc: 0.9827 - val_loss: 0.0616 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0728 - acc: 0.9833 - val_loss: 0.0622 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0486 - acc: 0.9872 - val_loss: 0.0619 - val_acc: 0.9872\n","Epoch 34/50\n","15/15 [==============================] - 0s 28ms/step - loss: 0.0601 - acc: 0.9890 - val_loss: 0.0625 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0536 - acc: 0.9839 - val_loss: 0.0638 - val_acc: 0.9872\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0704 - acc: 0.9766 - val_loss: 0.0716 - val_acc: 0.9744\n","Epoch 37/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0586 - acc: 0.9902 - val_loss: 0.0740 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0690 - acc: 0.9829 - val_loss: 0.0507 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0384 - acc: 0.9943 - val_loss: 0.0488 - val_acc: 0.9872\n","Epoch 40/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0472 - acc: 0.9887 - val_loss: 0.0473 - val_acc: 0.9872\n","Epoch 41/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0503 - acc: 0.9803 - val_loss: 0.0465 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0315 - acc: 0.9946 - val_loss: 0.0437 - val_acc: 0.9872\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0452 - acc: 0.9879 - val_loss: 0.0428 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0271 - acc: 0.9950 - val_loss: 0.0464 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0392 - acc: 0.9971 - val_loss: 0.0446 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0329 - acc: 0.9900 - val_loss: 0.0440 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0315 - acc: 0.9935 - val_loss: 0.0428 - val_acc: 0.9872\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0314 - acc: 0.9928 - val_loss: 0.0509 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0466 - acc: 0.9819 - val_loss: 0.0415 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0330 - acc: 0.9914 - val_loss: 0.0398 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e2906598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 140)         7000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 140)               157360    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 987       \n","=================================================================\n","Total params: 165,347\n","Trainable params: 165,347\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","          99     0.0000    0.0000    0.0000         0\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.8750    0.8557    0.8648       156\n","weighted avg     1.0000    0.9808    0.9899       156\n","\n","샘플예측시간:0.57 초\n","learning rate: 4.6e-03\n","num_dense_layers: 1\n","num_dense_nodes: 195\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 120\n","Epoch 1/50\n","15/15 [==============================] - 3s 105ms/step - loss: 1.7958 - acc: 0.2340 - val_loss: 0.6600 - val_acc: 0.6474\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4460 - acc: 0.8347 - val_loss: 0.1133 - val_acc: 0.9744\n","Epoch 3/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0951 - acc: 0.9889 - val_loss: 0.0481 - val_acc: 0.9808\n","Epoch 4/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0508 - acc: 0.9904 - val_loss: 0.0920 - val_acc: 0.9679\n","Epoch 5/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0639 - acc: 0.9679 - val_loss: 0.0300 - val_acc: 0.9936\n","Epoch 6/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0254 - acc: 0.9876 - val_loss: 0.0522 - val_acc: 0.9744\n","Epoch 7/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0304 - acc: 0.9797 - val_loss: 0.0499 - val_acc: 0.9808\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - acc: 0.9948 - val_loss: 0.0560 - val_acc: 0.9744\n","Epoch 9/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - acc: 0.9932 - val_loss: 0.0545 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0130 - acc: 0.9915 - val_loss: 0.1066 - val_acc: 0.9679\n","Epoch 11/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0451 - acc: 0.9878 - val_loss: 0.0389 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0185 - acc: 0.9988 - val_loss: 0.0481 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0643 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0689 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0208 - acc: 0.9858 - val_loss: 0.0805 - val_acc: 0.9744\n","Epoch 16/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0165 - acc: 0.9965 - val_loss: 0.0524 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0247 - acc: 0.9909 - val_loss: 0.0641 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0265 - acc: 0.9868 - val_loss: 0.0818 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0822 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0192 - acc: 0.9888 - val_loss: 0.0910 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0107 - acc: 0.9981 - val_loss: 0.0893 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0083 - acc: 0.9964 - val_loss: 0.0739 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0164 - acc: 0.9953 - val_loss: 0.0670 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0099 - acc: 0.9960 - val_loss: 0.0825 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0098 - acc: 0.9905 - val_loss: 0.0950 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - acc: 0.9961 - val_loss: 0.1006 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0074 - acc: 0.9943 - val_loss: 0.0945 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0169 - acc: 0.9892 - val_loss: 0.0797 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0889 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0950 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0100 - acc: 0.9965 - val_loss: 0.1051 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - acc: 0.9961 - val_loss: 0.0947 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0113 - acc: 0.9956 - val_loss: 0.0868 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0960 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0210 - acc: 0.9878 - val_loss: 0.0663 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0156 - acc: 0.9977 - val_loss: 0.0737 - val_acc: 0.9744\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0091 - acc: 0.9960 - val_loss: 0.0982 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0120 - acc: 0.9915 - val_loss: 0.1044 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0130 - acc: 0.9898 - val_loss: 0.0991 - val_acc: 0.9744\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0156 - acc: 0.9865 - val_loss: 0.0934 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0055 - acc: 0.9972 - val_loss: 0.0908 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0930 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0061 - acc: 0.9949 - val_loss: 0.0882 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0977 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0087 - acc: 0.9919 - val_loss: 0.1060 - val_acc: 0.9744\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0075 - acc: 0.9949 - val_loss: 0.1024 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - acc: 0.9944 - val_loss: 0.1052 - val_acc: 0.9744\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0061 - acc: 0.9963 - val_loss: 0.1006 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0112 - acc: 0.9922 - val_loss: 0.1051 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0113 - acc: 0.9963 - val_loss: 0.1039 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70f5fc488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 120)         6000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 120)               115680    \n","_________________________________________________________________\n","dense (Dense)                (None, 195)               23595     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 1372      \n","=================================================================\n","Total params: 146,647\n","Trainable params: 146,647\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.42 초\n","learning rate: 1.4e-03\n","num_dense_layers: 1\n","num_dense_nodes: 196\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adadelta.Adadelta'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 69\n","Epoch 1/50\n","15/15 [==============================] - 2s 58ms/step - loss: 1.9462 - acc: 0.1730 - val_loss: 1.9442 - val_acc: 0.2179\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9450 - acc: 0.1815 - val_loss: 1.9440 - val_acc: 0.2179\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9461 - acc: 0.1701 - val_loss: 1.9439 - val_acc: 0.2179\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9451 - acc: 0.1698 - val_loss: 1.9437 - val_acc: 0.2179\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9442 - acc: 0.2085 - val_loss: 1.9435 - val_acc: 0.2244\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9454 - acc: 0.1774 - val_loss: 1.9434 - val_acc: 0.2244\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9451 - acc: 0.1955 - val_loss: 1.9432 - val_acc: 0.2244\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9448 - acc: 0.1930 - val_loss: 1.9430 - val_acc: 0.2244\n","Epoch 9/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9443 - acc: 0.1801 - val_loss: 1.9429 - val_acc: 0.2244\n","Epoch 10/50\n","15/15 [==============================] - 0s 30ms/step - loss: 1.9441 - acc: 0.2038 - val_loss: 1.9427 - val_acc: 0.2244\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9441 - acc: 0.1714 - val_loss: 1.9425 - val_acc: 0.2244\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9437 - acc: 0.1870 - val_loss: 1.9424 - val_acc: 0.2244\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9438 - acc: 0.2025 - val_loss: 1.9422 - val_acc: 0.2244\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9431 - acc: 0.1819 - val_loss: 1.9420 - val_acc: 0.2244\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9443 - acc: 0.1584 - val_loss: 1.9419 - val_acc: 0.2244\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9428 - acc: 0.1880 - val_loss: 1.9417 - val_acc: 0.2244\n","Epoch 17/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9440 - acc: 0.1593 - val_loss: 1.9415 - val_acc: 0.2308\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9441 - acc: 0.1851 - val_loss: 1.9414 - val_acc: 0.2436\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9431 - acc: 0.1853 - val_loss: 1.9412 - val_acc: 0.2628\n","Epoch 20/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9416 - acc: 0.2168 - val_loss: 1.9410 - val_acc: 0.2628\n","Epoch 21/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9430 - acc: 0.2139 - val_loss: 1.9409 - val_acc: 0.3269\n","Epoch 22/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9425 - acc: 0.2312 - val_loss: 1.9407 - val_acc: 0.3269\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9426 - acc: 0.2562 - val_loss: 1.9405 - val_acc: 0.3269\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9433 - acc: 0.2255 - val_loss: 1.9404 - val_acc: 0.3269\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9429 - acc: 0.2285 - val_loss: 1.9402 - val_acc: 0.3269\n","Epoch 26/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9412 - acc: 0.2565 - val_loss: 1.9400 - val_acc: 0.3269\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9422 - acc: 0.2440 - val_loss: 1.9399 - val_acc: 0.3269\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9411 - acc: 0.2318 - val_loss: 1.9397 - val_acc: 0.3269\n","Epoch 29/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9405 - acc: 0.2893 - val_loss: 1.9395 - val_acc: 0.3269\n","Epoch 30/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9411 - acc: 0.2435 - val_loss: 1.9394 - val_acc: 0.3269\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9411 - acc: 0.2546 - val_loss: 1.9392 - val_acc: 0.3269\n","Epoch 32/50\n","15/15 [==============================] - 0s 22ms/step - loss: 1.9408 - acc: 0.2533 - val_loss: 1.9390 - val_acc: 0.3269\n","Epoch 33/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9405 - acc: 0.2822 - val_loss: 1.9389 - val_acc: 0.3654\n","Epoch 34/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9410 - acc: 0.2845 - val_loss: 1.9387 - val_acc: 0.3782\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9402 - acc: 0.3275 - val_loss: 1.9386 - val_acc: 0.3782\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9408 - acc: 0.2888 - val_loss: 1.9384 - val_acc: 0.3782\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9408 - acc: 0.3006 - val_loss: 1.9382 - val_acc: 0.3782\n","Epoch 38/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9394 - acc: 0.3516 - val_loss: 1.9381 - val_acc: 0.3782\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9405 - acc: 0.2998 - val_loss: 1.9379 - val_acc: 0.3782\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9402 - acc: 0.2850 - val_loss: 1.9378 - val_acc: 0.3782\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9394 - acc: 0.3209 - val_loss: 1.9376 - val_acc: 0.3782\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9401 - acc: 0.2811 - val_loss: 1.9374 - val_acc: 0.3782\n","Epoch 43/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9389 - acc: 0.3343 - val_loss: 1.9373 - val_acc: 0.4679\n","Epoch 44/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9384 - acc: 0.3997 - val_loss: 1.9371 - val_acc: 0.4679\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9405 - acc: 0.3387 - val_loss: 1.9370 - val_acc: 0.4679\n","Epoch 46/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9389 - acc: 0.3907 - val_loss: 1.9368 - val_acc: 0.4679\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9380 - acc: 0.4092 - val_loss: 1.9366 - val_acc: 0.4679\n","Epoch 48/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9381 - acc: 0.3826 - val_loss: 1.9365 - val_acc: 0.4679\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9384 - acc: 0.3748 - val_loss: 1.9363 - val_acc: 0.4679\n","Epoch 50/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9399 - acc: 0.3414 - val_loss: 1.9361 - val_acc: 0.4679\n","\n","Accuracy: 46.79%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e19fa8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 69)          3450      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 69)                38364     \n","_________________________________________________________________\n","dense (Dense)                (None, 196)               13720     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 1379      \n","=================================================================\n","Total params: 56,913\n","Trainable params: 56,913\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000      27.0\n","           1     0.0000    0.0000    0.0000      20.0\n","           2     0.0000    0.0000    0.0000      37.0\n","           3     0.0000    0.0000    0.0000      17.0\n","           4     0.0000    0.0000    0.0000      34.0\n","           5     0.0000    0.0000    0.0000      11.0\n","           6     0.0000    0.0000    0.0000      10.0\n","          99     0.0000    0.0000    0.0000       0.0\n","\n","    accuracy                         0.0000     156.0\n","   macro avg     0.0000    0.0000    0.0000     156.0\n","weighted avg     0.0000    0.0000    0.0000     156.0\n","\n","샘플예측시간:0.4 초\n","learning rate: 7.2e-04\n","num_dense_layers: 1\n","num_dense_nodes: 446\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 66ms/step - loss: 1.8825 - acc: 0.2899 - val_loss: 1.6698 - val_acc: 0.2179\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5554 - acc: 0.4149 - val_loss: 0.9941 - val_acc: 0.5833\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7754 - acc: 0.7861 - val_loss: 0.2841 - val_acc: 0.9231\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2205 - acc: 0.9507 - val_loss: 0.1492 - val_acc: 0.9487\n","Epoch 5/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1125 - acc: 0.9893 - val_loss: 0.0663 - val_acc: 0.9872\n","Epoch 6/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.1206 - acc: 0.9738 - val_loss: 0.1187 - val_acc: 0.9744\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0779 - acc: 0.9844 - val_loss: 0.0771 - val_acc: 0.9551\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0528 - acc: 0.9869 - val_loss: 0.0449 - val_acc: 0.9872\n","Epoch 9/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0538 - acc: 0.9851 - val_loss: 0.0486 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0590 - acc: 0.9791 - val_loss: 0.0364 - val_acc: 0.9936\n","Epoch 11/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0354 - acc: 0.9843 - val_loss: 0.0651 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0379 - acc: 0.9894 - val_loss: 0.0712 - val_acc: 0.9679\n","Epoch 13/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0295 - acc: 0.9928 - val_loss: 0.0801 - val_acc: 0.9744\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0385 - acc: 0.9827 - val_loss: 0.0616 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0463 - acc: 0.9808 - val_loss: 0.0305 - val_acc: 0.9936\n","Epoch 16/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0321 - acc: 0.9893 - val_loss: 0.0343 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0116 - acc: 0.9941 - val_loss: 0.1071 - val_acc: 0.9679\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0328 - acc: 0.9813 - val_loss: 0.0509 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0452 - acc: 0.9750 - val_loss: 0.0538 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0204 - acc: 0.9909 - val_loss: 0.0556 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - acc: 0.9952 - val_loss: 0.0353 - val_acc: 0.9936\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0274 - acc: 0.9900 - val_loss: 0.0552 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0209 - acc: 0.9956 - val_loss: 0.0627 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0186 - acc: 0.9898 - val_loss: 0.0766 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0171 - acc: 0.9923 - val_loss: 0.0794 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0214 - acc: 0.9920 - val_loss: 0.0576 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0593 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0152 - acc: 0.9942 - val_loss: 0.0674 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0166 - acc: 0.9898 - val_loss: 0.0758 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0262 - acc: 0.9806 - val_loss: 0.0649 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0875 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0092 - acc: 0.9988 - val_loss: 0.0668 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0224 - acc: 0.9861 - val_loss: 0.0645 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 0.0678 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0145 - acc: 0.9916 - val_loss: 0.0568 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0204 - acc: 0.9882 - val_loss: 0.0795 - val_acc: 0.9744\n","Epoch 37/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0579 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0101 - acc: 0.9961 - val_loss: 0.0879 - val_acc: 0.9744\n","Epoch 39/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - acc: 0.9928 - val_loss: 0.0822 - val_acc: 0.9744\n","Epoch 40/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0098 - acc: 0.9933 - val_loss: 0.0746 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0141 - acc: 0.9925 - val_loss: 0.0800 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0574 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0134 - acc: 0.9950 - val_loss: 0.0677 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0182 - acc: 0.9924 - val_loss: 0.0761 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0121 - acc: 0.9934 - val_loss: 0.0662 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.0703 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0846 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0847 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0735 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0835 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70f464378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 446)               107486    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 3129      \n","=================================================================\n","Total params: 584,375\n","Trainable params: 584,375\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 1.0e-04\n","num_dense_layers: 0\n","num_dense_nodes: 408\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 3s 101ms/step - loss: 1.9414 - acc: 0.2427 - val_loss: 1.9361 - val_acc: 0.1795\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9337 - acc: 0.2084 - val_loss: 1.9281 - val_acc: 0.1731\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9258 - acc: 0.2003 - val_loss: 1.9197 - val_acc: 0.1731\n","Epoch 4/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9158 - acc: 0.2259 - val_loss: 1.9107 - val_acc: 0.1731\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9093 - acc: 0.2139 - val_loss: 1.9009 - val_acc: 0.1731\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8971 - acc: 0.2205 - val_loss: 1.8901 - val_acc: 0.1731\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8919 - acc: 0.2064 - val_loss: 1.8785 - val_acc: 0.1731\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8623 - acc: 0.2748 - val_loss: 1.8650 - val_acc: 0.1731\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8581 - acc: 0.2117 - val_loss: 1.8497 - val_acc: 0.1731\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8446 - acc: 0.2355 - val_loss: 1.8332 - val_acc: 0.1731\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8315 - acc: 0.2070 - val_loss: 1.8143 - val_acc: 0.1731\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.8238 - acc: 0.2187 - val_loss: 1.7969 - val_acc: 0.1731\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7980 - acc: 0.2259 - val_loss: 1.7754 - val_acc: 0.1731\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7676 - acc: 0.2285 - val_loss: 1.7548 - val_acc: 0.1731\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7247 - acc: 0.2535 - val_loss: 1.7344 - val_acc: 0.1795\n","Epoch 16/50\n","15/15 [==============================] - 0s 22ms/step - loss: 1.7700 - acc: 0.2642 - val_loss: 1.7135 - val_acc: 0.2949\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7240 - acc: 0.3234 - val_loss: 1.6904 - val_acc: 0.4936\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6792 - acc: 0.4637 - val_loss: 1.6679 - val_acc: 0.4936\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6834 - acc: 0.4376 - val_loss: 1.6440 - val_acc: 0.5577\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6512 - acc: 0.5086 - val_loss: 1.6162 - val_acc: 0.5897\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6063 - acc: 0.5717 - val_loss: 1.5853 - val_acc: 0.6090\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5999 - acc: 0.5663 - val_loss: 1.5513 - val_acc: 0.6090\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5537 - acc: 0.5663 - val_loss: 1.5163 - val_acc: 0.6090\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.5139 - acc: 0.5871 - val_loss: 1.4756 - val_acc: 0.6154\n","Epoch 25/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.4841 - acc: 0.5859 - val_loss: 1.4346 - val_acc: 0.6154\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4881 - acc: 0.5624 - val_loss: 1.3902 - val_acc: 0.6154\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4154 - acc: 0.5761 - val_loss: 1.3421 - val_acc: 0.6154\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.3476 - acc: 0.6013 - val_loss: 1.2896 - val_acc: 0.6154\n","Epoch 29/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.3142 - acc: 0.6018 - val_loss: 1.2389 - val_acc: 0.6154\n","Epoch 30/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.2588 - acc: 0.6254 - val_loss: 1.1835 - val_acc: 0.6282\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.2017 - acc: 0.6121 - val_loss: 1.1298 - val_acc: 0.6282\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.2032 - acc: 0.5698 - val_loss: 1.0720 - val_acc: 0.6346\n","Epoch 33/50\n","15/15 [==============================] - 0s 22ms/step - loss: 1.0773 - acc: 0.6371 - val_loss: 1.0156 - val_acc: 0.6538\n","Epoch 34/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.0659 - acc: 0.6141 - val_loss: 0.9614 - val_acc: 0.6859\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.0243 - acc: 0.6288 - val_loss: 0.9068 - val_acc: 0.7500\n","Epoch 36/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.9873 - acc: 0.6265 - val_loss: 0.8575 - val_acc: 0.7564\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.9076 - acc: 0.7112 - val_loss: 0.8083 - val_acc: 0.8333\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.8526 - acc: 0.8080 - val_loss: 0.7643 - val_acc: 0.8397\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.8192 - acc: 0.8049 - val_loss: 0.7184 - val_acc: 0.8397\n","Epoch 40/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.7500 - acc: 0.8189 - val_loss: 0.6827 - val_acc: 0.8782\n","Epoch 41/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.7656 - acc: 0.8196 - val_loss: 0.6441 - val_acc: 0.9103\n","Epoch 42/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.6893 - acc: 0.8430 - val_loss: 0.6095 - val_acc: 0.8782\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.6411 - acc: 0.8644 - val_loss: 0.5761 - val_acc: 0.9231\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.6125 - acc: 0.9256 - val_loss: 0.5477 - val_acc: 0.9103\n","Epoch 45/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.5774 - acc: 0.8722 - val_loss: 0.5207 - val_acc: 0.9231\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.5546 - acc: 0.9087 - val_loss: 0.4936 - val_acc: 0.9231\n","Epoch 47/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.5323 - acc: 0.9075 - val_loss: 0.4737 - val_acc: 0.9295\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4859 - acc: 0.9310 - val_loss: 0.4492 - val_acc: 0.9295\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4818 - acc: 0.9280 - val_loss: 0.4325 - val_acc: 0.9295\n","Epoch 50/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4640 - acc: 0.9193 - val_loss: 0.4121 - val_acc: 0.9295\n","\n","Accuracy: 92.95%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70f3f8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 427       \n","=================================================================\n","Total params: 32,467\n","Trainable params: 32,467\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.7714    1.0000    0.8710        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     0.8824    0.8824    0.8824        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    0.1000    0.1818        10\n","          99     0.0000    0.0000    0.0000         0\n","\n","    accuracy                         0.9295       156\n","   macro avg     0.8317    0.7478    0.7419       156\n","weighted avg     0.9476    0.9295    0.9124       156\n","\n","샘플예측시간:0.56 초\n","learning rate: 1.0e-02\n","num_dense_layers: 0\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 4s 111ms/step - loss: 1.9334 - acc: 0.2915 - val_loss: 1.8294 - val_acc: 0.1731\n","Epoch 2/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7873 - acc: 0.2666 - val_loss: 1.5515 - val_acc: 0.6154\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.4507 - acc: 0.6096 - val_loss: 0.7563 - val_acc: 0.8269\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6520 - acc: 0.8464 - val_loss: 0.1633 - val_acc: 0.9744\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1753 - acc: 0.9747 - val_loss: 0.0597 - val_acc: 0.9744\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0911 - acc: 0.9710 - val_loss: 0.0540 - val_acc: 0.9872\n","Epoch 7/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0437 - acc: 0.9823 - val_loss: 0.0452 - val_acc: 0.9872\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0364 - acc: 0.9926 - val_loss: 0.0419 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0463 - acc: 0.9866 - val_loss: 0.0527 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0366 - acc: 0.9934 - val_loss: 0.0494 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0589 - acc: 0.9808 - val_loss: 0.0454 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0310 - acc: 0.9960 - val_loss: 0.0384 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0177 - acc: 0.9916 - val_loss: 0.0418 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0258 - acc: 0.9969 - val_loss: 0.0416 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0262 - acc: 0.9951 - val_loss: 0.0525 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0269 - acc: 0.9811 - val_loss: 0.0482 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0151 - acc: 0.9959 - val_loss: 0.0486 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.0520 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0323 - acc: 0.9857 - val_loss: 0.0476 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0175 - acc: 0.9959 - val_loss: 0.0504 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0171 - acc: 0.9887 - val_loss: 0.0717 - val_acc: 0.9744\n","Epoch 22/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0219 - acc: 0.9942 - val_loss: 0.0518 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0250 - acc: 0.9870 - val_loss: 0.0681 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0213 - acc: 0.9879 - val_loss: 0.0637 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - acc: 0.9947 - val_loss: 0.0588 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0160 - acc: 0.9929 - val_loss: 0.0543 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0181 - acc: 0.9961 - val_loss: 0.0512 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0188 - acc: 0.9929 - val_loss: 0.0743 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0252 - acc: 0.9789 - val_loss: 0.0948 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0055 - acc: 0.9978 - val_loss: 0.0839 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.0814 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - acc: 0.9991 - val_loss: 0.0871 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0195 - acc: 0.9907 - val_loss: 0.0747 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0157 - acc: 0.9925 - val_loss: 0.0947 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0098 - acc: 0.9957 - val_loss: 0.0828 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0116 - acc: 0.9940 - val_loss: 0.0794 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0127 - acc: 0.9909 - val_loss: 0.0857 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0909 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0076 - acc: 0.9943 - val_loss: 0.0751 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0088 - acc: 0.9949 - val_loss: 0.1016 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0192 - acc: 0.9861 - val_loss: 0.1091 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0135 - acc: 0.9900 - val_loss: 0.0864 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0191 - acc: 0.9892 - val_loss: 0.0950 - val_acc: 0.9744\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0946 - val_acc: 0.9744\n","Epoch 45/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0155 - acc: 0.9928 - val_loss: 0.0694 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0210 - acc: 0.9957 - val_loss: 0.0983 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0160 - acc: 0.9908 - val_loss: 0.0924 - val_acc: 0.9744\n","Epoch 48/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0761 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0094 - acc: 0.9965 - val_loss: 0.0919 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0070 - acc: 0.9961 - val_loss: 0.1005 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70e54e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1687      \n","=================================================================\n","Total params: 475,447\n","Trainable params: 475,447\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.58 초\n","learning rate: 1.0e-02\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 4s 114ms/step - loss: 1.6871 - acc: 0.4093 - val_loss: 0.1746 - val_acc: 0.9359\n","Epoch 2/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2743 - acc: 0.9157 - val_loss: 0.0865 - val_acc: 0.9744\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0902 - acc: 0.9734 - val_loss: 0.2063 - val_acc: 0.9103\n","Epoch 4/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0803 - acc: 0.9622 - val_loss: 0.1590 - val_acc: 0.9679\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0507 - acc: 0.9867 - val_loss: 0.0577 - val_acc: 0.9808\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0504 - acc: 0.9861 - val_loss: 0.0665 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0139 - acc: 0.9972 - val_loss: 0.0847 - val_acc: 0.9679\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0233 - acc: 0.9982 - val_loss: 0.0693 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0133 - acc: 0.9981 - val_loss: 0.0663 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0213 - acc: 0.9884 - val_loss: 0.0587 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0174 - acc: 0.9910 - val_loss: 0.1031 - val_acc: 0.9744\n","Epoch 12/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0222 - acc: 0.9886 - val_loss: 0.0724 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0826 - val_acc: 0.9744\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0185 - acc: 0.9974 - val_loss: 0.0801 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0145 - acc: 0.9943 - val_loss: 0.0976 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0138 - acc: 0.9977 - val_loss: 0.0607 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0124 - acc: 0.9931 - val_loss: 0.1049 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0097 - acc: 0.9963 - val_loss: 0.0822 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0126 - acc: 0.9931 - val_loss: 0.0881 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0936 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0184 - acc: 0.9911 - val_loss: 0.0769 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0153 - acc: 0.9927 - val_loss: 0.0924 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0137 - acc: 0.9951 - val_loss: 0.0902 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - acc: 0.9897 - val_loss: 0.0967 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.1031 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0154 - acc: 0.9926 - val_loss: 0.0909 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0053 - acc: 0.9962 - val_loss: 0.0987 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0132 - acc: 0.9869 - val_loss: 0.1188 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0059 - acc: 0.9989 - val_loss: 0.0816 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0139 - acc: 0.9889 - val_loss: 0.0902 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0105 - acc: 0.9957 - val_loss: 0.1008 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0058 - acc: 0.9965 - val_loss: 0.0918 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0184 - acc: 0.9829 - val_loss: 0.1062 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0100 - acc: 0.9949 - val_loss: 0.0988 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0092 - acc: 0.9957 - val_loss: 0.1029 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0116 - acc: 0.9883 - val_loss: 0.1009 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0144 - acc: 0.9893 - val_loss: 0.1108 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0067 - acc: 0.9960 - val_loss: 0.0979 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0081 - acc: 0.9929 - val_loss: 0.1048 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0105 - acc: 0.9944 - val_loss: 0.1038 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0081 - acc: 0.9985 - val_loss: 0.1140 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0079 - acc: 0.9937 - val_loss: 0.0507 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0184 - acc: 0.9920 - val_loss: 0.0753 - val_acc: 0.9744\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0122 - acc: 0.9877 - val_loss: 0.0871 - val_acc: 0.9744\n","Epoch 45/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0101 - acc: 0.9933 - val_loss: 0.0948 - val_acc: 0.9744\n","Epoch 46/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0795 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0152 - acc: 0.9915 - val_loss: 0.0793 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0062 - acc: 0.9923 - val_loss: 0.0857 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0972 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0145 - acc: 0.9864 - val_loss: 0.1061 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70e58e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               31232     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 329,519\n","Trainable params: 329,519\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.59 초\n","learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 3s 61ms/step - loss: 1.9396 - acc: 0.2302 - val_loss: 1.9188 - val_acc: 0.2949\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9133 - acc: 0.3149 - val_loss: 1.8876 - val_acc: 0.3782\n","Epoch 3/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.8790 - acc: 0.3913 - val_loss: 1.8460 - val_acc: 0.4167\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8422 - acc: 0.3775 - val_loss: 1.7928 - val_acc: 0.3782\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7672 - acc: 0.4322 - val_loss: 1.7260 - val_acc: 0.4167\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7063 - acc: 0.5371 - val_loss: 1.6462 - val_acc: 0.5769\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6469 - acc: 0.5604 - val_loss: 1.5541 - val_acc: 0.6090\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5679 - acc: 0.5739 - val_loss: 1.4387 - val_acc: 0.6154\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4132 - acc: 0.6215 - val_loss: 1.3005 - val_acc: 0.6154\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.3256 - acc: 0.5847 - val_loss: 1.1531 - val_acc: 0.6282\n","Epoch 11/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.1627 - acc: 0.5922 - val_loss: 1.0008 - val_acc: 0.6795\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.0322 - acc: 0.6406 - val_loss: 0.8623 - val_acc: 0.7051\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.8098 - acc: 0.7153 - val_loss: 0.7316 - val_acc: 0.7244\n","Epoch 14/50\n","15/15 [==============================] - 0s 31ms/step - loss: 0.7672 - acc: 0.7338 - val_loss: 0.6213 - val_acc: 0.9103\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.6556 - acc: 0.8723 - val_loss: 0.5184 - val_acc: 0.9231\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.5346 - acc: 0.8844 - val_loss: 0.4321 - val_acc: 0.9231\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4645 - acc: 0.8962 - val_loss: 0.3595 - val_acc: 0.9359\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.3577 - acc: 0.9315 - val_loss: 0.2956 - val_acc: 0.9359\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.3075 - acc: 0.9431 - val_loss: 0.2471 - val_acc: 0.9487\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2879 - acc: 0.9470 - val_loss: 0.2088 - val_acc: 0.9551\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2207 - acc: 0.9724 - val_loss: 0.1731 - val_acc: 0.9615\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1951 - acc: 0.9814 - val_loss: 0.1681 - val_acc: 0.9487\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1764 - acc: 0.9677 - val_loss: 0.1323 - val_acc: 0.9872\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1344 - acc: 0.9859 - val_loss: 0.1165 - val_acc: 0.9872\n","Epoch 25/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1086 - acc: 0.9850 - val_loss: 0.1058 - val_acc: 0.9872\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1153 - acc: 0.9804 - val_loss: 0.0991 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1182 - acc: 0.9733 - val_loss: 0.0915 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0910 - acc: 0.9850 - val_loss: 0.0862 - val_acc: 0.9872\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0732 - acc: 0.9849 - val_loss: 0.0811 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0797 - acc: 0.9766 - val_loss: 0.0769 - val_acc: 0.9872\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0617 - acc: 0.9878 - val_loss: 0.0753 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0647 - acc: 0.9902 - val_loss: 0.0677 - val_acc: 0.9872\n","Epoch 33/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0509 - acc: 0.9883 - val_loss: 0.0666 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0631 - acc: 0.9827 - val_loss: 0.0808 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0607 - acc: 0.9790 - val_loss: 0.0597 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0578 - acc: 0.9830 - val_loss: 0.0614 - val_acc: 0.9872\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0389 - acc: 0.9928 - val_loss: 0.0588 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0487 - acc: 0.9854 - val_loss: 0.0659 - val_acc: 0.9872\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0444 - acc: 0.9844 - val_loss: 0.0571 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0480 - acc: 0.9932 - val_loss: 0.0606 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0368 - acc: 0.9898 - val_loss: 0.0550 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0453 - acc: 0.9910 - val_loss: 0.0511 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0327 - acc: 0.9916 - val_loss: 0.0514 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0490 - acc: 0.9889 - val_loss: 0.0600 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0635 - acc: 0.9721 - val_loss: 0.0493 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0458 - acc: 0.9817 - val_loss: 0.0538 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0407 - acc: 0.9809 - val_loss: 0.0467 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0435 - acc: 0.9869 - val_loss: 0.0510 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0391 - acc: 0.9864 - val_loss: 0.0546 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0290 - acc: 0.9933 - val_loss: 0.0461 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7a6f5dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               31232     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 329,519\n","Trainable params: 329,519\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.41 초\n","learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 5s 122ms/step - loss: 1.9476 - acc: 0.0970 - val_loss: 1.9464 - val_acc: 0.1282\n","Epoch 2/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.9448 - acc: 0.1325 - val_loss: 1.9435 - val_acc: 0.1282\n","Epoch 3/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9436 - acc: 0.1070 - val_loss: 1.9406 - val_acc: 0.2115\n","Epoch 4/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9415 - acc: 0.1637 - val_loss: 1.9382 - val_acc: 0.2115\n","Epoch 5/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9394 - acc: 0.1446 - val_loss: 1.9357 - val_acc: 0.1346\n","Epoch 6/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9367 - acc: 0.1319 - val_loss: 1.9332 - val_acc: 0.1346\n","Epoch 7/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9359 - acc: 0.1084 - val_loss: 1.9303 - val_acc: 0.1346\n","Epoch 8/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9330 - acc: 0.1066 - val_loss: 1.9272 - val_acc: 0.1346\n","Epoch 9/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.9285 - acc: 0.1211 - val_loss: 1.9235 - val_acc: 0.1346\n","Epoch 10/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9277 - acc: 0.0985 - val_loss: 1.9199 - val_acc: 0.1346\n","Epoch 11/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9249 - acc: 0.0910 - val_loss: 1.9157 - val_acc: 0.1346\n","Epoch 12/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.9209 - acc: 0.1191 - val_loss: 1.9112 - val_acc: 0.1346\n","Epoch 13/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.9140 - acc: 0.0988 - val_loss: 1.9057 - val_acc: 0.1346\n","Epoch 14/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.9110 - acc: 0.0986 - val_loss: 1.8999 - val_acc: 0.1346\n","Epoch 15/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.9033 - acc: 0.1111 - val_loss: 1.8927 - val_acc: 0.1282\n","Epoch 16/50\n","15/15 [==============================] - 0s 30ms/step - loss: 1.9002 - acc: 0.0959 - val_loss: 1.8849 - val_acc: 0.1282\n","Epoch 17/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.8903 - acc: 0.1066 - val_loss: 1.8755 - val_acc: 0.1282\n","Epoch 18/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.8853 - acc: 0.0922 - val_loss: 1.8652 - val_acc: 0.1282\n","Epoch 19/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.8747 - acc: 0.1063 - val_loss: 1.8537 - val_acc: 0.1282\n","Epoch 20/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.8630 - acc: 0.1060 - val_loss: 1.8409 - val_acc: 0.1282\n","Epoch 21/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.8535 - acc: 0.1070 - val_loss: 1.8271 - val_acc: 0.1282\n","Epoch 22/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.8375 - acc: 0.1097 - val_loss: 1.8121 - val_acc: 0.1282\n","Epoch 23/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.8325 - acc: 0.1095 - val_loss: 1.7952 - val_acc: 0.1282\n","Epoch 24/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.8069 - acc: 0.1335 - val_loss: 1.7758 - val_acc: 0.1282\n","Epoch 25/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.7914 - acc: 0.1195 - val_loss: 1.7553 - val_acc: 0.1282\n","Epoch 26/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.7644 - acc: 0.1020 - val_loss: 1.7300 - val_acc: 0.1282\n","Epoch 27/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.7452 - acc: 0.1325 - val_loss: 1.7041 - val_acc: 0.1282\n","Epoch 28/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.7378 - acc: 0.1072 - val_loss: 1.6765 - val_acc: 0.1282\n","Epoch 29/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.7033 - acc: 0.1071 - val_loss: 1.6439 - val_acc: 0.1282\n","Epoch 30/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.6821 - acc: 0.1204 - val_loss: 1.6077 - val_acc: 0.1282\n","Epoch 31/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.6439 - acc: 0.1758 - val_loss: 1.5737 - val_acc: 0.1346\n","Epoch 32/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.6127 - acc: 0.2017 - val_loss: 1.5333 - val_acc: 0.2500\n","Epoch 33/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.5722 - acc: 0.2564 - val_loss: 1.4698 - val_acc: 0.4487\n","Epoch 34/50\n","15/15 [==============================] - 0s 30ms/step - loss: 1.5522 - acc: 0.3133 - val_loss: 1.4150 - val_acc: 0.4551\n","Epoch 35/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.5037 - acc: 0.3571 - val_loss: 1.3519 - val_acc: 0.5128\n","Epoch 36/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.4050 - acc: 0.4006 - val_loss: 1.2836 - val_acc: 0.5833\n","Epoch 37/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.3372 - acc: 0.4650 - val_loss: 1.2323 - val_acc: 0.6538\n","Epoch 38/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.2822 - acc: 0.5590 - val_loss: 1.1757 - val_acc: 0.5962\n","Epoch 39/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.2407 - acc: 0.5699 - val_loss: 1.1258 - val_acc: 0.6474\n","Epoch 40/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.1790 - acc: 0.6011 - val_loss: 1.1034 - val_acc: 0.6538\n","Epoch 41/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.1839 - acc: 0.6043 - val_loss: 1.0413 - val_acc: 0.6667\n","Epoch 42/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.1544 - acc: 0.5886 - val_loss: 1.0048 - val_acc: 0.6667\n","Epoch 43/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.0891 - acc: 0.6222 - val_loss: 0.9750 - val_acc: 0.7115\n","Epoch 44/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.0776 - acc: 0.6068 - val_loss: 0.9398 - val_acc: 0.7051\n","Epoch 45/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.9329 - acc: 0.6861 - val_loss: 0.9023 - val_acc: 0.7115\n","Epoch 46/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.9627 - acc: 0.6822 - val_loss: 0.8769 - val_acc: 0.7436\n","Epoch 47/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.8918 - acc: 0.7414 - val_loss: 0.8415 - val_acc: 0.7500\n","Epoch 48/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.9210 - acc: 0.7086 - val_loss: 0.8117 - val_acc: 0.8141\n","Epoch 49/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.8747 - acc: 0.7124 - val_loss: 0.7874 - val_acc: 0.8013\n","Epoch 50/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.8574 - acc: 0.7867 - val_loss: 0.7552 - val_acc: 0.8077\n","\n","Accuracy: 80.77%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70ee1f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 1928      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 63        \n","=================================================================\n","Total params: 475,823\n","Trainable params: 475,823\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.7037    0.8261        27\n","           1     0.5714    1.0000    0.7273        20\n","           2     0.9737    1.0000    0.9867        37\n","           3     0.5652    0.7647    0.6500        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     0.0000    0.0000    0.0000        11\n","           6     1.0000    0.3000    0.4615        10\n","          99     0.0000    0.0000    0.0000         0\n","\n","    accuracy                         0.8077       156\n","   macro avg     0.6388    0.5961    0.5814       156\n","weighted avg     0.8209    0.8077    0.7886       156\n","\n","샘플예측시간:0.41 초\n","learning rate: 1.0e-02\n","num_dense_layers: 1\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 3s 63ms/step - loss: 1.5041 - acc: 0.4459 - val_loss: 0.2882 - val_acc: 0.8590\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1029 - acc: 0.9493 - val_loss: 0.1553 - val_acc: 0.9744\n","Epoch 3/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0686 - acc: 0.9832 - val_loss: 0.0468 - val_acc: 0.9808\n","Epoch 4/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0166 - acc: 0.9934 - val_loss: 0.0435 - val_acc: 0.9808\n","Epoch 5/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0251 - acc: 0.9901 - val_loss: 0.0672 - val_acc: 0.9744\n","Epoch 6/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0311 - acc: 0.9781 - val_loss: 0.0497 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0161 - acc: 0.9971 - val_loss: 0.0809 - val_acc: 0.9744\n","Epoch 8/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0168 - acc: 0.9887 - val_loss: 0.0563 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0203 - acc: 0.9960 - val_loss: 0.0651 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0180 - acc: 0.9878 - val_loss: 0.0675 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - acc: 0.9990 - val_loss: 0.0760 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0237 - acc: 0.9850 - val_loss: 0.0631 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0174 - acc: 0.9907 - val_loss: 0.0740 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0212 - acc: 0.9884 - val_loss: 0.0795 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0272 - acc: 0.9878 - val_loss: 0.0836 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0198 - acc: 0.9920 - val_loss: 0.0953 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0139 - acc: 0.9947 - val_loss: 0.0802 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0115 - acc: 0.9948 - val_loss: 0.0868 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0128 - acc: 0.9893 - val_loss: 0.0793 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0160 - acc: 0.9898 - val_loss: 0.0877 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0177 - acc: 0.9908 - val_loss: 0.0922 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0200 - acc: 0.9843 - val_loss: 0.0522 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - acc: 0.9907 - val_loss: 0.0770 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0059 - acc: 0.9960 - val_loss: 0.0927 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.1009 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0076 - acc: 0.9948 - val_loss: 0.1009 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0071 - acc: 0.9944 - val_loss: 0.1050 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0120 - acc: 0.9884 - val_loss: 0.1028 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0139 - acc: 0.9908 - val_loss: 0.1016 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0816 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0110 - acc: 0.9921 - val_loss: 0.0853 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0091 - acc: 0.9962 - val_loss: 0.0939 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.1008 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0966 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0051 - acc: 0.9979 - val_loss: 0.0995 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0992 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0091 - acc: 0.9954 - val_loss: 0.0982 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.0079 - acc: 0.9936 - val_loss: 0.0997 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0082 - acc: 0.9945 - val_loss: 0.1071 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0111 - acc: 0.9911 - val_loss: 0.1045 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - acc: 0.9898 - val_loss: 0.1019 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0203 - acc: 0.9836 - val_loss: 0.0991 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0166 - acc: 0.9848 - val_loss: 0.1023 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0055 - acc: 0.9951 - val_loss: 0.0974 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1003 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0121 - acc: 0.9916 - val_loss: 0.1030 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0096 - acc: 0.9981 - val_loss: 0.1025 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0144 - acc: 0.9878 - val_loss: 0.0961 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0136 - acc: 0.9871 - val_loss: 0.1020 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0107 - acc: 0.9903 - val_loss: 0.1062 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e29152f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               31232     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 66,863\n","Trainable params: 66,863\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.41 초\n","learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 4s 112ms/step - loss: 1.9310 - acc: 0.2626 - val_loss: 1.8909 - val_acc: 0.3397\n","Epoch 2/50\n","15/15 [==============================] - 0s 15ms/step - loss: 1.8763 - acc: 0.3514 - val_loss: 1.8088 - val_acc: 0.4936\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7848 - acc: 0.4927 - val_loss: 1.6885 - val_acc: 0.5577\n","Epoch 4/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.6902 - acc: 0.5256 - val_loss: 1.5240 - val_acc: 0.6026\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.5163 - acc: 0.5463 - val_loss: 1.3115 - val_acc: 0.6154\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.3004 - acc: 0.6209 - val_loss: 1.0865 - val_acc: 0.6282\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.0821 - acc: 0.6462 - val_loss: 0.8122 - val_acc: 0.8013\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.8692 - acc: 0.7139 - val_loss: 0.6513 - val_acc: 0.8910\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5864 - acc: 0.8902 - val_loss: 0.3890 - val_acc: 0.9423\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.4290 - acc: 0.9135 - val_loss: 0.5110 - val_acc: 0.8718\n","Epoch 11/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.3428 - acc: 0.9383 - val_loss: 0.2003 - val_acc: 0.9359\n","Epoch 12/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2264 - acc: 0.9431 - val_loss: 0.1583 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1984 - acc: 0.9658 - val_loss: 0.1574 - val_acc: 0.9551\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1504 - acc: 0.9827 - val_loss: 0.1624 - val_acc: 0.9487\n","Epoch 15/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1480 - acc: 0.9691 - val_loss: 0.0939 - val_acc: 0.9872\n","Epoch 16/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.1390 - acc: 0.9708 - val_loss: 0.0755 - val_acc: 0.9872\n","Epoch 17/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1090 - acc: 0.9767 - val_loss: 0.0701 - val_acc: 0.9936\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1044 - acc: 0.9837 - val_loss: 0.2530 - val_acc: 0.9038\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1803 - acc: 0.9645 - val_loss: 0.0701 - val_acc: 0.9615\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0821 - acc: 0.9854 - val_loss: 0.0774 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0614 - acc: 0.9918 - val_loss: 0.0810 - val_acc: 0.9872\n","Epoch 22/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0807 - acc: 0.9725 - val_loss: 0.0768 - val_acc: 0.9872\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0707 - acc: 0.9722 - val_loss: 0.0538 - val_acc: 0.9872\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0518 - acc: 0.9882 - val_loss: 0.0446 - val_acc: 0.9936\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0674 - acc: 0.9704 - val_loss: 0.0449 - val_acc: 0.9936\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0713 - acc: 0.9791 - val_loss: 0.0553 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0363 - acc: 0.9944 - val_loss: 0.0911 - val_acc: 0.9679\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0508 - acc: 0.9835 - val_loss: 0.0501 - val_acc: 0.9872\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0444 - acc: 0.9884 - val_loss: 0.0489 - val_acc: 0.9872\n","Epoch 30/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0636 - acc: 0.9805 - val_loss: 0.0738 - val_acc: 0.9872\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0643 - acc: 0.9655 - val_loss: 0.0429 - val_acc: 0.9872\n","Epoch 32/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0594 - acc: 0.9740 - val_loss: 0.0399 - val_acc: 0.9936\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0458 - acc: 0.9858 - val_loss: 0.0630 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0323 - acc: 0.9913 - val_loss: 0.0517 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0496 - acc: 0.9815 - val_loss: 0.0384 - val_acc: 0.9936\n","Epoch 36/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0378 - acc: 0.9858 - val_loss: 0.0418 - val_acc: 0.9936\n","Epoch 37/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0447 - acc: 0.9800 - val_loss: 0.0531 - val_acc: 0.9872\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0347 - acc: 0.9880 - val_loss: 0.0388 - val_acc: 0.9936\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0288 - acc: 0.9924 - val_loss: 0.1043 - val_acc: 0.9615\n","Epoch 40/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0410 - acc: 0.9877 - val_loss: 0.0488 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0534 - acc: 0.9879 - val_loss: 0.0346 - val_acc: 0.9936\n","Epoch 42/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0403 - acc: 0.9856 - val_loss: 0.1332 - val_acc: 0.9615\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0476 - acc: 0.9779 - val_loss: 0.1582 - val_acc: 0.9423\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0561 - acc: 0.9768 - val_loss: 0.0520 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0391 - acc: 0.9853 - val_loss: 0.0661 - val_acc: 0.9872\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0301 - acc: 0.9915 - val_loss: 0.0738 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0404 - acc: 0.9921 - val_loss: 0.0371 - val_acc: 0.9936\n","Epoch 48/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0424 - acc: 0.9821 - val_loss: 0.0416 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0293 - acc: 0.9874 - val_loss: 0.0903 - val_acc: 0.9679\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0507 - acc: 0.9722 - val_loss: 0.0496 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd782b69d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.57 초\n","learning rate: 1.6e-04\n","num_dense_layers: 0\n","num_dense_nodes: 398\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 4s 107ms/step - loss: 1.9447 - acc: 0.2836 - val_loss: 1.9378 - val_acc: 0.3077\n","Epoch 2/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9354 - acc: 0.3383 - val_loss: 1.9272 - val_acc: 0.3269\n","Epoch 3/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9245 - acc: 0.3213 - val_loss: 1.9154 - val_acc: 0.1731\n","Epoch 4/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9142 - acc: 0.2265 - val_loss: 1.9013 - val_acc: 0.1731\n","Epoch 5/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8985 - acc: 0.2203 - val_loss: 1.8844 - val_acc: 0.1731\n","Epoch 6/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8801 - acc: 0.2047 - val_loss: 1.8639 - val_acc: 0.1731\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8608 - acc: 0.2076 - val_loss: 1.8383 - val_acc: 0.1731\n","Epoch 8/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8343 - acc: 0.2499 - val_loss: 1.8087 - val_acc: 0.1731\n","Epoch 9/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8061 - acc: 0.2101 - val_loss: 1.7763 - val_acc: 0.1731\n","Epoch 10/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.7687 - acc: 0.2214 - val_loss: 1.7459 - val_acc: 0.1731\n","Epoch 11/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.7296 - acc: 0.2422 - val_loss: 1.7154 - val_acc: 0.1731\n","Epoch 12/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.6917 - acc: 0.2531 - val_loss: 1.6821 - val_acc: 0.1731\n","Epoch 13/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.7026 - acc: 0.2295 - val_loss: 1.6432 - val_acc: 0.3718\n","Epoch 14/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.6342 - acc: 0.3878 - val_loss: 1.5996 - val_acc: 0.4872\n","Epoch 15/50\n","15/15 [==============================] - 0s 24ms/step - loss: 1.6579 - acc: 0.4191 - val_loss: 1.5491 - val_acc: 0.5256\n","Epoch 16/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5501 - acc: 0.5114 - val_loss: 1.4897 - val_acc: 0.6026\n","Epoch 17/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.4779 - acc: 0.5640 - val_loss: 1.4228 - val_acc: 0.6154\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.4812 - acc: 0.5472 - val_loss: 1.3471 - val_acc: 0.6090\n","Epoch 19/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.3881 - acc: 0.5702 - val_loss: 1.2615 - val_acc: 0.6218\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.3123 - acc: 0.5894 - val_loss: 1.1779 - val_acc: 0.6859\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.2160 - acc: 0.6439 - val_loss: 1.0972 - val_acc: 0.6859\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.1313 - acc: 0.6623 - val_loss: 1.0143 - val_acc: 0.6987\n","Epoch 23/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.0333 - acc: 0.6733 - val_loss: 0.9428 - val_acc: 0.7051\n","Epoch 24/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.9768 - acc: 0.6692 - val_loss: 0.8673 - val_acc: 0.7051\n","Epoch 25/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.9041 - acc: 0.6632 - val_loss: 0.7985 - val_acc: 0.7115\n","Epoch 26/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.8371 - acc: 0.6867 - val_loss: 0.7391 - val_acc: 0.7244\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.7823 - acc: 0.7153 - val_loss: 0.6845 - val_acc: 0.7949\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.7629 - acc: 0.7740 - val_loss: 0.6442 - val_acc: 0.8141\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6667 - acc: 0.8285 - val_loss: 0.5984 - val_acc: 0.8782\n","Epoch 30/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.6594 - acc: 0.8570 - val_loss: 0.5597 - val_acc: 0.8782\n","Epoch 31/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.5959 - acc: 0.8744 - val_loss: 0.5210 - val_acc: 0.9167\n","Epoch 32/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.5842 - acc: 0.9111 - val_loss: 0.4880 - val_acc: 0.9167\n","Epoch 33/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.5083 - acc: 0.9174 - val_loss: 0.4570 - val_acc: 0.9167\n","Epoch 34/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.5072 - acc: 0.9028 - val_loss: 0.4253 - val_acc: 0.9167\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4848 - acc: 0.8967 - val_loss: 0.4004 - val_acc: 0.9615\n","Epoch 36/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.4335 - acc: 0.9416 - val_loss: 0.3827 - val_acc: 0.9744\n","Epoch 37/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.3943 - acc: 0.9648 - val_loss: 0.3639 - val_acc: 0.9615\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.3801 - acc: 0.9551 - val_loss: 0.3396 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.3456 - acc: 0.9792 - val_loss: 0.3344 - val_acc: 0.9679\n","Epoch 40/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.3509 - acc: 0.9691 - val_loss: 0.3027 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.3102 - acc: 0.9783 - val_loss: 0.2858 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.3017 - acc: 0.9799 - val_loss: 0.2691 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.3255 - acc: 0.9676 - val_loss: 0.2602 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.3029 - acc: 0.9674 - val_loss: 0.2491 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2646 - acc: 0.9746 - val_loss: 0.2451 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2566 - acc: 0.9815 - val_loss: 0.2243 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2619 - acc: 0.9659 - val_loss: 0.2169 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2277 - acc: 0.9800 - val_loss: 0.2019 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2395 - acc: 0.9770 - val_loss: 0.1912 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2174 - acc: 0.9734 - val_loss: 0.1855 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e29150d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 427       \n","=================================================================\n","Total params: 32,467\n","Trainable params: 32,467\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.9310    1.0000    0.9643        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    0.9000    0.9474        10\n","          99     0.0000    0.0000    0.0000         0\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.8664    0.8478    0.8561       156\n","weighted avg     0.9881    0.9808    0.9836       156\n","\n","샘플예측시간:0.41 초\n","learning rate: 1.1e-03\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 102ms/step - loss: 1.8242 - acc: 0.2886 - val_loss: 1.1391 - val_acc: 0.6154\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.8766 - acc: 0.6640 - val_loss: 0.2336 - val_acc: 0.9231\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1643 - acc: 0.9470 - val_loss: 0.0679 - val_acc: 0.9872\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0993 - acc: 0.9734 - val_loss: 0.0986 - val_acc: 0.9744\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1121 - acc: 0.9638 - val_loss: 0.0289 - val_acc: 0.9936\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0402 - acc: 0.9865 - val_loss: 0.0507 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0256 - acc: 0.9937 - val_loss: 0.0464 - val_acc: 0.9808\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0286 - acc: 0.9933 - val_loss: 0.0789 - val_acc: 0.9679\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0371 - acc: 0.9751 - val_loss: 0.0444 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0182 - acc: 0.9979 - val_loss: 0.0530 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0701 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0123 - acc: 0.9953 - val_loss: 0.0646 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9938 - val_loss: 0.0595 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0225 - acc: 0.9928 - val_loss: 0.1055 - val_acc: 0.9744\n","Epoch 15/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0251 - acc: 0.9896 - val_loss: 0.0485 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0228 - acc: 0.9940 - val_loss: 0.0664 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - acc: 0.9858 - val_loss: 0.0649 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0110 - acc: 0.9977 - val_loss: 0.0733 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0175 - acc: 0.9896 - val_loss: 0.0779 - val_acc: 0.9744\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0209 - acc: 0.9867 - val_loss: 0.0691 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0699 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0333 - acc: 0.9844 - val_loss: 0.0784 - val_acc: 0.9744\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - acc: 0.9933 - val_loss: 0.0724 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - acc: 0.9870 - val_loss: 0.0796 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - acc: 0.9921 - val_loss: 0.0943 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9860 - val_loss: 0.0573 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0266 - acc: 0.9933 - val_loss: 0.0881 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0777 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - acc: 0.9958 - val_loss: 0.0871 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - acc: 0.9912 - val_loss: 0.0829 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0168 - acc: 0.9906 - val_loss: 0.0879 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0182 - acc: 0.9920 - val_loss: 0.0897 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0073 - acc: 0.9934 - val_loss: 0.0910 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.0923 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - acc: 0.9845 - val_loss: 0.0909 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0136 - acc: 0.9965 - val_loss: 0.0916 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0802 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - acc: 0.9947 - val_loss: 0.0699 - val_acc: 0.9744\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - acc: 0.9983 - val_loss: 0.0706 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0935 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0088 - acc: 0.9953 - val_loss: 0.1091 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.1057 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - acc: 0.9933 - val_loss: 0.0988 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0065 - acc: 0.9965 - val_loss: 0.0989 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0185 - acc: 0.9881 - val_loss: 0.1002 - val_acc: 0.9744\n","Epoch 46/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0111 - acc: 0.9941 - val_loss: 0.1008 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - acc: 0.9944 - val_loss: 0.1078 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - acc: 0.9908 - val_loss: 0.1078 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0113 - acc: 0.9940 - val_loss: 0.1089 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0134 - acc: 0.9936 - val_loss: 0.1032 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e28e09d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 100ms/step - loss: 1.9387 - acc: 0.2682 - val_loss: 1.9044 - val_acc: 0.3654\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8955 - acc: 0.4241 - val_loss: 1.8483 - val_acc: 0.4936\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8276 - acc: 0.4731 - val_loss: 1.7594 - val_acc: 0.4872\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7243 - acc: 0.4849 - val_loss: 1.6251 - val_acc: 0.5641\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6016 - acc: 0.5226 - val_loss: 1.4411 - val_acc: 0.6154\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4252 - acc: 0.5751 - val_loss: 1.2032 - val_acc: 0.6154\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.2111 - acc: 0.6109 - val_loss: 0.9277 - val_acc: 0.7564\n","Epoch 8/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.9808 - acc: 0.7031 - val_loss: 0.6740 - val_acc: 0.8526\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.6538 - acc: 0.8596 - val_loss: 0.4540 - val_acc: 0.9231\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4831 - acc: 0.9036 - val_loss: 0.2764 - val_acc: 0.9359\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2983 - acc: 0.9220 - val_loss: 0.1829 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2383 - acc: 0.9524 - val_loss: 0.1353 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1795 - acc: 0.9610 - val_loss: 0.1179 - val_acc: 0.9679\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1571 - acc: 0.9510 - val_loss: 0.0895 - val_acc: 0.9936\n","Epoch 15/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.1085 - acc: 0.9820 - val_loss: 0.0811 - val_acc: 0.9936\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1069 - acc: 0.9810 - val_loss: 0.0929 - val_acc: 0.9615\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1091 - acc: 0.9773 - val_loss: 0.0836 - val_acc: 0.9744\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0893 - acc: 0.9778 - val_loss: 0.0771 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0887 - acc: 0.9779 - val_loss: 0.0554 - val_acc: 0.9936\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0717 - acc: 0.9879 - val_loss: 0.0657 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0680 - acc: 0.9774 - val_loss: 0.0486 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0742 - acc: 0.9774 - val_loss: 0.0527 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0560 - acc: 0.9798 - val_loss: 0.0617 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0586 - acc: 0.9922 - val_loss: 0.0880 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0699 - acc: 0.9825 - val_loss: 0.0444 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0367 - acc: 0.9936 - val_loss: 0.0552 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0401 - acc: 0.9937 - val_loss: 0.0472 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0420 - acc: 0.9771 - val_loss: 0.0332 - val_acc: 0.9936\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0453 - acc: 0.9859 - val_loss: 0.0879 - val_acc: 0.9679\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0523 - acc: 0.9832 - val_loss: 0.0617 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0496 - acc: 0.9754 - val_loss: 0.0549 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0294 - acc: 0.9943 - val_loss: 0.0469 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0664 - acc: 0.9739 - val_loss: 0.0660 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0465 - acc: 0.9830 - val_loss: 0.0551 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0353 - acc: 0.9811 - val_loss: 0.0467 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0451 - acc: 0.9846 - val_loss: 0.0478 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0393 - acc: 0.9800 - val_loss: 0.0440 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0374 - acc: 0.9867 - val_loss: 0.0457 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0330 - acc: 0.9863 - val_loss: 0.0501 - val_acc: 0.9872\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0308 - acc: 0.9923 - val_loss: 0.0862 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0410 - acc: 0.9889 - val_loss: 0.0420 - val_acc: 0.9872\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0284 - acc: 0.9882 - val_loss: 0.0497 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0193 - acc: 0.9955 - val_loss: 0.0489 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0334 - acc: 0.9822 - val_loss: 0.0418 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0271 - acc: 0.9906 - val_loss: 0.0546 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0257 - acc: 0.9966 - val_loss: 0.0410 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0402 - acc: 0.9839 - val_loss: 0.0510 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0249 - acc: 0.9882 - val_loss: 0.0448 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0296 - acc: 0.9855 - val_loss: 0.0609 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0240 - acc: 0.9898 - val_loss: 0.0360 - val_acc: 0.9936\n","\n","Accuracy: 99.36%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e28a2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     0.9444    1.0000    0.9714        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9936       156\n","   macro avg     0.9921    0.9947    0.9932       156\n","weighted avg     0.9939    0.9936    0.9936       156\n","\n","샘플예측시간:0.42 초\n","learning rate: 1.0e-04\n","num_dense_layers: 0\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 4s 108ms/step - loss: 1.9442 - acc: 0.2104 - val_loss: 1.9392 - val_acc: 0.3013\n","Epoch 2/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9392 - acc: 0.3158 - val_loss: 1.9334 - val_acc: 0.3910\n","Epoch 3/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9338 - acc: 0.4123 - val_loss: 1.9271 - val_acc: 0.5064\n","Epoch 4/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9288 - acc: 0.4702 - val_loss: 1.9203 - val_acc: 0.5321\n","Epoch 5/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9185 - acc: 0.5888 - val_loss: 1.9129 - val_acc: 0.6026\n","Epoch 6/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9143 - acc: 0.5542 - val_loss: 1.9047 - val_acc: 0.6026\n","Epoch 7/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.9084 - acc: 0.5129 - val_loss: 1.8952 - val_acc: 0.6090\n","Epoch 8/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8962 - acc: 0.5632 - val_loss: 1.8841 - val_acc: 0.6154\n","Epoch 9/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8890 - acc: 0.5467 - val_loss: 1.8710 - val_acc: 0.6154\n","Epoch 10/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8770 - acc: 0.5366 - val_loss: 1.8559 - val_acc: 0.6154\n","Epoch 11/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8550 - acc: 0.5761 - val_loss: 1.8381 - val_acc: 0.5897\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.8413 - acc: 0.5649 - val_loss: 1.8168 - val_acc: 0.5769\n","Epoch 13/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8448 - acc: 0.4844 - val_loss: 1.7912 - val_acc: 0.5769\n","Epoch 14/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.8010 - acc: 0.5103 - val_loss: 1.7637 - val_acc: 0.4679\n","Epoch 15/50\n","15/15 [==============================] - 0s 24ms/step - loss: 1.7959 - acc: 0.4528 - val_loss: 1.7369 - val_acc: 0.4744\n","Epoch 16/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7327 - acc: 0.5003 - val_loss: 1.7125 - val_acc: 0.4808\n","Epoch 17/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.7510 - acc: 0.4959 - val_loss: 1.6887 - val_acc: 0.5705\n","Epoch 18/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.7134 - acc: 0.5237 - val_loss: 1.6628 - val_acc: 0.5705\n","Epoch 19/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.6743 - acc: 0.5813 - val_loss: 1.6364 - val_acc: 0.5897\n","Epoch 20/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.6332 - acc: 0.5837 - val_loss: 1.6093 - val_acc: 0.5897\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.6539 - acc: 0.5501 - val_loss: 1.5796 - val_acc: 0.6090\n","Epoch 22/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.6411 - acc: 0.5451 - val_loss: 1.5452 - val_acc: 0.6218\n","Epoch 23/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5529 - acc: 0.6188 - val_loss: 1.5078 - val_acc: 0.6218\n","Epoch 24/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.5530 - acc: 0.5739 - val_loss: 1.4673 - val_acc: 0.6282\n","Epoch 25/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.5271 - acc: 0.5698 - val_loss: 1.4266 - val_acc: 0.6282\n","Epoch 26/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.4376 - acc: 0.6103 - val_loss: 1.3843 - val_acc: 0.6282\n","Epoch 27/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.3877 - acc: 0.6136 - val_loss: 1.3365 - val_acc: 0.6282\n","Epoch 28/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.3839 - acc: 0.6013 - val_loss: 1.2882 - val_acc: 0.6282\n","Epoch 29/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.2696 - acc: 0.6380 - val_loss: 1.2455 - val_acc: 0.6346\n","Epoch 30/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.2367 - acc: 0.6297 - val_loss: 1.1982 - val_acc: 0.6346\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.2141 - acc: 0.6233 - val_loss: 1.1466 - val_acc: 0.6346\n","Epoch 32/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.1420 - acc: 0.6397 - val_loss: 1.1019 - val_acc: 0.6474\n","Epoch 33/50\n","15/15 [==============================] - 0s 24ms/step - loss: 1.0978 - acc: 0.6699 - val_loss: 1.0568 - val_acc: 0.6923\n","Epoch 34/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.0752 - acc: 0.6619 - val_loss: 1.0113 - val_acc: 0.6923\n","Epoch 35/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.0565 - acc: 0.6537 - val_loss: 0.9710 - val_acc: 0.7115\n","Epoch 36/50\n","15/15 [==============================] - 0s 12ms/step - loss: 1.0040 - acc: 0.6780 - val_loss: 0.9313 - val_acc: 0.7244\n","Epoch 37/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.9980 - acc: 0.6840 - val_loss: 0.8912 - val_acc: 0.7244\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.9362 - acc: 0.7136 - val_loss: 0.8537 - val_acc: 0.7308\n","Epoch 39/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.9180 - acc: 0.7131 - val_loss: 0.8151 - val_acc: 0.7564\n","Epoch 40/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.8892 - acc: 0.7230 - val_loss: 0.7810 - val_acc: 0.7628\n","Epoch 41/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.8328 - acc: 0.7385 - val_loss: 0.7485 - val_acc: 0.7628\n","Epoch 42/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.8126 - acc: 0.7363 - val_loss: 0.7143 - val_acc: 0.7756\n","Epoch 43/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.7742 - acc: 0.7844 - val_loss: 0.6824 - val_acc: 0.8718\n","Epoch 44/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.7341 - acc: 0.8673 - val_loss: 0.6530 - val_acc: 0.9167\n","Epoch 45/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.6601 - acc: 0.9082 - val_loss: 0.6238 - val_acc: 0.9167\n","Epoch 46/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.6697 - acc: 0.8912 - val_loss: 0.5950 - val_acc: 0.9231\n","Epoch 47/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.6350 - acc: 0.8970 - val_loss: 0.5692 - val_acc: 0.9231\n","Epoch 48/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.5973 - acc: 0.8982 - val_loss: 0.5442 - val_acc: 0.9359\n","Epoch 49/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.5924 - acc: 0.9096 - val_loss: 0.5247 - val_acc: 0.9359\n","Epoch 50/50\n","15/15 [==============================] - 0s 12ms/step - loss: 0.5732 - acc: 0.9141 - val_loss: 0.4987 - val_acc: 0.9359\n","\n","Accuracy: 93.59%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7a880b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 427       \n","=================================================================\n","Total params: 32,467\n","Trainable params: 32,467\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.7297    1.0000    0.8437        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    0.8182    0.9000        11\n","           6     1.0000    0.2000    0.3333        10\n","          99     0.0000    0.0000    0.0000         0\n","\n","    accuracy                         0.9231       156\n","   macro avg     0.8412    0.7376    0.7518       156\n","weighted avg     0.9532    0.9231    0.9164       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 1.0e-02\n","num_dense_layers: 2\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 4s 111ms/step - loss: 1.9663 - acc: 0.1972 - val_loss: 1.1205 - val_acc: 0.5321\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.0251 - acc: 0.6174 - val_loss: 0.7138 - val_acc: 0.8462\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5669 - acc: 0.8188 - val_loss: 0.5472 - val_acc: 0.7949\n","Epoch 4/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2505 - acc: 0.8938 - val_loss: 0.1619 - val_acc: 0.9103\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1607 - acc: 0.9096 - val_loss: 0.1257 - val_acc: 0.9167\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0954 - acc: 0.9374 - val_loss: 0.1044 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0953 - acc: 0.9829 - val_loss: 0.0727 - val_acc: 0.9872\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0503 - acc: 0.9881 - val_loss: 0.0744 - val_acc: 0.9679\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0170 - acc: 0.9981 - val_loss: 0.0673 - val_acc: 0.9744\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0278 - acc: 0.9928 - val_loss: 0.0507 - val_acc: 0.9872\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0177 - acc: 0.9921 - val_loss: 0.0629 - val_acc: 0.9744\n","Epoch 12/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0209 - acc: 0.9956 - val_loss: 0.0644 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0128 - acc: 0.9978 - val_loss: 0.0699 - val_acc: 0.9744\n","Epoch 14/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0157 - acc: 0.9915 - val_loss: 0.0727 - val_acc: 0.9744\n","Epoch 15/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0196 - acc: 0.9956 - val_loss: 0.0741 - val_acc: 0.9679\n","Epoch 16/50\n","15/15 [==============================] - 0s 27ms/step - loss: 0.0144 - acc: 0.9980 - val_loss: 0.0773 - val_acc: 0.9679\n","Epoch 17/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0064 - acc: 0.9960 - val_loss: 0.0856 - val_acc: 0.9615\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0139 - acc: 0.9961 - val_loss: 0.0847 - val_acc: 0.9679\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0065 - acc: 0.9951 - val_loss: 0.0859 - val_acc: 0.9615\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0152 - acc: 0.9887 - val_loss: 0.0977 - val_acc: 0.9615\n","Epoch 21/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0217 - acc: 0.9867 - val_loss: 0.0898 - val_acc: 0.9615\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - acc: 0.9933 - val_loss: 0.0921 - val_acc: 0.9615\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0098 - acc: 0.9949 - val_loss: 0.0932 - val_acc: 0.9615\n","Epoch 24/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0072 - acc: 0.9972 - val_loss: 0.0962 - val_acc: 0.9615\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0979 - val_acc: 0.9615\n","Epoch 26/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0060 - acc: 0.9973 - val_loss: 0.1018 - val_acc: 0.9615\n","Epoch 27/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0139 - acc: 0.9936 - val_loss: 0.1056 - val_acc: 0.9615\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0119 - acc: 0.9956 - val_loss: 0.0922 - val_acc: 0.9615\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0121 - acc: 0.9929 - val_loss: 0.1001 - val_acc: 0.9615\n","Epoch 30/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0127 - acc: 0.9948 - val_loss: 0.1061 - val_acc: 0.9615\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0164 - acc: 0.9908 - val_loss: 0.1103 - val_acc: 0.9615\n","Epoch 32/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0109 - acc: 0.9969 - val_loss: 0.1012 - val_acc: 0.9615\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0142 - acc: 0.9904 - val_loss: 0.1001 - val_acc: 0.9615\n","Epoch 34/50\n","15/15 [==============================] - 0s 27ms/step - loss: 0.0064 - acc: 0.9986 - val_loss: 0.1051 - val_acc: 0.9615\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.1082 - val_acc: 0.9615\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0113 - acc: 0.9962 - val_loss: 0.1111 - val_acc: 0.9615\n","Epoch 37/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0198 - acc: 0.9835 - val_loss: 0.1156 - val_acc: 0.9615\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0127 - acc: 0.9925 - val_loss: 0.1245 - val_acc: 0.9679\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0082 - acc: 0.9951 - val_loss: 0.1261 - val_acc: 0.9679\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.1258 - val_acc: 0.9679\n","Epoch 41/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0090 - acc: 0.9960 - val_loss: 0.1110 - val_acc: 0.9615\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0232 - acc: 0.9895 - val_loss: 0.0914 - val_acc: 0.9615\n","Epoch 43/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 0.0893 - val_acc: 0.9615\n","Epoch 44/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0841 - val_acc: 0.9679\n","Epoch 45/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0160 - acc: 0.9875 - val_loss: 0.0980 - val_acc: 0.9679\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0064 - acc: 0.9948 - val_loss: 0.0842 - val_acc: 0.9679\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0100 - acc: 0.9979 - val_loss: 0.1047 - val_acc: 0.9679\n","Epoch 48/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0148 - acc: 0.9931 - val_loss: 0.1145 - val_acc: 0.9679\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0252 - acc: 0.9901 - val_loss: 0.1162 - val_acc: 0.9679\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0097 - acc: 0.9960 - val_loss: 0.1147 - val_acc: 0.9679\n","\n","Accuracy: 96.79%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70e4a60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 1928      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 63        \n","=================================================================\n","Total params: 475,823\n","Trainable params: 475,823\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    0.9730    0.9863        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     0.9167    1.0000    0.9565        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9679       156\n","   macro avg     0.9473    0.9656    0.9515       156\n","weighted avg     0.9758    0.9679    0.9692       156\n","\n","샘플예측시간:0.58 초\n","learning rate: 1.0e-04\n","num_dense_layers: 0\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 2s 54ms/step - loss: 1.9413 - acc: 0.2467 - val_loss: 1.9197 - val_acc: 0.3782\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.9111 - acc: 0.3849 - val_loss: 1.8905 - val_acc: 0.3654\n","Epoch 3/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.8831 - acc: 0.3602 - val_loss: 1.8556 - val_acc: 0.3654\n","Epoch 4/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.8435 - acc: 0.3257 - val_loss: 1.8129 - val_acc: 0.2949\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8098 - acc: 0.2907 - val_loss: 1.7651 - val_acc: 0.2949\n","Epoch 6/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.7646 - acc: 0.3153 - val_loss: 1.7210 - val_acc: 0.3013\n","Epoch 7/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.7362 - acc: 0.3275 - val_loss: 1.6724 - val_acc: 0.5705\n","Epoch 8/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.6635 - acc: 0.5662 - val_loss: 1.6180 - val_acc: 0.5705\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6450 - acc: 0.5537 - val_loss: 1.5580 - val_acc: 0.6154\n","Epoch 10/50\n","15/15 [==============================] - 0s 30ms/step - loss: 1.5826 - acc: 0.5631 - val_loss: 1.4786 - val_acc: 0.6282\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4810 - acc: 0.5722 - val_loss: 1.3747 - val_acc: 0.6154\n","Epoch 12/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.3956 - acc: 0.5916 - val_loss: 1.2452 - val_acc: 0.6346\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.2589 - acc: 0.6081 - val_loss: 1.0928 - val_acc: 0.6923\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.1067 - acc: 0.6908 - val_loss: 0.9313 - val_acc: 0.7500\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.9533 - acc: 0.7808 - val_loss: 0.7862 - val_acc: 0.8397\n","Epoch 16/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.7951 - acc: 0.8253 - val_loss: 0.6507 - val_acc: 0.9167\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.6797 - acc: 0.8921 - val_loss: 0.5653 - val_acc: 0.9231\n","Epoch 18/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.6145 - acc: 0.8685 - val_loss: 0.4501 - val_acc: 0.9295\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4828 - acc: 0.9108 - val_loss: 0.3804 - val_acc: 0.9231\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4175 - acc: 0.9451 - val_loss: 0.3279 - val_acc: 0.9487\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.3652 - acc: 0.9485 - val_loss: 0.2888 - val_acc: 0.9487\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2799 - acc: 0.9733 - val_loss: 0.2499 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.2906 - acc: 0.9761 - val_loss: 0.2448 - val_acc: 0.9359\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2431 - acc: 0.9678 - val_loss: 0.2052 - val_acc: 0.9872\n","Epoch 25/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.2269 - acc: 0.9821 - val_loss: 0.1826 - val_acc: 0.9551\n","Epoch 26/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.2298 - acc: 0.9759 - val_loss: 0.1651 - val_acc: 0.9872\n","Epoch 27/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.2020 - acc: 0.9748 - val_loss: 0.1708 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1778 - acc: 0.9800 - val_loss: 0.1403 - val_acc: 0.9872\n","Epoch 29/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.1831 - acc: 0.9774 - val_loss: 0.1406 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1497 - acc: 0.9789 - val_loss: 0.1254 - val_acc: 0.9872\n","Epoch 31/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.1449 - acc: 0.9801 - val_loss: 0.1214 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.1323 - acc: 0.9879 - val_loss: 0.1163 - val_acc: 0.9872\n","Epoch 33/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1406 - acc: 0.9780 - val_loss: 0.1101 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1226 - acc: 0.9804 - val_loss: 0.1007 - val_acc: 0.9872\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0971 - acc: 0.9898 - val_loss: 0.0957 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0972 - acc: 0.9912 - val_loss: 0.0933 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1003 - acc: 0.9864 - val_loss: 0.0964 - val_acc: 0.9872\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0995 - acc: 0.9827 - val_loss: 0.0865 - val_acc: 0.9744\n","Epoch 39/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0873 - acc: 0.9885 - val_loss: 0.0862 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0942 - acc: 0.9819 - val_loss: 0.0811 - val_acc: 0.9872\n","Epoch 41/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0845 - acc: 0.9827 - val_loss: 0.0785 - val_acc: 0.9872\n","Epoch 42/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0657 - acc: 0.9933 - val_loss: 0.0751 - val_acc: 0.9872\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0955 - acc: 0.9866 - val_loss: 0.0890 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0653 - acc: 0.9886 - val_loss: 0.0747 - val_acc: 0.9872\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0815 - acc: 0.9875 - val_loss: 0.0788 - val_acc: 0.9872\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0822 - acc: 0.9779 - val_loss: 0.0696 - val_acc: 0.9872\n","Epoch 47/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0845 - acc: 0.9800 - val_loss: 0.0694 - val_acc: 0.9872\n","Epoch 48/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0551 - acc: 0.9913 - val_loss: 0.0640 - val_acc: 0.9872\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0649 - acc: 0.9893 - val_loss: 0.0680 - val_acc: 0.9872\n","Epoch 50/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0708 - acc: 0.9805 - val_loss: 0.0639 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70e1bbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1687      \n","=================================================================\n","Total params: 475,447\n","Trainable params: 475,447\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 1.0e-02\n","num_dense_layers: 0\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 4s 109ms/step - loss: 1.9412 - acc: 0.2701 - val_loss: 1.9220 - val_acc: 0.1731\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9059 - acc: 0.2418 - val_loss: 1.8486 - val_acc: 0.1731\n","Epoch 3/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8268 - acc: 0.1898 - val_loss: 1.6996 - val_acc: 0.1731\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.6058 - acc: 0.3440 - val_loss: 1.3264 - val_acc: 0.6859\n","Epoch 5/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.2361 - acc: 0.6256 - val_loss: 0.6728 - val_acc: 0.8590\n","Epoch 6/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6777 - acc: 0.8002 - val_loss: 0.3033 - val_acc: 0.9231\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.3535 - acc: 0.9060 - val_loss: 0.1806 - val_acc: 0.9423\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1568 - acc: 0.9771 - val_loss: 0.1307 - val_acc: 0.9615\n","Epoch 9/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1122 - acc: 0.9841 - val_loss: 0.0834 - val_acc: 0.9744\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0962 - acc: 0.9733 - val_loss: 0.0795 - val_acc: 0.9744\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0472 - acc: 0.9903 - val_loss: 0.0622 - val_acc: 0.9936\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0648 - acc: 0.9806 - val_loss: 0.0664 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0476 - acc: 0.9902 - val_loss: 0.0675 - val_acc: 0.9744\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0414 - acc: 0.9873 - val_loss: 0.0473 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0410 - acc: 0.9882 - val_loss: 0.0592 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0486 - acc: 0.9736 - val_loss: 0.0452 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0320 - acc: 0.9916 - val_loss: 0.0491 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0284 - acc: 0.9949 - val_loss: 0.0465 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0277 - acc: 0.9887 - val_loss: 0.0471 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0223 - acc: 0.9906 - val_loss: 0.0667 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0227 - acc: 0.9954 - val_loss: 0.0396 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0385 - acc: 0.9848 - val_loss: 0.0556 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0230 - acc: 0.9939 - val_loss: 0.0493 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0291 - acc: 0.9829 - val_loss: 0.0592 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0494 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0298 - acc: 0.9825 - val_loss: 0.0622 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0111 - acc: 0.9951 - val_loss: 0.0600 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0177 - acc: 0.9940 - val_loss: 0.0683 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0639 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0134 - acc: 0.9975 - val_loss: 0.0648 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0117 - acc: 0.9925 - val_loss: 0.0786 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0270 - acc: 0.9834 - val_loss: 0.0596 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0158 - acc: 0.9933 - val_loss: 0.0820 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0145 - acc: 0.9961 - val_loss: 0.0535 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0126 - acc: 0.9906 - val_loss: 0.0734 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0157 - acc: 0.9929 - val_loss: 0.0857 - val_acc: 0.9744\n","Epoch 37/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0148 - acc: 0.9898 - val_loss: 0.0706 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0075 - acc: 0.9968 - val_loss: 0.0787 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0812 - val_acc: 0.9744\n","Epoch 40/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0098 - acc: 0.9965 - val_loss: 0.0809 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0084 - acc: 0.9950 - val_loss: 0.0895 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0705 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0227 - acc: 0.9913 - val_loss: 0.0704 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0155 - acc: 0.9918 - val_loss: 0.0803 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0179 - acc: 0.9866 - val_loss: 0.0845 - val_acc: 0.9744\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0799 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0180 - acc: 0.9850 - val_loss: 0.0706 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0104 - acc: 0.9960 - val_loss: 0.0899 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0133 - acc: 0.9894 - val_loss: 0.0936 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0174 - acc: 0.9856 - val_loss: 0.0884 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e277f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 427       \n","=================================================================\n","Total params: 32,467\n","Trainable params: 32,467\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.57 초\n","learning rate: 1.0e-04\n","num_dense_layers: 1\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 102ms/step - loss: 1.9383 - acc: 0.2497 - val_loss: 1.9097 - val_acc: 0.3782\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.9029 - acc: 0.3677 - val_loss: 1.8706 - val_acc: 0.3718\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8560 - acc: 0.3497 - val_loss: 1.8193 - val_acc: 0.3013\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8086 - acc: 0.3427 - val_loss: 1.7524 - val_acc: 0.3718\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7624 - acc: 0.3433 - val_loss: 1.6756 - val_acc: 0.5641\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6862 - acc: 0.5104 - val_loss: 1.5961 - val_acc: 0.5641\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5978 - acc: 0.5151 - val_loss: 1.5013 - val_acc: 0.5962\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5044 - acc: 0.5624 - val_loss: 1.3705 - val_acc: 0.6154\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.3754 - acc: 0.6070 - val_loss: 1.2061 - val_acc: 0.6218\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.2256 - acc: 0.6110 - val_loss: 0.9914 - val_acc: 0.6346\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.0046 - acc: 0.6435 - val_loss: 0.7307 - val_acc: 0.7244\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.7690 - acc: 0.7787 - val_loss: 0.5300 - val_acc: 0.7949\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.5516 - acc: 0.8642 - val_loss: 0.4052 - val_acc: 0.9103\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4881 - acc: 0.8704 - val_loss: 0.3095 - val_acc: 0.9359\n","Epoch 15/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.3341 - acc: 0.9293 - val_loss: 0.2845 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.3085 - acc: 0.9639 - val_loss: 0.2361 - val_acc: 0.9487\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2423 - acc: 0.9698 - val_loss: 0.1853 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2295 - acc: 0.9711 - val_loss: 0.1711 - val_acc: 0.9551\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1800 - acc: 0.9811 - val_loss: 0.1444 - val_acc: 0.9872\n","Epoch 20/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1532 - acc: 0.9873 - val_loss: 0.1274 - val_acc: 0.9872\n","Epoch 21/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1563 - acc: 0.9841 - val_loss: 0.1206 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1141 - acc: 0.9888 - val_loss: 0.1060 - val_acc: 0.9872\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1270 - acc: 0.9705 - val_loss: 0.0958 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0960 - acc: 0.9892 - val_loss: 0.1072 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0950 - acc: 0.9888 - val_loss: 0.0897 - val_acc: 0.9872\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1045 - acc: 0.9808 - val_loss: 0.0773 - val_acc: 0.9872\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0757 - acc: 0.9878 - val_loss: 0.0836 - val_acc: 0.9936\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0679 - acc: 0.9907 - val_loss: 0.0738 - val_acc: 0.9872\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0821 - acc: 0.9866 - val_loss: 0.0754 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0821 - acc: 0.9830 - val_loss: 0.0737 - val_acc: 0.9872\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0729 - acc: 0.9791 - val_loss: 0.0601 - val_acc: 0.9872\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0710 - acc: 0.9820 - val_loss: 0.0743 - val_acc: 0.9872\n","Epoch 33/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0763 - acc: 0.9780 - val_loss: 0.0569 - val_acc: 0.9872\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0641 - acc: 0.9875 - val_loss: 0.0582 - val_acc: 0.9936\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0750 - acc: 0.9845 - val_loss: 0.0592 - val_acc: 0.9872\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0613 - acc: 0.9841 - val_loss: 0.0555 - val_acc: 0.9872\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0646 - acc: 0.9809 - val_loss: 0.0532 - val_acc: 0.9872\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0533 - acc: 0.9892 - val_loss: 0.0509 - val_acc: 0.9872\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0665 - acc: 0.9822 - val_loss: 0.0743 - val_acc: 0.9872\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0494 - acc: 0.9874 - val_loss: 0.0479 - val_acc: 0.9936\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0593 - acc: 0.9862 - val_loss: 0.0489 - val_acc: 0.9872\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0570 - acc: 0.9832 - val_loss: 0.0597 - val_acc: 0.9872\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0447 - acc: 0.9921 - val_loss: 0.0504 - val_acc: 0.9872\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0430 - acc: 0.9915 - val_loss: 0.0455 - val_acc: 0.9936\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0349 - acc: 0.9920 - val_loss: 0.0512 - val_acc: 0.9872\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0383 - acc: 0.9935 - val_loss: 0.0497 - val_acc: 0.9872\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0540 - acc: 0.9849 - val_loss: 0.0483 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0516 - acc: 0.9799 - val_loss: 0.0489 - val_acc: 0.9872\n","Epoch 49/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0407 - acc: 0.9891 - val_loss: 0.0472 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0352 - acc: 0.9973 - val_loss: 0.0526 - val_acc: 0.9872\n","\n","Accuracy: 98.72%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd710ebb7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 600,743\n","Trainable params: 600,743\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.9310    1.0000    0.9643        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9872       156\n","   macro avg     0.9901    0.9832    0.9860       156\n","weighted avg     0.9881    0.9872    0.9870       156\n","\n","샘플예측시간:0.39 초\n","learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 4s 110ms/step - loss: 1.9426 - acc: 0.1555 - val_loss: 1.9250 - val_acc: 0.1731\n","Epoch 2/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9216 - acc: 0.2141 - val_loss: 1.9022 - val_acc: 0.1731\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.9109 - acc: 0.1956 - val_loss: 1.8771 - val_acc: 0.1731\n","Epoch 4/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8645 - acc: 0.2511 - val_loss: 1.8526 - val_acc: 0.1731\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8657 - acc: 0.2138 - val_loss: 1.8296 - val_acc: 0.1731\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8289 - acc: 0.2346 - val_loss: 1.8089 - val_acc: 0.1731\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8236 - acc: 0.2210 - val_loss: 1.7818 - val_acc: 0.1731\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7908 - acc: 0.2297 - val_loss: 1.7445 - val_acc: 0.1731\n","Epoch 9/50\n","15/15 [==============================] - 0s 15ms/step - loss: 1.7452 - acc: 0.2342 - val_loss: 1.7031 - val_acc: 0.1795\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.6792 - acc: 0.2252 - val_loss: 1.6567 - val_acc: 0.1859\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.6469 - acc: 0.2749 - val_loss: 1.6075 - val_acc: 0.2436\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5726 - acc: 0.2576 - val_loss: 1.5427 - val_acc: 0.2564\n","Epoch 13/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5190 - acc: 0.2966 - val_loss: 1.4742 - val_acc: 0.2692\n","Epoch 14/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.4272 - acc: 0.3582 - val_loss: 1.4031 - val_acc: 0.5192\n","Epoch 15/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.2992 - acc: 0.5116 - val_loss: 1.3210 - val_acc: 0.5962\n","Epoch 16/50\n","15/15 [==============================] - 0s 26ms/step - loss: 1.2701 - acc: 0.5759 - val_loss: 1.2168 - val_acc: 0.5897\n","Epoch 17/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.1495 - acc: 0.6390 - val_loss: 1.1343 - val_acc: 0.5962\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.1127 - acc: 0.6275 - val_loss: 1.0578 - val_acc: 0.5962\n","Epoch 19/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.0158 - acc: 0.6390 - val_loss: 1.0110 - val_acc: 0.6090\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.9510 - acc: 0.6504 - val_loss: 0.9921 - val_acc: 0.5897\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.8746 - acc: 0.6922 - val_loss: 0.9526 - val_acc: 0.5962\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.9327 - acc: 0.6329 - val_loss: 0.8735 - val_acc: 0.6026\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.8494 - acc: 0.6573 - val_loss: 0.8526 - val_acc: 0.6090\n","Epoch 24/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.7942 - acc: 0.6919 - val_loss: 0.8314 - val_acc: 0.6026\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7998 - acc: 0.6751 - val_loss: 0.8274 - val_acc: 0.6154\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7612 - acc: 0.6986 - val_loss: 0.7800 - val_acc: 0.7051\n","Epoch 27/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7663 - acc: 0.7316 - val_loss: 0.7744 - val_acc: 0.6474\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7069 - acc: 0.7002 - val_loss: 0.8959 - val_acc: 0.6346\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7330 - acc: 0.7208 - val_loss: 0.7355 - val_acc: 0.6154\n","Epoch 30/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.6645 - acc: 0.7371 - val_loss: 0.8652 - val_acc: 0.7436\n","Epoch 31/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7270 - acc: 0.7482 - val_loss: 0.7277 - val_acc: 0.7564\n","Epoch 32/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6667 - acc: 0.7500 - val_loss: 0.7591 - val_acc: 0.6410\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7178 - acc: 0.7132 - val_loss: 0.7159 - val_acc: 0.6410\n","Epoch 34/50\n","15/15 [==============================] - 0s 24ms/step - loss: 0.6148 - acc: 0.7487 - val_loss: 0.6687 - val_acc: 0.7628\n","Epoch 35/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6548 - acc: 0.7740 - val_loss: 0.6662 - val_acc: 0.7628\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.6383 - acc: 0.7669 - val_loss: 0.6560 - val_acc: 0.7564\n","Epoch 37/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6013 - acc: 0.7882 - val_loss: 0.7136 - val_acc: 0.7500\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6466 - acc: 0.7458 - val_loss: 0.6700 - val_acc: 0.7436\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5675 - acc: 0.8096 - val_loss: 0.6299 - val_acc: 0.7692\n","Epoch 40/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5804 - acc: 0.7923 - val_loss: 0.6162 - val_acc: 0.7692\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.6000 - acc: 0.7732 - val_loss: 0.6126 - val_acc: 0.7692\n","Epoch 42/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5892 - acc: 0.7648 - val_loss: 0.5959 - val_acc: 0.7692\n","Epoch 43/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.5205 - acc: 0.8160 - val_loss: 0.5952 - val_acc: 0.7692\n","Epoch 44/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.5635 - acc: 0.7773 - val_loss: 0.7249 - val_acc: 0.6474\n","Epoch 45/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.6213 - acc: 0.7355 - val_loss: 0.5729 - val_acc: 0.7692\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5003 - acc: 0.7939 - val_loss: 0.5897 - val_acc: 0.7628\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.4977 - acc: 0.8091 - val_loss: 0.5650 - val_acc: 0.7692\n","Epoch 48/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.4724 - acc: 0.8039 - val_loss: 0.5942 - val_acc: 0.7436\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5492 - acc: 0.7784 - val_loss: 0.5421 - val_acc: 0.7628\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.4612 - acc: 0.8151 - val_loss: 0.5404 - val_acc: 0.7564\n","\n","Accuracy: 75.64%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7868ff840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 1928      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 63        \n","=================================================================\n","Total params: 475,823\n","Trainable params: 475,823\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.4561    0.9630    0.6190        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     0.9375    0.8824    0.9091        17\n","           4     0.0000    0.0000    0.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    0.9000    0.9474        10\n","          99     0.0000    0.0000    0.0000         0\n","\n","    accuracy                         0.7564       156\n","   macro avg     0.6742    0.7182    0.6844       156\n","weighted avg     0.6811    0.7564    0.7028       156\n","\n","샘플예측시간:0.56 초\n","learning rate: 8.1e-03\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 106ms/step - loss: 1.5223 - acc: 0.4211 - val_loss: 0.1551 - val_acc: 0.9295\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2110 - acc: 0.9337 - val_loss: 5.0142 - val_acc: 0.6923\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.2112 - acc: 0.8951 - val_loss: 0.2865 - val_acc: 0.9103\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1721 - acc: 0.9508 - val_loss: 0.3253 - val_acc: 0.9487\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0983 - acc: 0.9827 - val_loss: 0.4929 - val_acc: 0.9872\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1337 - acc: 0.9741 - val_loss: 1.3258 - val_acc: 0.9615\n","Epoch 7/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.3774 - acc: 0.9787 - val_loss: 0.2953 - val_acc: 0.9679\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0939 - acc: 0.9888 - val_loss: 0.0870 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0396 - acc: 0.9926 - val_loss: 0.1269 - val_acc: 0.9744\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0573 - acc: 0.9863 - val_loss: 0.1557 - val_acc: 0.9615\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0557 - acc: 0.9926 - val_loss: 0.0488 - val_acc: 0.9872\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0306 - acc: 0.9910 - val_loss: 0.0745 - val_acc: 0.9615\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9888 - val_loss: 0.0543 - val_acc: 0.9744\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0673 - val_acc: 0.9744\n","Epoch 15/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0236 - acc: 0.9866 - val_loss: 0.0693 - val_acc: 0.9679\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0203 - acc: 0.9928 - val_loss: 0.0655 - val_acc: 0.9744\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - acc: 0.9983 - val_loss: 0.0762 - val_acc: 0.9744\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0075 - acc: 0.9965 - val_loss: 0.0925 - val_acc: 0.9679\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - acc: 0.9914 - val_loss: 0.0932 - val_acc: 0.9744\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - acc: 0.9913 - val_loss: 0.1000 - val_acc: 0.9679\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0064 - acc: 0.9966 - val_loss: 0.1002 - val_acc: 0.9744\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - acc: 0.9906 - val_loss: 0.1093 - val_acc: 0.9744\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.1095 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 0.1217 - val_acc: 0.9679\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0069 - acc: 0.9967 - val_loss: 0.1174 - val_acc: 0.9679\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0057 - acc: 0.9947 - val_loss: 0.1087 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1094 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.1082 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0060 - acc: 0.9959 - val_loss: 0.1179 - val_acc: 0.9679\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.1052 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0101 - acc: 0.9962 - val_loss: 0.1144 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - acc: 0.9956 - val_loss: 0.1192 - val_acc: 0.9679\n","Epoch 33/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.1103 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - acc: 0.9884 - val_loss: 0.1001 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0092 - acc: 0.9932 - val_loss: 0.1012 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - acc: 0.9941 - val_loss: 0.1100 - val_acc: 0.9679\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0077 - acc: 0.9951 - val_loss: 0.1112 - val_acc: 0.9679\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.1085 - val_acc: 0.9679\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - acc: 0.9972 - val_loss: 0.0945 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0083 - acc: 0.9958 - val_loss: 0.1065 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0072 - acc: 0.9936 - val_loss: 0.1239 - val_acc: 0.9679\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0049 - acc: 0.9958 - val_loss: 0.1177 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0222 - acc: 0.9873 - val_loss: 0.1090 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - acc: 0.9949 - val_loss: 0.1109 - val_acc: 0.9744\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0082 - acc: 0.9963 - val_loss: 0.1159 - val_acc: 0.9679\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0076 - acc: 0.9988 - val_loss: 0.1235 - val_acc: 0.9679\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0112 - acc: 0.9911 - val_loss: 0.1048 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0079 - acc: 0.9945 - val_loss: 0.1119 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - acc: 0.9940 - val_loss: 0.1224 - val_acc: 0.9679\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0085 - acc: 0.9960 - val_loss: 0.1303 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70ee1fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    0.9730    0.9863        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9740    0.9626       156\n","weighted avg     0.9817    0.9744    0.9760       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 1.0e-02\n","num_dense_layers: 2\n","num_dense_nodes: 328\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.nadam.Nadam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 4s 111ms/step - loss: 1.6066 - acc: 0.4070 - val_loss: 0.3777 - val_acc: 0.9423\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2353 - acc: 0.9392 - val_loss: 0.2781 - val_acc: 0.8974\n","Epoch 3/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0743 - acc: 0.9689 - val_loss: 0.0480 - val_acc: 0.9744\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0734 - acc: 0.9770 - val_loss: 0.0441 - val_acc: 0.9808\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0238 - acc: 0.9924 - val_loss: 0.0477 - val_acc: 0.9744\n","Epoch 6/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0134 - acc: 0.9988 - val_loss: 0.0851 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0466 - acc: 0.9821 - val_loss: 0.0478 - val_acc: 0.9808\n","Epoch 8/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1772 - acc: 0.9580 - val_loss: 0.0640 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0322 - acc: 0.9935 - val_loss: 0.0660 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0294 - acc: 0.9905 - val_loss: 0.0399 - val_acc: 0.9936\n","Epoch 11/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0131 - acc: 0.9926 - val_loss: 0.0787 - val_acc: 0.9744\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0284 - acc: 0.9829 - val_loss: 0.0972 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0136 - acc: 0.9949 - val_loss: 0.1195 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0305 - acc: 0.9933 - val_loss: 0.0924 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0154 - acc: 0.9954 - val_loss: 0.0886 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0962 - val_acc: 0.9679\n","Epoch 17/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0212 - acc: 0.9882 - val_loss: 0.0905 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0730 - acc: 0.9869 - val_loss: 10.5771 - val_acc: 0.3269\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 7.9052 - acc: 0.3899 - val_loss: 0.4732 - val_acc: 0.8141\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.3959 - acc: 0.8804 - val_loss: 0.0893 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0597 - acc: 0.9772 - val_loss: 0.1851 - val_acc: 0.9295\n","Epoch 22/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.1516 - acc: 0.9518 - val_loss: 0.0587 - val_acc: 0.9872\n","Epoch 23/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0464 - acc: 0.9777 - val_loss: 0.0622 - val_acc: 0.9679\n","Epoch 24/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0169 - acc: 0.9894 - val_loss: 0.0678 - val_acc: 0.9679\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0508 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0097 - acc: 0.9956 - val_loss: 0.0719 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0298 - acc: 0.9844 - val_loss: 0.0647 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0243 - acc: 0.9907 - val_loss: 0.0588 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0151 - acc: 0.9969 - val_loss: 0.0722 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0121 - acc: 0.9924 - val_loss: 0.0631 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0204 - acc: 0.9923 - val_loss: 0.0698 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0172 - acc: 0.9900 - val_loss: 0.0701 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.0803 - val_acc: 0.9679\n","Epoch 34/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0177 - acc: 0.9876 - val_loss: 0.0728 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0181 - acc: 0.9894 - val_loss: 0.0797 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0126 - acc: 0.9924 - val_loss: 0.0822 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0143 - acc: 0.9929 - val_loss: 0.0873 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0107 - acc: 0.9930 - val_loss: 0.0769 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0960 - val_acc: 0.9744\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0829 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1175 - val_acc: 0.9679\n","Epoch 42/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0185 - acc: 0.9958 - val_loss: 0.0711 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0056 - acc: 0.9955 - val_loss: 0.1048 - val_acc: 0.9679\n","Epoch 44/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0110 - acc: 0.9953 - val_loss: 0.0998 - val_acc: 0.9679\n","Epoch 45/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0099 - acc: 0.9983 - val_loss: 0.0829 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0779 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0110 - acc: 0.9909 - val_loss: 0.0830 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0114 - acc: 0.9892 - val_loss: 0.0876 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0069 - acc: 0.9960 - val_loss: 0.0942 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0084 - acc: 0.9965 - val_loss: 0.0976 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70f306ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 328)               20008     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 328)               107912    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 2303      \n","=================================================================\n","Total params: 162,263\n","Trainable params: 162,263\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    0.9091    0.9524        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9649    0.9578       156\n","weighted avg     0.9817    0.9744    0.9759       156\n","\n","샘플예측시간:0.59 초\n","learning rate: 6.1e-03\n","num_dense_layers: 0\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 199\n","Epoch 1/50\n","15/15 [==============================] - 3s 103ms/step - loss: 1.6454 - acc: 0.4238 - val_loss: 0.2235 - val_acc: 0.9231\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1995 - acc: 0.9462 - val_loss: 0.0532 - val_acc: 0.9872\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0451 - acc: 0.9863 - val_loss: 0.0306 - val_acc: 0.9936\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0271 - acc: 0.9916 - val_loss: 0.0457 - val_acc: 0.9744\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0368 - acc: 0.9847 - val_loss: 0.0407 - val_acc: 0.9808\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - acc: 0.9971 - val_loss: 0.0378 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0483 - acc: 0.9898 - val_loss: 0.0407 - val_acc: 0.9808\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - acc: 0.9946 - val_loss: 0.0417 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - acc: 0.9936 - val_loss: 0.0686 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0151 - acc: 0.9917 - val_loss: 0.0439 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0124 - acc: 0.9958 - val_loss: 0.0463 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.0673 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0078 - acc: 0.9969 - val_loss: 0.0554 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0199 - acc: 0.9884 - val_loss: 0.0471 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - acc: 0.9917 - val_loss: 0.0643 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0069 - acc: 0.9960 - val_loss: 0.0662 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0724 - val_acc: 0.9744\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0194 - acc: 0.9879 - val_loss: 0.0686 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - acc: 0.9947 - val_loss: 0.0796 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0165 - acc: 0.9928 - val_loss: 0.0870 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0859 - val_acc: 0.9744\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0190 - acc: 0.9854 - val_loss: 0.0852 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0871 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0129 - acc: 0.9953 - val_loss: 0.0960 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0080 - acc: 0.9935 - val_loss: 0.0953 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - acc: 0.9933 - val_loss: 0.0674 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0085 - acc: 0.9959 - val_loss: 0.0858 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - acc: 0.9895 - val_loss: 0.0721 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0162 - acc: 0.9932 - val_loss: 0.0705 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - acc: 0.9876 - val_loss: 0.0786 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - acc: 0.9985 - val_loss: 0.0966 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0082 - acc: 0.9960 - val_loss: 0.0999 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0156 - acc: 0.9881 - val_loss: 0.1030 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0073 - acc: 0.9953 - val_loss: 0.1041 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0106 - acc: 0.9936 - val_loss: 0.0982 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0971 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0072 - acc: 0.9941 - val_loss: 0.1015 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0146 - acc: 0.9835 - val_loss: 0.0918 - val_acc: 0.9744\n","Epoch 39/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0039 - acc: 0.9967 - val_loss: 0.0848 - val_acc: 0.9744\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.1017 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0105 - acc: 0.9913 - val_loss: 0.1099 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0096 - acc: 0.9948 - val_loss: 0.1032 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0063 - acc: 0.9945 - val_loss: 0.1075 - val_acc: 0.9744\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0065 - acc: 0.9958 - val_loss: 0.1066 - val_acc: 0.9744\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0084 - acc: 0.9949 - val_loss: 0.1037 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0109 - acc: 0.9936 - val_loss: 0.1090 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - acc: 0.9926 - val_loss: 0.0995 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0072 - acc: 0.9971 - val_loss: 0.1007 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - acc: 0.9907 - val_loss: 0.1002 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0100 - acc: 0.9963 - val_loss: 0.0960 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e28a2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 199)         9950      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 199)               317604    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1400      \n","=================================================================\n","Total params: 328,954\n","Trainable params: 328,954\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.59 초\n","learning rate: 1.0e-02\n","num_dense_layers: 2\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 3s 102ms/step - loss: 1.8366 - acc: 0.1479 - val_loss: 1.2735 - val_acc: 0.3077\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.1656 - acc: 0.3758 - val_loss: 0.9576 - val_acc: 0.5000\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.9491 - acc: 0.6521 - val_loss: 0.5444 - val_acc: 0.8718\n","Epoch 4/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4979 - acc: 0.8520 - val_loss: 0.2834 - val_acc: 0.9679\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2818 - acc: 0.9507 - val_loss: 0.1355 - val_acc: 0.9615\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1096 - acc: 0.9725 - val_loss: 0.0779 - val_acc: 0.9679\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0881 - acc: 0.9770 - val_loss: 0.0547 - val_acc: 0.9872\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0692 - acc: 0.9823 - val_loss: 0.0358 - val_acc: 0.9936\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0564 - acc: 0.9846 - val_loss: 0.0382 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0293 - acc: 0.9950 - val_loss: 0.0704 - val_acc: 0.9679\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0250 - acc: 0.9916 - val_loss: 0.0491 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0550 - acc: 0.9896 - val_loss: 0.0528 - val_acc: 0.9744\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0234 - acc: 0.9983 - val_loss: 0.0388 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - acc: 0.9969 - val_loss: 0.0414 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0428 - val_acc: 0.9744\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0122 - acc: 0.9973 - val_loss: 0.0424 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0476 - val_acc: 0.9744\n","Epoch 18/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0064 - acc: 0.9962 - val_loss: 0.0444 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0091 - acc: 0.9988 - val_loss: 0.0410 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - acc: 0.9958 - val_loss: 0.0593 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0150 - acc: 0.9929 - val_loss: 0.0298 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0312 - acc: 0.9920 - val_loss: 0.0361 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0435 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0225 - acc: 0.9871 - val_loss: 0.0497 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0126 - acc: 0.9915 - val_loss: 0.0493 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0120 - acc: 0.9949 - val_loss: 0.0712 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0694 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0099 - acc: 0.9956 - val_loss: 0.0534 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0125 - acc: 0.9941 - val_loss: 0.0603 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0718 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0261 - acc: 0.9792 - val_loss: 0.0777 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0095 - acc: 0.9985 - val_loss: 0.0714 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.0763 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0836 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0851 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - acc: 0.9937 - val_loss: 0.0905 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - acc: 0.9941 - val_loss: 0.1103 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0094 - acc: 0.9947 - val_loss: 0.1011 - val_acc: 0.9744\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - acc: 0.9878 - val_loss: 0.0991 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0056 - acc: 0.9953 - val_loss: 0.0980 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0071 - acc: 0.9962 - val_loss: 0.1031 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0948 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0109 - acc: 0.9943 - val_loss: 0.0549 - val_acc: 0.9744\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0268 - acc: 0.9923 - val_loss: 0.1222 - val_acc: 0.9744\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.1175 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.1191 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0061 - acc: 0.9956 - val_loss: 0.1148 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0127 - acc: 0.9901 - val_loss: 0.1085 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0929 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - acc: 0.9929 - val_loss: 0.0973 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70ee1f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 488       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 63        \n","=================================================================\n","Total params: 32,663\n","Trainable params: 32,663\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 3.8e-03\n","num_dense_layers: 0\n","num_dense_nodes: 243\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 4s 145ms/step - loss: 1.9470 - acc: 0.1157 - val_loss: 1.9082 - val_acc: 0.3654\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8850 - acc: 0.3804 - val_loss: 1.7757 - val_acc: 0.2949\n","Epoch 3/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7603 - acc: 0.3311 - val_loss: 1.6294 - val_acc: 0.6154\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5949 - acc: 0.5706 - val_loss: 1.2602 - val_acc: 0.6218\n","Epoch 5/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.1647 - acc: 0.6298 - val_loss: 0.5852 - val_acc: 0.7949\n","Epoch 6/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.5513 - acc: 0.8711 - val_loss: 0.2489 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.2970 - acc: 0.9222 - val_loss: 0.2211 - val_acc: 0.9295\n","Epoch 8/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1870 - acc: 0.9749 - val_loss: 0.1078 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.1065 - acc: 0.9739 - val_loss: 0.0727 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0669 - acc: 0.9864 - val_loss: 0.0834 - val_acc: 0.9744\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0604 - acc: 0.9856 - val_loss: 0.0737 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0592 - acc: 0.9923 - val_loss: 0.0481 - val_acc: 0.9936\n","Epoch 13/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0432 - acc: 0.9887 - val_loss: 0.0546 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0524 - acc: 0.9832 - val_loss: 0.0500 - val_acc: 0.9872\n","Epoch 15/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0524 - acc: 0.9845 - val_loss: 0.0536 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 26ms/step - loss: 0.0401 - acc: 0.9866 - val_loss: 0.0410 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0377 - acc: 0.9907 - val_loss: 0.0415 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0263 - acc: 0.9944 - val_loss: 0.0498 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0371 - acc: 0.9951 - val_loss: 0.0472 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0257 - acc: 0.9869 - val_loss: 0.0368 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0329 - acc: 0.9925 - val_loss: 0.0536 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0202 - acc: 0.9964 - val_loss: 0.0458 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0256 - acc: 0.9928 - val_loss: 0.0477 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0212 - acc: 0.9934 - val_loss: 0.0428 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0249 - acc: 0.9943 - val_loss: 0.0632 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0171 - acc: 0.9972 - val_loss: 0.0378 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0191 - acc: 0.9967 - val_loss: 0.0635 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0099 - acc: 0.9949 - val_loss: 0.0539 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0198 - acc: 0.9903 - val_loss: 0.0461 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0151 - acc: 0.9949 - val_loss: 0.0682 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0156 - acc: 0.9944 - val_loss: 0.0514 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0251 - acc: 0.9827 - val_loss: 0.0713 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0467 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0160 - acc: 0.9958 - val_loss: 0.0650 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0119 - acc: 0.9932 - val_loss: 0.0722 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.0551 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0139 - acc: 0.9932 - val_loss: 0.0645 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0132 - acc: 0.9978 - val_loss: 0.0671 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0209 - acc: 0.9856 - val_loss: 0.0546 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0673 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0130 - acc: 0.9911 - val_loss: 0.0793 - val_acc: 0.9744\n","Epoch 42/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0125 - acc: 0.9898 - val_loss: 0.0744 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0253 - acc: 0.9800 - val_loss: 0.0543 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.0895 - val_acc: 0.9744\n","Epoch 45/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0140 - acc: 0.9933 - val_loss: 0.0844 - val_acc: 0.9744\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.0707 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0151 - acc: 0.9935 - val_loss: 0.0739 - val_acc: 0.9744\n","Epoch 48/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.0118 - acc: 0.9976 - val_loss: 0.0621 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0800 - val_acc: 0.9744\n","Epoch 50/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.0164 - acc: 0.9936 - val_loss: 0.0799 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e2915268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1687      \n","=================================================================\n","Total params: 475,447\n","Trainable params: 475,447\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.56 초\n","learning rate: 3.0e-03\n","num_dense_layers: 2\n","num_dense_nodes: 8\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 60\n","Epoch 1/50\n","15/15 [==============================] - 5s 120ms/step - loss: 1.9470 - acc: 0.2399 - val_loss: 1.9406 - val_acc: 0.3654\n","Epoch 2/50\n","15/15 [==============================] - 0s 18ms/step - loss: 1.9387 - acc: 0.3653 - val_loss: 1.9283 - val_acc: 0.3974\n","Epoch 3/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.9255 - acc: 0.3448 - val_loss: 1.9044 - val_acc: 0.3846\n","Epoch 4/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.9013 - acc: 0.3737 - val_loss: 1.8633 - val_acc: 0.4551\n","Epoch 5/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.8506 - acc: 0.4426 - val_loss: 1.7779 - val_acc: 0.5705\n","Epoch 6/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.7530 - acc: 0.4919 - val_loss: 1.6197 - val_acc: 0.5577\n","Epoch 7/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.5907 - acc: 0.4820 - val_loss: 1.3917 - val_acc: 0.5897\n","Epoch 8/50\n","15/15 [==============================] - 0s 16ms/step - loss: 1.3611 - acc: 0.5260 - val_loss: 1.1213 - val_acc: 0.5833\n","Epoch 9/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.0874 - acc: 0.6044 - val_loss: 0.9088 - val_acc: 0.6154\n","Epoch 10/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.8771 - acc: 0.6194 - val_loss: 0.7671 - val_acc: 0.6538\n","Epoch 11/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.7503 - acc: 0.6527 - val_loss: 0.6785 - val_acc: 0.7244\n","Epoch 12/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.6636 - acc: 0.7840 - val_loss: 0.5398 - val_acc: 0.9038\n","Epoch 13/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.5721 - acc: 0.8649 - val_loss: 0.4860 - val_acc: 0.9038\n","Epoch 14/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.5107 - acc: 0.8867 - val_loss: 0.5201 - val_acc: 0.9103\n","Epoch 15/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.4911 - acc: 0.8905 - val_loss: 0.3705 - val_acc: 0.9038\n","Epoch 16/50\n","15/15 [==============================] - 0s 29ms/step - loss: 0.4464 - acc: 0.8820 - val_loss: 0.3907 - val_acc: 0.9103\n","Epoch 17/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.3207 - acc: 0.9145 - val_loss: 0.2935 - val_acc: 0.9103\n","Epoch 18/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.2836 - acc: 0.8995 - val_loss: 0.2880 - val_acc: 0.9103\n","Epoch 19/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.3044 - acc: 0.9110 - val_loss: 0.2699 - val_acc: 0.9231\n","Epoch 20/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.2476 - acc: 0.9184 - val_loss: 0.2104 - val_acc: 0.9551\n","Epoch 21/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.2113 - acc: 0.9576 - val_loss: 0.2325 - val_acc: 0.9551\n","Epoch 22/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.2208 - acc: 0.9494 - val_loss: 0.1688 - val_acc: 0.9615\n","Epoch 23/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.1635 - acc: 0.9611 - val_loss: 0.1500 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.1435 - acc: 0.9782 - val_loss: 0.1595 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.1475 - acc: 0.9714 - val_loss: 0.1558 - val_acc: 0.9744\n","Epoch 26/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.1227 - acc: 0.9801 - val_loss: 0.1222 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.1253 - acc: 0.9680 - val_loss: 0.1220 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0831 - acc: 0.9780 - val_loss: 0.1070 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0893 - acc: 0.9797 - val_loss: 0.0907 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0687 - acc: 0.9884 - val_loss: 0.1085 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.1243 - acc: 0.9747 - val_loss: 0.0897 - val_acc: 0.9744\n","Epoch 32/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0762 - acc: 0.9900 - val_loss: 0.1426 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.0798 - acc: 0.9786 - val_loss: 0.0764 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 29ms/step - loss: 0.0482 - acc: 0.9798 - val_loss: 0.0847 - val_acc: 0.9744\n","Epoch 35/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0391 - acc: 0.9876 - val_loss: 0.0691 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0591 - acc: 0.9905 - val_loss: 0.0844 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0512 - acc: 0.9868 - val_loss: 0.0903 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0534 - acc: 0.9830 - val_loss: 0.0745 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0410 - acc: 0.9912 - val_loss: 0.0707 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0429 - acc: 0.9931 - val_loss: 0.0641 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0392 - acc: 0.9902 - val_loss: 0.0717 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.0451 - acc: 0.9905 - val_loss: 0.0625 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0278 - acc: 0.9916 - val_loss: 0.0716 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0364 - acc: 0.9912 - val_loss: 0.0666 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0287 - acc: 0.9957 - val_loss: 0.0760 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0220 - acc: 0.9962 - val_loss: 0.0810 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0273 - acc: 0.9941 - val_loss: 0.0677 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0234 - acc: 0.9958 - val_loss: 0.0835 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0231 - acc: 0.9977 - val_loss: 0.0754 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0177 - acc: 0.9964 - val_loss: 0.0720 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70e4a6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 60)          3000      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 60)                29040     \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 488       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 72        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 63        \n","=================================================================\n","Total params: 32,663\n","Trainable params: 32,663\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.4 초\n","learning rate: 2.8e-03\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 4s 113ms/step - loss: 1.9435 - acc: 0.1649 - val_loss: 1.9022 - val_acc: 0.6987\n","Epoch 2/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.8801 - acc: 0.6635 - val_loss: 1.7245 - val_acc: 0.6090\n","Epoch 3/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.6602 - acc: 0.5649 - val_loss: 1.2430 - val_acc: 0.6090\n","Epoch 4/50\n","15/15 [==============================] - 0s 17ms/step - loss: 1.1027 - acc: 0.6375 - val_loss: 0.5263 - val_acc: 0.8910\n","Epoch 5/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.4786 - acc: 0.8526 - val_loss: 0.1686 - val_acc: 0.9295\n","Epoch 6/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.2343 - acc: 0.8976 - val_loss: 0.1541 - val_acc: 0.9423\n","Epoch 7/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.1803 - acc: 0.9239 - val_loss: 0.0868 - val_acc: 0.9551\n","Epoch 8/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0924 - acc: 0.9734 - val_loss: 0.0463 - val_acc: 0.9872\n","Epoch 9/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0616 - acc: 0.9736 - val_loss: 0.1750 - val_acc: 0.9359\n","Epoch 10/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0710 - acc: 0.9710 - val_loss: 0.0558 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0507 - acc: 0.9895 - val_loss: 0.0547 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.0424 - acc: 0.9902 - val_loss: 0.0413 - val_acc: 0.9936\n","Epoch 13/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0339 - acc: 0.9858 - val_loss: 0.0672 - val_acc: 0.9679\n","Epoch 14/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0398 - acc: 0.9939 - val_loss: 0.0404 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0261 - acc: 0.9906 - val_loss: 0.0754 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 28ms/step - loss: 0.0678 - acc: 0.9842 - val_loss: 0.0584 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0268 - acc: 0.9958 - val_loss: 0.0526 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0185 - acc: 0.9930 - val_loss: 0.0677 - val_acc: 0.9744\n","Epoch 19/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0199 - acc: 0.9888 - val_loss: 0.0503 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0203 - acc: 0.9898 - val_loss: 0.0684 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0222 - acc: 0.9947 - val_loss: 0.0495 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0752 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0157 - acc: 0.9973 - val_loss: 0.0795 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0166 - acc: 0.9930 - val_loss: 0.0618 - val_acc: 0.9744\n","Epoch 25/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0747 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0475 - acc: 0.9836 - val_loss: 0.0896 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0130 - acc: 0.9968 - val_loss: 0.0769 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0132 - acc: 0.9932 - val_loss: 0.0667 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0271 - acc: 0.9878 - val_loss: 0.0903 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0824 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0272 - acc: 0.9856 - val_loss: 0.0805 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0092 - acc: 0.9927 - val_loss: 0.0903 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0217 - acc: 0.9886 - val_loss: 0.0687 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 27ms/step - loss: 0.0229 - acc: 0.9939 - val_loss: 0.0723 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0176 - acc: 0.9940 - val_loss: 0.0862 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0132 - acc: 0.9952 - val_loss: 0.0928 - val_acc: 0.9744\n","Epoch 37/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0198 - acc: 0.9892 - val_loss: 0.0871 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0239 - acc: 0.9901 - val_loss: 0.1087 - val_acc: 0.9744\n","Epoch 39/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.0276 - acc: 0.9900 - val_loss: 0.0780 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.0077 - acc: 0.9984 - val_loss: 0.0866 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.0084 - acc: 0.9948 - val_loss: 0.0989 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 18ms/step - loss: 0.0199 - acc: 0.9889 - val_loss: 0.0988 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0140 - acc: 0.9964 - val_loss: 0.0704 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0199 - acc: 0.9896 - val_loss: 0.0864 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0249 - acc: 0.9920 - val_loss: 0.0904 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0140 - acc: 0.9932 - val_loss: 0.0959 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0083 - acc: 0.9960 - val_loss: 0.0938 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 16ms/step - loss: 0.0121 - acc: 0.9948 - val_loss: 0.0952 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 17ms/step - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0937 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 15ms/step - loss: 0.0170 - acc: 0.9938 - val_loss: 0.1093 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e28a29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.42 초\n","learning rate: 4.6e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 200\n","Epoch 1/50\n","15/15 [==============================] - 3s 59ms/step - loss: 1.9038 - acc: 0.3228 - val_loss: 1.7000 - val_acc: 0.3718\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6271 - acc: 0.4835 - val_loss: 1.2396 - val_acc: 0.6218\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.1389 - acc: 0.6400 - val_loss: 0.5386 - val_acc: 0.9103\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4955 - acc: 0.8775 - val_loss: 0.2031 - val_acc: 0.9231\n","Epoch 5/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2201 - acc: 0.9233 - val_loss: 0.1506 - val_acc: 0.9615\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1100 - acc: 0.9722 - val_loss: 0.0910 - val_acc: 0.9679\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0648 - acc: 0.9756 - val_loss: 0.0753 - val_acc: 0.9744\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0572 - acc: 0.9796 - val_loss: 0.0838 - val_acc: 0.9551\n","Epoch 9/50\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0568 - acc: 0.9748 - val_loss: 0.0554 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0565 - acc: 0.9790 - val_loss: 0.0270 - val_acc: 0.9936\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0594 - acc: 0.9752 - val_loss: 0.0395 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0634 - acc: 0.9777 - val_loss: 0.0435 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0550 - acc: 0.9802 - val_loss: 0.0411 - val_acc: 0.9936\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0238 - acc: 0.9942 - val_loss: 0.0569 - val_acc: 0.9872\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0310 - acc: 0.9916 - val_loss: 0.0404 - val_acc: 0.9936\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0375 - acc: 0.9909 - val_loss: 0.0442 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0313 - acc: 0.9904 - val_loss: 0.0538 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0574 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0413 - acc: 0.9824 - val_loss: 0.0298 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.0605 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0164 - acc: 0.9972 - val_loss: 0.0497 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0385 - acc: 0.9754 - val_loss: 0.0650 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - acc: 0.9956 - val_loss: 0.0649 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0298 - acc: 0.9839 - val_loss: 0.0589 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0176 - acc: 0.9956 - val_loss: 0.0501 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0149 - acc: 0.9907 - val_loss: 0.0854 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0283 - acc: 0.9914 - val_loss: 0.0400 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0253 - acc: 0.9936 - val_loss: 0.0680 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0098 - acc: 0.9962 - val_loss: 0.0633 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.0712 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0093 - acc: 0.9982 - val_loss: 0.0562 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0220 - acc: 0.9962 - val_loss: 0.0629 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0141 - acc: 0.9923 - val_loss: 0.0652 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0579 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0169 - acc: 0.9961 - val_loss: 0.0726 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0126 - acc: 0.9894 - val_loss: 0.0730 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0158 - acc: 0.9920 - val_loss: 0.0698 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0171 - acc: 0.9920 - val_loss: 0.0685 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0184 - acc: 0.9897 - val_loss: 0.0611 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9907 - val_loss: 0.0660 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - acc: 0.9915 - val_loss: 0.0643 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0189 - acc: 0.9907 - val_loss: 0.0742 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0116 - acc: 0.9938 - val_loss: 0.0773 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - acc: 0.9920 - val_loss: 0.0810 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0110 - acc: 0.9916 - val_loss: 0.0785 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0179 - acc: 0.9884 - val_loss: 0.0729 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0118 - acc: 0.9973 - val_loss: 0.0724 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0154 - acc: 0.9935 - val_loss: 0.0895 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0081 - acc: 0.9935 - val_loss: 0.0755 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0218 - acc: 0.9839 - val_loss: 0.0845 - val_acc: 0.9744\n","\n","Accuracy: 97.44%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e29150d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 200)         10000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 200)               320800    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               102912    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 699,959\n","Trainable params: 699,959\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8235    0.9032        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7143    1.0000    0.8333        10\n","\n","    accuracy                         0.9744       156\n","   macro avg     0.9592    0.9695    0.9597       156\n","weighted avg     0.9817    0.9744    0.9755       156\n","\n","샘플예측시간:0.39 초\n","learning rate: 6.1e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 106ms/step - loss: 1.8787 - acc: 0.3094 - val_loss: 1.6088 - val_acc: 0.2949\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.4591 - acc: 0.5101 - val_loss: 0.8184 - val_acc: 0.7372\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.6521 - acc: 0.7910 - val_loss: 0.1412 - val_acc: 0.9744\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1651 - acc: 0.9513 - val_loss: 0.0547 - val_acc: 0.9872\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0962 - acc: 0.9713 - val_loss: 0.0628 - val_acc: 0.9872\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0700 - acc: 0.9784 - val_loss: 0.0833 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0721 - acc: 0.9784 - val_loss: 0.0411 - val_acc: 0.9936\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0474 - acc: 0.9805 - val_loss: 0.0681 - val_acc: 0.9808\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0513 - acc: 0.9880 - val_loss: 0.0503 - val_acc: 0.9808\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0684 - acc: 0.9832 - val_loss: 0.0533 - val_acc: 0.9872\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0686 - acc: 0.9811 - val_loss: 0.0562 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0391 - acc: 0.9836 - val_loss: 0.0222 - val_acc: 0.9936\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0344 - acc: 0.9906 - val_loss: 0.0938 - val_acc: 0.9679\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0290 - acc: 0.9909 - val_loss: 0.0367 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0249 - acc: 0.9911 - val_loss: 0.0549 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0219 - acc: 0.9909 - val_loss: 0.0464 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0285 - acc: 0.9860 - val_loss: 0.0381 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0414 - acc: 0.9905 - val_loss: 0.0639 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0154 - acc: 0.9936 - val_loss: 0.0567 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0144 - acc: 0.9920 - val_loss: 0.0653 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0130 - acc: 0.9928 - val_loss: 0.0519 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - acc: 0.9924 - val_loss: 0.0664 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0208 - acc: 0.9919 - val_loss: 0.0768 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0146 - acc: 0.9977 - val_loss: 0.0539 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - acc: 0.9966 - val_loss: 0.0982 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0250 - acc: 0.9880 - val_loss: 0.0697 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0224 - acc: 0.9933 - val_loss: 0.0746 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0143 - acc: 0.9923 - val_loss: 0.0920 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0141 - acc: 0.9940 - val_loss: 0.0721 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0108 - acc: 0.9927 - val_loss: 0.0978 - val_acc: 0.9744\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0128 - acc: 0.9953 - val_loss: 0.0783 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0069 - acc: 0.9993 - val_loss: 0.0814 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0284 - acc: 0.9876 - val_loss: 0.0837 - val_acc: 0.9744\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0155 - acc: 0.9915 - val_loss: 0.0447 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0094 - acc: 0.9988 - val_loss: 0.0614 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0103 - acc: 0.9960 - val_loss: 0.1023 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - acc: 0.9932 - val_loss: 0.0981 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0118 - acc: 0.9950 - val_loss: 0.0698 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0111 - acc: 0.9944 - val_loss: 0.0732 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - acc: 0.9954 - val_loss: 0.0901 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0131 - acc: 0.9948 - val_loss: 0.0855 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0213 - acc: 0.9885 - val_loss: 0.0925 - val_acc: 0.9744\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0149 - acc: 0.9941 - val_loss: 0.0898 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - acc: 0.9873 - val_loss: 0.0852 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0139 - acc: 0.9935 - val_loss: 0.1021 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0181 - acc: 0.9801 - val_loss: 0.0911 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0170 - acc: 0.9874 - val_loss: 0.0927 - val_acc: 0.9744\n","Epoch 48/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0170 - acc: 0.9848 - val_loss: 0.0971 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0096 - acc: 0.9956 - val_loss: 0.0956 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0147 - acc: 0.9859 - val_loss: 0.0960 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd77024c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.4 초\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n","  warnings.warn(\"The objective has been evaluated \"\n"],"name":"stderr"},{"output_type":"stream","text":["learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 99ms/step - loss: 1.9355 - acc: 0.2340 - val_loss: 1.8960 - val_acc: 0.5000\n","Epoch 2/50\n","15/15 [==============================] - 0s 9ms/step - loss: 1.8899 - acc: 0.4008 - val_loss: 1.8366 - val_acc: 0.3333\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8255 - acc: 0.3484 - val_loss: 1.7386 - val_acc: 0.3397\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7357 - acc: 0.3729 - val_loss: 1.6175 - val_acc: 0.5705\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5904 - acc: 0.5436 - val_loss: 1.4694 - val_acc: 0.6154\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4564 - acc: 0.5667 - val_loss: 1.2720 - val_acc: 0.6282\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.2435 - acc: 0.6340 - val_loss: 1.0383 - val_acc: 0.7115\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.0101 - acc: 0.7534 - val_loss: 0.7589 - val_acc: 0.8013\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.7890 - acc: 0.8297 - val_loss: 0.5083 - val_acc: 0.9231\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4843 - acc: 0.9162 - val_loss: 0.3779 - val_acc: 0.9679\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.3929 - acc: 0.9524 - val_loss: 0.2219 - val_acc: 0.9295\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2300 - acc: 0.9650 - val_loss: 0.1838 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1751 - acc: 0.9762 - val_loss: 0.1488 - val_acc: 0.9744\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1567 - acc: 0.9818 - val_loss: 0.1576 - val_acc: 0.9487\n","Epoch 15/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.1391 - acc: 0.9829 - val_loss: 0.1131 - val_acc: 0.9551\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1263 - acc: 0.9755 - val_loss: 0.1008 - val_acc: 0.9615\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1027 - acc: 0.9801 - val_loss: 0.1150 - val_acc: 0.9487\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0758 - acc: 0.9888 - val_loss: 0.0926 - val_acc: 0.9744\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0823 - acc: 0.9844 - val_loss: 0.0788 - val_acc: 0.9615\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0779 - acc: 0.9790 - val_loss: 0.0793 - val_acc: 0.9551\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0631 - acc: 0.9878 - val_loss: 0.0680 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0615 - acc: 0.9795 - val_loss: 0.0544 - val_acc: 0.9744\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0384 - acc: 0.9943 - val_loss: 0.0776 - val_acc: 0.9679\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0800 - acc: 0.9740 - val_loss: 0.0519 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0396 - acc: 0.9912 - val_loss: 0.0420 - val_acc: 0.9936\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0703 - acc: 0.9695 - val_loss: 0.0769 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0523 - acc: 0.9805 - val_loss: 0.0484 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0554 - acc: 0.9899 - val_loss: 0.0392 - val_acc: 0.9936\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0534 - acc: 0.9812 - val_loss: 0.0450 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0361 - acc: 0.9896 - val_loss: 0.0560 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0367 - acc: 0.9856 - val_loss: 0.0376 - val_acc: 0.9936\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0302 - acc: 0.9930 - val_loss: 0.0642 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0567 - acc: 0.9742 - val_loss: 0.0469 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0553 - acc: 0.9791 - val_loss: 0.0704 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0445 - acc: 0.9813 - val_loss: 0.0393 - val_acc: 0.9936\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0434 - acc: 0.9890 - val_loss: 0.0663 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0513 - acc: 0.9796 - val_loss: 0.0380 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0339 - acc: 0.9908 - val_loss: 0.0623 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0428 - acc: 0.9741 - val_loss: 0.0523 - val_acc: 0.9872\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0708 - acc: 0.9845 - val_loss: 0.0522 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0273 - acc: 0.9926 - val_loss: 0.0348 - val_acc: 0.9936\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0410 - acc: 0.9886 - val_loss: 0.0492 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9818 - val_loss: 0.0390 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0368 - acc: 0.9903 - val_loss: 0.0454 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0307 - acc: 0.9891 - val_loss: 0.0423 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0382 - acc: 0.9898 - val_loss: 0.0564 - val_acc: 0.9744\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0532 - acc: 0.9878 - val_loss: 0.0395 - val_acc: 0.9872\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0338 - acc: 0.9833 - val_loss: 0.0443 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0364 - acc: 0.9861 - val_loss: 0.0434 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0222 - acc: 0.9906 - val_loss: 0.0461 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd70e1bbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.42 초\n","learning rate: 1.0e-04\n","num_dense_layers: 0\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow_addons.optimizers.rectified_adam.RectifiedAdam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 4s 106ms/step - loss: 1.9485 - acc: 0.2090 - val_loss: 1.9448 - val_acc: 0.2949\n","Epoch 2/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9459 - acc: 0.2373 - val_loss: 1.9420 - val_acc: 0.3077\n","Epoch 3/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9442 - acc: 0.2171 - val_loss: 1.9384 - val_acc: 0.2949\n","Epoch 4/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9397 - acc: 0.2029 - val_loss: 1.9338 - val_acc: 0.3397\n","Epoch 5/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9358 - acc: 0.2718 - val_loss: 1.9286 - val_acc: 0.3718\n","Epoch 6/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9297 - acc: 0.2800 - val_loss: 1.9227 - val_acc: 0.3782\n","Epoch 7/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9231 - acc: 0.3326 - val_loss: 1.9162 - val_acc: 0.4423\n","Epoch 8/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9201 - acc: 0.4408 - val_loss: 1.9092 - val_acc: 0.5385\n","Epoch 9/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9106 - acc: 0.4901 - val_loss: 1.9006 - val_acc: 0.5192\n","Epoch 10/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.9031 - acc: 0.4405 - val_loss: 1.8908 - val_acc: 0.4359\n","Epoch 11/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8998 - acc: 0.3703 - val_loss: 1.8804 - val_acc: 0.4231\n","Epoch 12/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8843 - acc: 0.3416 - val_loss: 1.8674 - val_acc: 0.1795\n","Epoch 13/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8719 - acc: 0.2239 - val_loss: 1.8532 - val_acc: 0.1731\n","Epoch 14/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8497 - acc: 0.2397 - val_loss: 1.8364 - val_acc: 0.1731\n","Epoch 15/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.8378 - acc: 0.2232 - val_loss: 1.8183 - val_acc: 0.1731\n","Epoch 16/50\n","15/15 [==============================] - 0s 25ms/step - loss: 1.8184 - acc: 0.2246 - val_loss: 1.8011 - val_acc: 0.1731\n","Epoch 17/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.8225 - acc: 0.2185 - val_loss: 1.7855 - val_acc: 0.1731\n","Epoch 18/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7727 - acc: 0.2230 - val_loss: 1.7692 - val_acc: 0.1731\n","Epoch 19/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7577 - acc: 0.2141 - val_loss: 1.7556 - val_acc: 0.1795\n","Epoch 20/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7673 - acc: 0.2758 - val_loss: 1.7408 - val_acc: 0.2949\n","Epoch 21/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7194 - acc: 0.3264 - val_loss: 1.7256 - val_acc: 0.2949\n","Epoch 22/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7376 - acc: 0.3462 - val_loss: 1.7108 - val_acc: 0.3654\n","Epoch 23/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7358 - acc: 0.3398 - val_loss: 1.6933 - val_acc: 0.3654\n","Epoch 24/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.7127 - acc: 0.4229 - val_loss: 1.6734 - val_acc: 0.5641\n","Epoch 25/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.7252 - acc: 0.5291 - val_loss: 1.6496 - val_acc: 0.5641\n","Epoch 26/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.6615 - acc: 0.5459 - val_loss: 1.6246 - val_acc: 0.5769\n","Epoch 27/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.6664 - acc: 0.5374 - val_loss: 1.6009 - val_acc: 0.5769\n","Epoch 28/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.6267 - acc: 0.5591 - val_loss: 1.5744 - val_acc: 0.5641\n","Epoch 29/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5928 - acc: 0.5520 - val_loss: 1.5336 - val_acc: 0.6090\n","Epoch 30/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5567 - acc: 0.5954 - val_loss: 1.4923 - val_acc: 0.6154\n","Epoch 31/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.5385 - acc: 0.5646 - val_loss: 1.4444 - val_acc: 0.6218\n","Epoch 32/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.4975 - acc: 0.5667 - val_loss: 1.3917 - val_acc: 0.6154\n","Epoch 33/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.4365 - acc: 0.5713 - val_loss: 1.3300 - val_acc: 0.6218\n","Epoch 34/50\n","15/15 [==============================] - 0s 25ms/step - loss: 1.4055 - acc: 0.5656 - val_loss: 1.2564 - val_acc: 0.6218\n","Epoch 35/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.3153 - acc: 0.5821 - val_loss: 1.1711 - val_acc: 0.6859\n","Epoch 36/50\n","15/15 [==============================] - 0s 13ms/step - loss: 1.2109 - acc: 0.6498 - val_loss: 1.0978 - val_acc: 0.6987\n","Epoch 37/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.1045 - acc: 0.7134 - val_loss: 1.0159 - val_acc: 0.7308\n","Epoch 38/50\n","15/15 [==============================] - 0s 14ms/step - loss: 1.0773 - acc: 0.6731 - val_loss: 0.9413 - val_acc: 0.7628\n","Epoch 39/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.8968 - acc: 0.7898 - val_loss: 0.8598 - val_acc: 0.8590\n","Epoch 40/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.8981 - acc: 0.8623 - val_loss: 0.7861 - val_acc: 0.8269\n","Epoch 41/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.8126 - acc: 0.8029 - val_loss: 0.7252 - val_acc: 0.9295\n","Epoch 42/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.7608 - acc: 0.9276 - val_loss: 0.6498 - val_acc: 0.9359\n","Epoch 43/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.6888 - acc: 0.8986 - val_loss: 0.5884 - val_acc: 0.9295\n","Epoch 44/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.6499 - acc: 0.9109 - val_loss: 0.5379 - val_acc: 0.9487\n","Epoch 45/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.5981 - acc: 0.9345 - val_loss: 0.4928 - val_acc: 0.9295\n","Epoch 46/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.5390 - acc: 0.9001 - val_loss: 0.4462 - val_acc: 0.9487\n","Epoch 47/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.4927 - acc: 0.9778 - val_loss: 0.4043 - val_acc: 0.9359\n","Epoch 48/50\n","15/15 [==============================] - 0s 14ms/step - loss: 0.4382 - acc: 0.9425 - val_loss: 0.3797 - val_acc: 0.9487\n","Epoch 49/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.4072 - acc: 0.9595 - val_loss: 0.3409 - val_acc: 0.9487\n","Epoch 50/50\n","15/15 [==============================] - 0s 13ms/step - loss: 0.3843 - acc: 0.9565 - val_loss: 0.3141 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd78259e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1687      \n","=================================================================\n","Total params: 475,447\n","Trainable params: 475,447\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     0.9000    1.0000    0.9474        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    0.9000    0.9474        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9857    0.9689    0.9760       156\n","weighted avg     0.9827    0.9808    0.9807       156\n","\n","샘플예측시간:0.58 초\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n","  warnings.warn(\"The objective has been evaluated \"\n"],"name":"stderr"},{"output_type":"stream","text":["learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 109ms/step - loss: 1.9305 - acc: 0.2234 - val_loss: 1.8877 - val_acc: 0.4103\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.8796 - acc: 0.4277 - val_loss: 1.8194 - val_acc: 0.5962\n","Epoch 3/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.8068 - acc: 0.5564 - val_loss: 1.7238 - val_acc: 0.4936\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7045 - acc: 0.4525 - val_loss: 1.6062 - val_acc: 0.6154\n","Epoch 5/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.5710 - acc: 0.6076 - val_loss: 1.4478 - val_acc: 0.6154\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4677 - acc: 0.5490 - val_loss: 1.2500 - val_acc: 0.6282\n","Epoch 7/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.2334 - acc: 0.5953 - val_loss: 0.9868 - val_acc: 0.7179\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.9270 - acc: 0.7407 - val_loss: 0.6977 - val_acc: 0.8590\n","Epoch 9/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.6816 - acc: 0.8981 - val_loss: 0.4741 - val_acc: 0.9487\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4917 - acc: 0.9335 - val_loss: 0.3235 - val_acc: 0.9487\n","Epoch 11/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.3022 - acc: 0.9464 - val_loss: 0.1969 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2017 - acc: 0.9758 - val_loss: 0.1393 - val_acc: 0.9872\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1690 - acc: 0.9681 - val_loss: 0.1743 - val_acc: 0.9551\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1823 - acc: 0.9621 - val_loss: 0.1118 - val_acc: 0.9872\n","Epoch 15/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1263 - acc: 0.9742 - val_loss: 0.1056 - val_acc: 0.9487\n","Epoch 16/50\n","15/15 [==============================] - 0s 23ms/step - loss: 0.1057 - acc: 0.9808 - val_loss: 0.0794 - val_acc: 0.9872\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0822 - acc: 0.9821 - val_loss: 0.0685 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0957 - acc: 0.9866 - val_loss: 0.0531 - val_acc: 0.9872\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0754 - acc: 0.9823 - val_loss: 0.0474 - val_acc: 0.9872\n","Epoch 20/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0886 - acc: 0.9761 - val_loss: 0.0507 - val_acc: 0.9872\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0673 - acc: 0.9757 - val_loss: 0.0562 - val_acc: 0.9872\n","Epoch 22/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0633 - acc: 0.9859 - val_loss: 0.0641 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0627 - acc: 0.9876 - val_loss: 0.0450 - val_acc: 0.9936\n","Epoch 24/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0481 - acc: 0.9892 - val_loss: 0.0549 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0693 - acc: 0.9832 - val_loss: 0.0474 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0820 - acc: 0.9756 - val_loss: 0.0471 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0550 - acc: 0.9906 - val_loss: 0.0641 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0413 - acc: 0.9905 - val_loss: 0.0612 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0759 - acc: 0.9677 - val_loss: 0.0376 - val_acc: 0.9936\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0545 - acc: 0.9814 - val_loss: 0.0397 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0546 - acc: 0.9761 - val_loss: 0.0408 - val_acc: 0.9872\n","Epoch 32/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0326 - acc: 0.9903 - val_loss: 0.0496 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0610 - acc: 0.9694 - val_loss: 0.0723 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0448 - acc: 0.9866 - val_loss: 0.0387 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0473 - acc: 0.9809 - val_loss: 0.0650 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0408 - acc: 0.9922 - val_loss: 0.0390 - val_acc: 0.9872\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0403 - acc: 0.9845 - val_loss: 0.0368 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0249 - acc: 0.9936 - val_loss: 0.0492 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0394 - acc: 0.9918 - val_loss: 0.0287 - val_acc: 0.9936\n","Epoch 40/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0357 - acc: 0.9935 - val_loss: 0.0572 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0382 - acc: 0.9851 - val_loss: 0.0366 - val_acc: 0.9872\n","Epoch 42/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0495 - acc: 0.9825 - val_loss: 0.0665 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0368 - acc: 0.9891 - val_loss: 0.0513 - val_acc: 0.9744\n","Epoch 44/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0340 - acc: 0.9878 - val_loss: 0.0353 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0328 - acc: 0.9909 - val_loss: 0.0538 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0466 - acc: 0.9817 - val_loss: 0.0398 - val_acc: 0.9872\n","Epoch 47/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0343 - acc: 0.9838 - val_loss: 0.0369 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0269 - acc: 0.9938 - val_loss: 0.0710 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0379 - acc: 0.9907 - val_loss: 0.0566 - val_acc: 0.9872\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0695 - acc: 0.9718 - val_loss: 0.0410 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7868316a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.58 초\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n","  warnings.warn(\"The objective has been evaluated \"\n"],"name":"stderr"},{"output_type":"stream","text":["learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 101ms/step - loss: 1.9318 - acc: 0.2605 - val_loss: 1.8918 - val_acc: 0.6026\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8845 - acc: 0.4699 - val_loss: 1.8291 - val_acc: 0.5000\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8210 - acc: 0.4760 - val_loss: 1.7337 - val_acc: 0.5641\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7342 - acc: 0.5079 - val_loss: 1.6109 - val_acc: 0.6026\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6253 - acc: 0.5311 - val_loss: 1.4468 - val_acc: 0.6154\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4378 - acc: 0.5971 - val_loss: 1.2417 - val_acc: 0.6154\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.2356 - acc: 0.5897 - val_loss: 0.9973 - val_acc: 0.6474\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.0088 - acc: 0.6416 - val_loss: 0.7573 - val_acc: 0.8269\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.7731 - acc: 0.7893 - val_loss: 0.5432 - val_acc: 0.8590\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.5495 - acc: 0.8382 - val_loss: 0.3731 - val_acc: 0.9808\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4317 - acc: 0.9404 - val_loss: 0.2394 - val_acc: 0.9167\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2826 - acc: 0.9205 - val_loss: 0.1686 - val_acc: 0.9551\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1932 - acc: 0.9690 - val_loss: 0.1329 - val_acc: 0.9487\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1703 - acc: 0.9698 - val_loss: 0.1024 - val_acc: 0.9615\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1196 - acc: 0.9896 - val_loss: 0.1048 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.1573 - acc: 0.9453 - val_loss: 0.0742 - val_acc: 0.9872\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1134 - acc: 0.9766 - val_loss: 0.0736 - val_acc: 0.9872\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0884 - acc: 0.9849 - val_loss: 0.0600 - val_acc: 0.9872\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0806 - acc: 0.9873 - val_loss: 0.0692 - val_acc: 0.9744\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1001 - acc: 0.9823 - val_loss: 0.1219 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1627 - acc: 0.9506 - val_loss: 0.1343 - val_acc: 0.9423\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0849 - acc: 0.9783 - val_loss: 0.0786 - val_acc: 0.9872\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0793 - acc: 0.9730 - val_loss: 0.0543 - val_acc: 0.9872\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0760 - acc: 0.9792 - val_loss: 0.0495 - val_acc: 0.9872\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0581 - acc: 0.9826 - val_loss: 0.0562 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0660 - acc: 0.9800 - val_loss: 0.0408 - val_acc: 0.9936\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0325 - acc: 0.9964 - val_loss: 0.0519 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0636 - acc: 0.9850 - val_loss: 0.0624 - val_acc: 0.9744\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0895 - acc: 0.9735 - val_loss: 0.0741 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0501 - acc: 0.9872 - val_loss: 0.0442 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0689 - acc: 0.9813 - val_loss: 0.0455 - val_acc: 0.9936\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0459 - acc: 0.9879 - val_loss: 0.0483 - val_acc: 0.9872\n","Epoch 33/50\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0497 - acc: 0.9817 - val_loss: 0.0413 - val_acc: 0.9872\n","Epoch 34/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0360 - acc: 0.9918 - val_loss: 0.0426 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0375 - acc: 0.9922 - val_loss: 0.0437 - val_acc: 0.9872\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0433 - acc: 0.9848 - val_loss: 0.0587 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0347 - acc: 0.9957 - val_loss: 0.0401 - val_acc: 0.9872\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0396 - acc: 0.9894 - val_loss: 0.0487 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0366 - acc: 0.9881 - val_loss: 0.0351 - val_acc: 0.9936\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0470 - acc: 0.9766 - val_loss: 0.0509 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0395 - acc: 0.9872 - val_loss: 0.0350 - val_acc: 0.9936\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9915 - val_loss: 0.0455 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0381 - acc: 0.9857 - val_loss: 0.0387 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0213 - acc: 0.9940 - val_loss: 0.0462 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0497 - acc: 0.9774 - val_loss: 0.0406 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0302 - acc: 0.9905 - val_loss: 0.0457 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0263 - acc: 0.9885 - val_loss: 0.0375 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0372 - acc: 0.9878 - val_loss: 0.0476 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0337 - acc: 0.9841 - val_loss: 0.0338 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0315 - acc: 0.9894 - val_loss: 0.0551 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7826a2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.58 초\n","learning rate: 6.7e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 100ms/step - loss: 1.8676 - acc: 0.3787 - val_loss: 1.4912 - val_acc: 0.5962\n","Epoch 2/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.3601 - acc: 0.5740 - val_loss: 0.5727 - val_acc: 0.8077\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4281 - acc: 0.8985 - val_loss: 0.1050 - val_acc: 0.9872\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0832 - acc: 0.9805 - val_loss: 0.1199 - val_acc: 0.9679\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1127 - acc: 0.9622 - val_loss: 0.0732 - val_acc: 0.9615\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0800 - acc: 0.9770 - val_loss: 0.0624 - val_acc: 0.9808\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0523 - acc: 0.9806 - val_loss: 0.0524 - val_acc: 0.9936\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0364 - acc: 0.9924 - val_loss: 0.0925 - val_acc: 0.9679\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0522 - acc: 0.9956 - val_loss: 0.0645 - val_acc: 0.9551\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0447 - acc: 0.9858 - val_loss: 0.0705 - val_acc: 0.9744\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0382 - acc: 0.9809 - val_loss: 0.0489 - val_acc: 0.9808\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0225 - acc: 0.9870 - val_loss: 0.0654 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0167 - acc: 0.9967 - val_loss: 0.0527 - val_acc: 0.9808\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0245 - acc: 0.9897 - val_loss: 0.0580 - val_acc: 0.9744\n","Epoch 15/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0145 - acc: 0.9951 - val_loss: 0.0614 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0218 - acc: 0.9947 - val_loss: 0.0512 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0238 - acc: 0.9908 - val_loss: 0.0747 - val_acc: 0.9744\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0071 - acc: 0.9970 - val_loss: 0.0727 - val_acc: 0.9744\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0259 - acc: 0.9850 - val_loss: 0.0735 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.0908 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0225 - acc: 0.9799 - val_loss: 0.0860 - val_acc: 0.9744\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 0.0701 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0095 - acc: 0.9937 - val_loss: 0.0867 - val_acc: 0.9744\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0124 - acc: 0.9936 - val_loss: 0.0754 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0744 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0860 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0135 - acc: 0.9930 - val_loss: 0.0855 - val_acc: 0.9808\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - acc: 0.9954 - val_loss: 0.0686 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0154 - acc: 0.9938 - val_loss: 0.0883 - val_acc: 0.9808\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0390 - acc: 0.9848 - val_loss: 0.0607 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0241 - acc: 0.9888 - val_loss: 0.0781 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0117 - acc: 0.9981 - val_loss: 0.0944 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0968 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0140 - acc: 0.9875 - val_loss: 0.0860 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0104 - acc: 0.9958 - val_loss: 0.0982 - val_acc: 0.9744\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0132 - acc: 0.9941 - val_loss: 0.0924 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0930 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0151 - acc: 0.9925 - val_loss: 0.0808 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0929 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0108 - acc: 0.9953 - val_loss: 0.0794 - val_acc: 0.9744\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0205 - acc: 0.9893 - val_loss: 0.0640 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0144 - acc: 0.9920 - val_loss: 0.0796 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0106 - acc: 0.9979 - val_loss: 0.0935 - val_acc: 0.9744\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0138 - acc: 0.9938 - val_loss: 0.1027 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0121 - acc: 0.9909 - val_loss: 0.0911 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0072 - acc: 0.9957 - val_loss: 0.0952 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0230 - acc: 0.9859 - val_loss: 0.1045 - val_acc: 0.9744\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0115 - acc: 0.9906 - val_loss: 0.0900 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0136 - acc: 0.9886 - val_loss: 0.0927 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0114 - acc: 0.9953 - val_loss: 0.0991 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e27822f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.42 초\n","learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 124\n","Epoch 1/50\n","15/15 [==============================] - 3s 101ms/step - loss: 1.9323 - acc: 0.2609 - val_loss: 1.8997 - val_acc: 0.5769\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8940 - acc: 0.5376 - val_loss: 1.8551 - val_acc: 0.5705\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8424 - acc: 0.5641 - val_loss: 1.7889 - val_acc: 0.5705\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8004 - acc: 0.4614 - val_loss: 1.7077 - val_acc: 0.5641\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7096 - acc: 0.5326 - val_loss: 1.6004 - val_acc: 0.5897\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5990 - acc: 0.5803 - val_loss: 1.4696 - val_acc: 0.6154\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.4756 - acc: 0.5918 - val_loss: 1.3158 - val_acc: 0.6282\n","Epoch 8/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.3315 - acc: 0.5798 - val_loss: 1.1378 - val_acc: 0.6154\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.1693 - acc: 0.5645 - val_loss: 0.9500 - val_acc: 0.6795\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.9394 - acc: 0.6404 - val_loss: 0.7701 - val_acc: 0.8141\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.7928 - acc: 0.8286 - val_loss: 0.6088 - val_acc: 0.9231\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.6255 - acc: 0.8630 - val_loss: 0.4608 - val_acc: 0.9295\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4831 - acc: 0.9296 - val_loss: 0.3370 - val_acc: 0.9295\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.3568 - acc: 0.9414 - val_loss: 0.2539 - val_acc: 0.9872\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.2897 - acc: 0.9812 - val_loss: 0.1948 - val_acc: 0.9744\n","Epoch 16/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.2173 - acc: 0.9587 - val_loss: 0.1604 - val_acc: 0.9808\n","Epoch 17/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1704 - acc: 0.9829 - val_loss: 0.1182 - val_acc: 0.9872\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1457 - acc: 0.9706 - val_loss: 0.1085 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1342 - acc: 0.9698 - val_loss: 0.0908 - val_acc: 0.9744\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0951 - acc: 0.9824 - val_loss: 0.1006 - val_acc: 0.9744\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0964 - acc: 0.9766 - val_loss: 0.0845 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1003 - acc: 0.9798 - val_loss: 0.0690 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0645 - acc: 0.9855 - val_loss: 0.0722 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0842 - acc: 0.9783 - val_loss: 0.0628 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0690 - acc: 0.9843 - val_loss: 0.0725 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0506 - acc: 0.9878 - val_loss: 0.0844 - val_acc: 0.9744\n","Epoch 27/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0685 - acc: 0.9790 - val_loss: 0.0590 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0877 - acc: 0.9741 - val_loss: 0.0681 - val_acc: 0.9872\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0596 - acc: 0.9846 - val_loss: 0.0733 - val_acc: 0.9679\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0564 - acc: 0.9829 - val_loss: 0.0605 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0466 - acc: 0.9922 - val_loss: 0.0630 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0539 - acc: 0.9891 - val_loss: 0.0736 - val_acc: 0.9744\n","Epoch 33/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0694 - acc: 0.9864 - val_loss: 0.0575 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0494 - acc: 0.9795 - val_loss: 0.0450 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0346 - acc: 0.9931 - val_loss: 0.0465 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0406 - acc: 0.9908 - val_loss: 0.0468 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0353 - acc: 0.9880 - val_loss: 0.0425 - val_acc: 0.9936\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0404 - acc: 0.9913 - val_loss: 0.0774 - val_acc: 0.9872\n","Epoch 39/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0379 - acc: 0.9916 - val_loss: 0.0440 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0526 - acc: 0.9857 - val_loss: 0.0401 - val_acc: 0.9936\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0342 - acc: 0.9913 - val_loss: 0.0681 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0342 - acc: 0.9815 - val_loss: 0.0369 - val_acc: 0.9936\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0491 - acc: 0.9781 - val_loss: 0.0429 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0408 - acc: 0.9921 - val_loss: 0.0397 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0384 - acc: 0.9836 - val_loss: 0.0369 - val_acc: 0.9936\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0478 - acc: 0.9799 - val_loss: 0.0379 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0397 - acc: 0.9873 - val_loss: 0.0530 - val_acc: 0.9872\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0337 - acc: 0.9929 - val_loss: 0.0742 - val_acc: 0.9808\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0474 - acc: 0.9840 - val_loss: 0.0444 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0440 - acc: 0.9864 - val_loss: 0.0437 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6dff0a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 124)         6200      \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 124)               123504    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               64000     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 459,951\n","Trainable params: 459,951\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     0.9189    1.0000    0.9577        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9884    0.9779    0.9823       156\n","weighted avg     0.9823    0.9808    0.9807       156\n","\n","샘플예측시간:0.58 초\n","learning rate: 1.0e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 211\n","Epoch 1/50\n","15/15 [==============================] - 3s 102ms/step - loss: 1.9334 - acc: 0.3389 - val_loss: 1.8959 - val_acc: 0.4103\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8867 - acc: 0.4398 - val_loss: 1.8378 - val_acc: 0.5000\n","Epoch 3/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8180 - acc: 0.4825 - val_loss: 1.7520 - val_acc: 0.5000\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.7388 - acc: 0.4733 - val_loss: 1.6446 - val_acc: 0.5641\n","Epoch 5/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.6326 - acc: 0.5362 - val_loss: 1.5153 - val_acc: 0.5769\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5074 - acc: 0.5645 - val_loss: 1.3437 - val_acc: 0.6218\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.3190 - acc: 0.6202 - val_loss: 1.1152 - val_acc: 0.6987\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.0950 - acc: 0.6720 - val_loss: 0.8602 - val_acc: 0.8462\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.9187 - acc: 0.7504 - val_loss: 0.6269 - val_acc: 0.8974\n","Epoch 10/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.6007 - acc: 0.8969 - val_loss: 0.4077 - val_acc: 0.9359\n","Epoch 11/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.4315 - acc: 0.9220 - val_loss: 0.2563 - val_acc: 0.9295\n","Epoch 12/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2665 - acc: 0.9345 - val_loss: 0.1912 - val_acc: 0.9808\n","Epoch 13/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2001 - acc: 0.9631 - val_loss: 0.1354 - val_acc: 0.9936\n","Epoch 14/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.1761 - acc: 0.9767 - val_loss: 0.1149 - val_acc: 0.9744\n","Epoch 15/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1293 - acc: 0.9766 - val_loss: 0.0989 - val_acc: 0.9808\n","Epoch 16/50\n","15/15 [==============================] - 0s 22ms/step - loss: 0.1125 - acc: 0.9848 - val_loss: 0.1038 - val_acc: 0.9551\n","Epoch 17/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0949 - acc: 0.9803 - val_loss: 0.1011 - val_acc: 0.9808\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1059 - acc: 0.9662 - val_loss: 0.0884 - val_acc: 0.9808\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0864 - acc: 0.9803 - val_loss: 0.0658 - val_acc: 0.9679\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0548 - acc: 0.9905 - val_loss: 0.0678 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0719 - acc: 0.9879 - val_loss: 0.0726 - val_acc: 0.9808\n","Epoch 22/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0915 - acc: 0.9718 - val_loss: 0.0576 - val_acc: 0.9872\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0504 - acc: 0.9897 - val_loss: 0.0703 - val_acc: 0.9808\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0736 - acc: 0.9755 - val_loss: 0.0453 - val_acc: 0.9936\n","Epoch 25/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0648 - acc: 0.9791 - val_loss: 0.0609 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0592 - acc: 0.9851 - val_loss: 0.0502 - val_acc: 0.9872\n","Epoch 27/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0786 - acc: 0.9768 - val_loss: 0.0934 - val_acc: 0.9487\n","Epoch 28/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0778 - acc: 0.9725 - val_loss: 0.0871 - val_acc: 0.9487\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0596 - acc: 0.9924 - val_loss: 0.0627 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0544 - acc: 0.9922 - val_loss: 0.0549 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0605 - acc: 0.9752 - val_loss: 0.0456 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0512 - acc: 0.9866 - val_loss: 0.0480 - val_acc: 0.9808\n","Epoch 33/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0329 - acc: 0.9893 - val_loss: 0.0427 - val_acc: 0.9936\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0414 - acc: 0.9906 - val_loss: 0.0419 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0341 - acc: 0.9912 - val_loss: 0.0499 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0372 - acc: 0.9923 - val_loss: 0.0441 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0440 - acc: 0.9886 - val_loss: 0.0480 - val_acc: 0.9744\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0281 - acc: 0.9928 - val_loss: 0.0394 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0545 - acc: 0.9884 - val_loss: 0.0463 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0358 - acc: 0.9943 - val_loss: 0.0445 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0347 - acc: 0.9845 - val_loss: 0.0343 - val_acc: 0.9936\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0210 - acc: 0.9954 - val_loss: 0.0473 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0320 - acc: 0.9864 - val_loss: 0.0447 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0363 - acc: 0.9870 - val_loss: 0.0349 - val_acc: 0.9936\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0419 - acc: 0.9737 - val_loss: 0.0480 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0357 - acc: 0.9927 - val_loss: 0.0730 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0590 - acc: 0.9676 - val_loss: 0.0494 - val_acc: 0.9936\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0431 - acc: 0.9832 - val_loss: 0.0588 - val_acc: 0.9744\n","Epoch 49/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0400 - acc: 0.9827 - val_loss: 0.0419 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0364 - acc: 0.9904 - val_loss: 0.0345 - val_acc: 0.9936\n","\n","Accuracy: 99.36%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd782b69d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 211)         10550     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 211)               357012    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               108544    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 742,353\n","Trainable params: 742,353\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     0.9444    1.0000    0.9714        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     1.0000    1.0000    1.0000        10\n","\n","    accuracy                         0.9936       156\n","   macro avg     0.9921    0.9947    0.9932       156\n","weighted avg     0.9939    0.9936    0.9936       156\n","\n","샘플예측시간:0.55 초\n","learning rate: 1.4e-04\n","num_dense_layers: 2\n","num_dense_nodes: 512\n","optimizer: <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>\n","epochs: 3\n","batch_size: 20\n","Embed_dim: 240\n","Epoch 1/50\n","15/15 [==============================] - 3s 103ms/step - loss: 1.9209 - acc: 0.2339 - val_loss: 1.8530 - val_acc: 0.5385\n","Epoch 2/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.8330 - acc: 0.4967 - val_loss: 1.7304 - val_acc: 0.3718\n","Epoch 3/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.7234 - acc: 0.3771 - val_loss: 1.5791 - val_acc: 0.5449\n","Epoch 4/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.5649 - acc: 0.5455 - val_loss: 1.3573 - val_acc: 0.6154\n","Epoch 5/50\n","15/15 [==============================] - 0s 11ms/step - loss: 1.3663 - acc: 0.5830 - val_loss: 1.0537 - val_acc: 0.6346\n","Epoch 6/50\n","15/15 [==============================] - 0s 10ms/step - loss: 1.0163 - acc: 0.6602 - val_loss: 0.7310 - val_acc: 0.8397\n","Epoch 7/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.7707 - acc: 0.8076 - val_loss: 0.4507 - val_acc: 0.9038\n","Epoch 8/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.4707 - acc: 0.8794 - val_loss: 0.3002 - val_acc: 0.9103\n","Epoch 9/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.3236 - acc: 0.9084 - val_loss: 0.1739 - val_acc: 0.9872\n","Epoch 10/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1928 - acc: 0.9831 - val_loss: 0.1294 - val_acc: 0.9872\n","Epoch 11/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1539 - acc: 0.9816 - val_loss: 0.0931 - val_acc: 0.9872\n","Epoch 12/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1126 - acc: 0.9841 - val_loss: 0.0969 - val_acc: 0.9551\n","Epoch 13/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.1169 - acc: 0.9688 - val_loss: 0.0774 - val_acc: 0.9744\n","Epoch 14/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0945 - acc: 0.9830 - val_loss: 0.0799 - val_acc: 0.9808\n","Epoch 15/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0777 - acc: 0.9836 - val_loss: 0.0553 - val_acc: 0.9936\n","Epoch 16/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0601 - acc: 0.9847 - val_loss: 0.0693 - val_acc: 0.9744\n","Epoch 17/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0939 - acc: 0.9815 - val_loss: 0.0499 - val_acc: 0.9936\n","Epoch 18/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0580 - acc: 0.9872 - val_loss: 0.0478 - val_acc: 0.9936\n","Epoch 19/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0436 - acc: 0.9893 - val_loss: 0.0514 - val_acc: 0.9808\n","Epoch 20/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0522 - acc: 0.9853 - val_loss: 0.0469 - val_acc: 0.9808\n","Epoch 21/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0400 - acc: 0.9896 - val_loss: 0.0409 - val_acc: 0.9936\n","Epoch 22/50\n","15/15 [==============================] - 0s 9ms/step - loss: 0.0349 - acc: 0.9899 - val_loss: 0.0672 - val_acc: 0.9808\n","Epoch 23/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0669 - acc: 0.9769 - val_loss: 0.0457 - val_acc: 0.9872\n","Epoch 24/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0479 - acc: 0.9844 - val_loss: 0.0486 - val_acc: 0.9808\n","Epoch 25/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0532 - acc: 0.9881 - val_loss: 0.0471 - val_acc: 0.9808\n","Epoch 26/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0641 - acc: 0.9878 - val_loss: 0.0519 - val_acc: 0.9808\n","Epoch 27/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0334 - acc: 0.9875 - val_loss: 0.0555 - val_acc: 0.9744\n","Epoch 28/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0441 - acc: 0.9816 - val_loss: 0.0424 - val_acc: 0.9808\n","Epoch 29/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0424 - acc: 0.9871 - val_loss: 0.0536 - val_acc: 0.9744\n","Epoch 30/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0466 - acc: 0.9662 - val_loss: 0.0427 - val_acc: 0.9808\n","Epoch 31/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0492 - acc: 0.9847 - val_loss: 0.0488 - val_acc: 0.9808\n","Epoch 32/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0331 - acc: 0.9893 - val_loss: 0.0394 - val_acc: 0.9936\n","Epoch 33/50\n","15/15 [==============================] - 0s 21ms/step - loss: 0.0452 - acc: 0.9724 - val_loss: 0.0405 - val_acc: 0.9808\n","Epoch 34/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0579 - acc: 0.9814 - val_loss: 0.0485 - val_acc: 0.9808\n","Epoch 35/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0680 - acc: 0.9856 - val_loss: 0.0464 - val_acc: 0.9808\n","Epoch 36/50\n","15/15 [==============================] - 0s 11ms/step - loss: 0.0392 - acc: 0.9874 - val_loss: 0.0386 - val_acc: 0.9808\n","Epoch 37/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0232 - acc: 0.9959 - val_loss: 0.0474 - val_acc: 0.9808\n","Epoch 38/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0350 - acc: 0.9832 - val_loss: 0.0426 - val_acc: 0.9808\n","Epoch 39/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0223 - acc: 0.9922 - val_loss: 0.0374 - val_acc: 0.9808\n","Epoch 40/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0274 - acc: 0.9906 - val_loss: 0.0415 - val_acc: 0.9808\n","Epoch 41/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0225 - acc: 0.9924 - val_loss: 0.0417 - val_acc: 0.9808\n","Epoch 42/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0436 - acc: 0.9820 - val_loss: 0.0492 - val_acc: 0.9808\n","Epoch 43/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0405 - acc: 0.9847 - val_loss: 0.0384 - val_acc: 0.9808\n","Epoch 44/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0201 - acc: 0.9942 - val_loss: 0.0439 - val_acc: 0.9808\n","Epoch 45/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0356 - acc: 0.9851 - val_loss: 0.0429 - val_acc: 0.9808\n","Epoch 46/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0143 - acc: 0.9982 - val_loss: 0.0398 - val_acc: 0.9808\n","Epoch 47/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0389 - acc: 0.9821 - val_loss: 0.0485 - val_acc: 0.9808\n","Epoch 48/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0346 - acc: 0.9932 - val_loss: 0.0443 - val_acc: 0.9872\n","Epoch 49/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.0593 - val_acc: 0.9808\n","Epoch 50/50\n","15/15 [==============================] - 0s 10ms/step - loss: 0.0161 - acc: 0.9962 - val_loss: 0.0542 - val_acc: 0.9808\n","\n","Accuracy: 98.08%\n","\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6e19faea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 240)         12000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 240)               461760    \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               123392    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 7)                 3591      \n","=================================================================\n","Total params: 863,399\n","Trainable params: 863,399\n","Non-trainable params: 0\n","_________________________________________________________________\n","              precision    recall  f1-score   support\n","\n","           0     1.0000    0.9630    0.9811        27\n","           1     1.0000    1.0000    1.0000        20\n","           2     1.0000    1.0000    1.0000        37\n","           3     1.0000    0.8824    0.9375        17\n","           4     1.0000    1.0000    1.0000        34\n","           5     1.0000    1.0000    1.0000        11\n","           6     0.7692    1.0000    0.8696        10\n","\n","    accuracy                         0.9808       156\n","   macro avg     0.9670    0.9779    0.9697       156\n","weighted avg     0.9852    0.9808    0.9816       156\n","\n","샘플예측시간:0.4 초\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vMZnUes9-HGl","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1608624623248,"user_tz":-540,"elapsed":792,"user":{"displayName":"kyu lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmkzfcSHJ_6QYAN8AkXNovpnffqoU98UvnEirWfQ=s64","userId":"03916563542393832270"}},"outputId":"2ef65414-2b82-4e0a-fd1e-d4a0bc6ef2c4"},"source":["model_ls\r\n","\r\n","model_df = pd.DataFrame(model_ls)\r\n","\r\n","model_df.columns = ['pred_time','best_acc','LR','Num_of_dense_layers','Num_of_nodes','optimizer','Embed_dim']\r\n","\r\n","model_df.sort_values('pred_time')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pred_time</th>\n","      <th>best_acc</th>\n","      <th>LR</th>\n","      <th>Num_of_dense_layers</th>\n","      <th>Num_of_nodes</th>\n","      <th>optimizer</th>\n","      <th>Embed_dim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>0.389416</td>\n","      <td>0.980769</td>\n","      <td>0.001050</td>\n","      <td>1</td>\n","      <td>431</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>215</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.393235</td>\n","      <td>0.993590</td>\n","      <td>0.000458</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.394624</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>1</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.395438</td>\n","      <td>0.993590</td>\n","      <td>0.008063</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.395909</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>0</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.396234</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>0</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.396824</td>\n","      <td>0.980769</td>\n","      <td>0.001351</td>\n","      <td>1</td>\n","      <td>196</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>69</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.397129</td>\n","      <td>0.980769</td>\n","      <td>0.000240</td>\n","      <td>1</td>\n","      <td>415</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>202</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.397764</td>\n","      <td>0.993590</td>\n","      <td>0.000610</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.398861</td>\n","      <td>0.993590</td>\n","      <td>0.003029</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.399779</td>\n","      <td>0.980769</td>\n","      <td>0.001098</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>0.403530</td>\n","      <td>0.993590</td>\n","      <td>0.000139</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.404845</td>\n","      <td>0.993590</td>\n","      <td>0.010000</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.404958</td>\n","      <td>0.980769</td>\n","      <td>0.000722</td>\n","      <td>1</td>\n","      <td>446</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.406821</td>\n","      <td>0.980769</td>\n","      <td>0.010000</td>\n","      <td>1</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.407424</td>\n","      <td>0.980769</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.410816</td>\n","      <td>0.980769</td>\n","      <td>0.000158</td>\n","      <td>0</td>\n","      <td>259</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>122</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.412102</td>\n","      <td>0.980769</td>\n","      <td>0.000156</td>\n","      <td>0</td>\n","      <td>398</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.412605</td>\n","      <td>0.980769</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>0.415535</td>\n","      <td>0.993590</td>\n","      <td>0.000672</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.417060</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.419264</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.419931</td>\n","      <td>0.980769</td>\n","      <td>0.004593</td>\n","      <td>1</td>\n","      <td>195</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.424365</td>\n","      <td>0.993590</td>\n","      <td>0.002841</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.428478</td>\n","      <td>0.980769</td>\n","      <td>0.001996</td>\n","      <td>0</td>\n","      <td>201</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>172</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.545186</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>211</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.555400</td>\n","      <td>0.980769</td>\n","      <td>0.000100</td>\n","      <td>0</td>\n","      <td>408</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.558840</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.560388</td>\n","      <td>0.993590</td>\n","      <td>0.003750</td>\n","      <td>0</td>\n","      <td>243</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.562700</td>\n","      <td>0.980769</td>\n","      <td>0.000970</td>\n","      <td>1</td>\n","      <td>212</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.569062</td>\n","      <td>0.980769</td>\n","      <td>0.001003</td>\n","      <td>0</td>\n","      <td>476</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>140</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.569734</td>\n","      <td>0.993590</td>\n","      <td>0.010000</td>\n","      <td>0</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.573762</td>\n","      <td>0.980769</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.575073</td>\n","      <td>0.993590</td>\n","      <td>0.010000</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.575138</td>\n","      <td>0.980769</td>\n","      <td>0.010000</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.576337</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.579361</td>\n","      <td>0.980769</td>\n","      <td>0.001000</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.583062</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>124</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.583138</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.584706</td>\n","      <td>0.993590</td>\n","      <td>0.000100</td>\n","      <td>0</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow_addons.optimizers.rectified...</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.585231</td>\n","      <td>0.980769</td>\n","      <td>0.003354</td>\n","      <td>2</td>\n","      <td>139</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>227</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.586202</td>\n","      <td>0.980769</td>\n","      <td>0.010000</td>\n","      <td>2</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.588215</td>\n","      <td>0.993590</td>\n","      <td>0.006140</td>\n","      <td>0</td>\n","      <td>512</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n","      <td>199</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.592026</td>\n","      <td>0.993590</td>\n","      <td>0.010000</td>\n","      <td>2</td>\n","      <td>328</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.598336</td>\n","      <td>0.980769</td>\n","      <td>0.008967</td>\n","      <td>0</td>\n","      <td>495</td>\n","      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.n...</td>\n","      <td>188</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    pred_time  ...  Embed_dim\n","6    0.389416  ...        215\n","35   0.393235  ...        200\n","26   0.394624  ...        240\n","28   0.395438  ...        240\n","22   0.395909  ...         60\n","24   0.396234  ...        240\n","10   0.396824  ...         69\n","1    0.397129  ...        202\n","36   0.397764  ...        240\n","33   0.398861  ...         60\n","20   0.399779  ...        240\n","44   0.403530  ...        240\n","31   0.404845  ...         60\n","11   0.404958  ...        240\n","17   0.406821  ...         60\n","16   0.407424  ...        240\n","2    0.410816  ...        122\n","19   0.412102  ...         60\n","15   0.412605  ...         60\n","41   0.415535  ...        240\n","37   0.417060  ...        240\n","21   0.419264  ...        240\n","9    0.419931  ...        120\n","34   0.424365  ...        240\n","3    0.428478  ...        172\n","43   0.545186  ...        211\n","12   0.555400  ...         60\n","27   0.558840  ...        240\n","32   0.560388  ...        240\n","5    0.562700  ...         86\n","8    0.569062  ...        140\n","25   0.569734  ...         60\n","18   0.573762  ...        240\n","23   0.575073  ...        240\n","13   0.575138  ...        240\n","39   0.576337  ...        240\n","0    0.579361  ...        120\n","42   0.583062  ...        124\n","40   0.583138  ...        240\n","38   0.584706  ...        240\n","4    0.585231  ...        227\n","14   0.586202  ...         60\n","30   0.588215  ...        199\n","29   0.592026  ...         60\n","7    0.598336  ...        188\n","\n","[45 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"dz-z1xMX1Fup"},"source":["plot_convergence(search_result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nnnz2M71UGtU"},"source":["search_result.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOkQXbNZULE3"},"source":["search_result.fun"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hBV2M33iUSLD"},"source":["sorted(zip(search_result.func_vals, search_result.x_iters))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CmHTe-WKU-to"},"source":[""],"execution_count":null,"outputs":[]}]}